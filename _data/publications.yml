stats:
  citations: 41497
  h_index: 79
  i10_index: 214
publications:
- title: '{PowerGraph}: Distributed {Graph-Parallel} computation on natural graphs'
  authors: Joseph E Gonzalez and Yucheng Low and Haijie Gu and Danny Bickson and Carlos
    Guestrin
  venue: 10th USENIX symposium on operating systems design and implementation (OSDI
    12)
  year: ''
  citations: 3341
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:t6usbXjVLHcC
  abstract: Large-scale graph-structured computation is central to tasks ranging from
    targeted advertising to natural language processing and has led to the development
    of several graph-parallel abstractions including Pregel and GraphLab. However,
    the natural graphs commonly found in the real-world have highly skewed power-law
    degree distributions, which challenge the assumptions made by these abstractions,
    limiting performance and scalability.
- title: 'Apache spark: a unified engine for big data processing'
  authors: Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and
    Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram
    Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott
    Shenker and Ion Stoica
  venue: Communications of the ACM
  year: ''
  citations: 3172
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:cFHS6HbyZ2cC
  abstract: This open source computing framework unifies streaming, batch, and interactive
    big data workloads to unlock new applications.
- title: 'Distributed graphlab: A framework for machine learning in the cloud'
  authors: Yucheng Low and Joseph Gonzalez and Aapo Kyrola and Danny Bickson and Carlos
    Guestrin and Joseph M Hellerstein
  venue: arXiv preprint arXiv:1204.6078
  year: ''
  citations: 2534
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:WF5omc3nYNoC
  abstract: While high-level data parallel frameworks, like MapReduce, simplify the
    design and implementation of large-scale data processing systems, they do not
    naturally or efficiently support many important data mining and machine learning
    algorithms and can lead to inefficient learning systems. To help fill this critical
    void, we introduced the GraphLab abstraction which naturally expresses asynchronous,
    dynamic, graph-parallel computation while ensuring data consistency and achieving
    a high degree of parallel performance in the shared-memory setting. In this paper,
    we extend the GraphLab framework to the substantially more challenging distributed
    setting while preserving strong data consistency guarantees. We develop graph
    based extensions to pipelined locking and data versioning to reduce network congestion
    and mitigate the effect of network latency. We also introduce fault tolerance
    to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm
    and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction
    itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction
    on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance
    gains over Hadoop-based implementations.
- title: Judging llm-as-a-judge with mt-bench and chatbot arena
  authors: Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao
    Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and
    Hao Zhang and Joseph E Gonzalez and Ion Stoica
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 2315
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:a3BOlSfXSfwC
  abstract: 'Evaluating large language model (LLM) based chat assistants is challenging
    due to their broad capabilities and the inadequacy of existing benchmarks in measuring
    human preferences. To address this, we explore using strong LLMs as judges to
    evaluate these models on more open-ended questions. We examine the usage and limitations
    of LLM-as-a-judge, including position, verbosity, and self-enhancement biases,
    as well as limited reasoning ability, and propose solutions to mitigate some of
    them. We then verify the agreement between LLM judges and human preferences by
    introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena,
    a crowdsourced battle platform. Our results reveal that strong LLM judges like
    GPT-4 can match both controlled and crowdsourced human preferences well, achieving
    over 80\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge
    is a scalable and explainable way to approximate human preferences, which are
    otherwise very expensive to obtain. Additionally, we show our benchmark and traditional
    benchmarks complement each other by evaluating several variants of LLaMA and Vicuna.
    The MT-bench questions, 3K expert votes, and 30K conversations with human preferences
    are publicly available at https://github. com/lm-sys/FastChat/tree/main/fastchat/llm_judge.'
- title: 'Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality'
  authors: Wei-Lin Chiang and Zhuohan Li and Zi Lin and Ying Sheng and Zhanghao Wu
    and Hao Zhang and Lianmin Zheng and Siyuan Zhuang and Yonghao Zhuang and Joseph
    E Gonzalez and Ion Stoica and Eric P Xing
  venue: See https://vicuna. lmsys. org (accessed 14 April 2023)
  year: ''
  citations: 1752
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:LhH-TYMQEocC
  abstract: ''
- title: 'Tune: A research platform for distributed model selection and training'
  authors: Richard Liaw and Eric Liang and Robert Nishihara and Philipp Moritz and
    Joseph E Gonzalez and Ion Stoica
  venue: arXiv preprint arXiv:1807.05118
  year: ''
  citations: 1181
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:URolC5Kub84C
  abstract: Modern machine learning algorithms are increasingly computationally demanding,
    requiring specialized hardware and distributed computation to achieve high performance
    in a reasonable time frame. Many hyperparameter search algorithms have been proposed
    for improving the efficiency of model selection, however their adaptation to the
    distributed compute environment is often ad-hoc. We propose Tune, a unified framework
    for model selection and training that provides a narrow-waist interface between
    training scripts and search algorithms. We show that this interface meets the
    requirements for a broad range of hyperparameter search algorithms, allows straightforward
    scaling of search to large clusters, and simplifies algorithm implementation.
    We demonstrate the implementation of several state-of-the-art hyperparameter search
    algorithms in Tune. Tune is available at http://ray.readthedocs.io/en/latest/tune.html.
- title: 'Graphlab: A new framework for parallel machine learning'
  authors: Yucheng Low and Joseph E Gonzalez and Aapo Kyrola and Danny Bickson and
    Carlos E Guestrin and Joseph Hellerstein
  venue: arXiv preprint arXiv:1408.2041
  year: ''
  citations: 1119
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:rO6llkc54NcC
  abstract: Designing and implementing efficient, provably correct parallel machine
    learning (ML) algorithms is challenging. Existing high-level parallel abstractions
    like MapReduce are insufficiently expressive while low-level tools like MPI and
    Pthreads leave ML experts repeatedly solving the same design challenges. By targeting
    common patterns in ML, we developed GraphLab, which improves upon abstractions
    like MapReduce by compactly expressing asynchronous iterative algorithms with
    sparse computational dependencies while ensuring data consistency and achieving
    a high degree of parallel performance. We demonstrate the expressiveness of the
    GraphLab framework by designing and implementing parallel versions of belief propagation,
    Gibbs sampling, Co-EM, Lasso and Compressed Sensing. We show that using GraphLab
    we can achieve excellent parallel performance on large scale real-world problems.
- title: 'RLlib: Abstractions for distributed reinforcement learning'
  authors: Eric Liang and Richard Liaw and Robert Nishihara and Philipp Moritz and
    Roy Fox and Ken Goldberg and Joseph Gonzalez and Michael Jordan and Ion Stoica
  venue: International conference on machine learning
  year: ''
  citations: 1076
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:dhFuZR0502QC
  abstract: 'Reinforcement learning (RL) algorithms involve the deep nesting of highly
    irregular computation patterns, each of which typically exhibits opportunities
    for distributed computation. We argue for distributing RL components in a composable
    way by adapting algorithms for top-down hierarchical control, thereby encapsulating
    parallelism and resource requirements within short-running compute tasks. We demonstrate
    the benefits of this principle through RLlib: a library that provides scalable
    software primitives for RL. These primitives enable a broad range of algorithms
    to be implemented with high performance, scalability, and substantial code reuse.
    RLlib is available as part of the open source Ray project at http://rllib. io/.'
- title: Efficient memory management for large language model serving with pagedattention
  authors: Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin
    Zheng and Cody Hao Yu and Joseph Gonzalez and Hao Zhang and Ion Stoica
  venue: ''
  year: ''
  citations: 1072
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ZzlSgRqYykMC
  abstract: High throughput serving of large language models (LLMs) requires batching
    sufficiently many requests at a time. However, existing systems struggle because
    the key-value cache (KV cache) memory for each request is huge and grows and shrinks
    dynamically. When managed inefficiently, this memory can be significantly wasted
    by fragmentation and redundant duplication, limiting the batch size. To address
    this problem, we propose PagedAttention, an attention algorithm inspired by the
    classical virtual memory and paging techniques in operating systems. On top of
    it, we build vLLM, an LLM serving system that achieves (1) near-zero waste in
    KV cache memory and (2) flexible sharing of KV cache within and across requests
    to further reduce memory usage. Our evaluations show that vLLM improves the throughput
    of popular LLMs by 2--4× with the same level of latency compared to the state-of-the-art
    systems …
- title: 'Graphx: A resilient distributed graph system on spark'
  authors: Reynold S Xin and Joseph E Gonzalez and Michael J Franklin and Ion Stoica
  venue: ''
  year: ''
  citations: 938
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:lSLTfruPkqcC
  abstract: From social networks to targeted advertising, big graphs capture the structure
    in data and are central to recent advances in machine learning and data mining.
    Unfortunately, directly applying existing data-parallel tools to graph computation
    tasks can be cumbersome and inefficient. The need for intuitive, scalable tools
    for graph computation has lead to the development of new graph-parallel systems
    (e.g., Pregel, PowerGraph) which are designed to efficiently execute graph algorithms.
    Unfortunately, these new graph-parallel systems do not address the challenges
    of graph construction and transformation which are often just as problematic as
    the subsequent computation. Furthermore, existing graph-parallel systems provide
    limited fault-tolerance and support for interactive data mining.We introduce GraphX,
    which combines the advantages of both data-parallel and graph-parallel systems
    by efficiently expressing …
- title: 'Cloud programming simplified: A berkeley view on serverless computing'
  authors: Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-Che
    Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira
    and Karl Krauth and Neeraja Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa
    and Ion Stoica and David A Patterson
  venue: arXiv preprint arXiv:1902.03383
  year: ''
  citations: 840
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:BqipwSGYUEgC
  abstract: Serverless cloud computing handles virtually all the system administration
    operations needed to make it easier for programmers to use the cloud. It provides
    an interface that greatly simplifies cloud programming, and represents an evolution
    that parallels the transition from assembly language to high-level programming
    languages. This paper gives a quick history of cloud computing, including an accounting
    of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains
    the motivation for serverless computing, describes applications that stretch the
    current limits of serverless, and then lists obstacles and research opportunities
    required for serverless computing to fulfill its full potential. Just as the 2009
    paper identified challenges for the cloud and predicted they would be addressed
    and that cloud use would accelerate, we predict these issues are solvable and
    that serverless computing will grow to dominate the future of cloud computing.
- title: Carbon emissions and large neural network training
  authors: David Patterson and Joseph Gonzalez and Quoc Le and Chen Liang and Lluis-Miquel
    Munguia and Daniel Rothchild and David So and Maud Texier and Jeff Dean
  venue: arXiv preprint arXiv:2104.10350
  year: ''
  citations: 839
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:edDO8Oi4QzsC
  abstract: 'The computation demand for machine learning (ML) has grown rapidly recently,
    which comes with a number of costs. Estimating the energy cost helps measure its
    environmental impact and finding greener strategies, yet it is challenging without
    detailed information. We calculate the energy use and carbon footprint of several
    recent large models-T5, Meena, GShard, Switch Transformer, and GPT-3-and refine
    earlier estimates for the neural architecture search that found Evolved Transformer.
    We highlight the following opportunities to improve energy efficiency and CO2
    equivalent emissions (CO2e): Large but sparsely activated DNNs can consume <1/10th
    the energy of large, dense DNNs without sacrificing accuracy despite using as
    many or even more parameters. Geographic location matters for ML workload scheduling
    since the fraction of carbon-free energy and resulting CO2e vary ~5X-10X, even
    within the same country and the same organization. We are now optimizing where
    and when large models are trained. Specific datacenter infrastructure matters,
    as Cloud datacenters can be ~1.4-2X more energy efficient than typical datacenters,
    and the ML-oriented accelerators inside them can be ~2-5X more effective than
    off-the-shelf systems. Remarkably, the choice of DNN, datacenter, and processor
    can reduce the carbon footprint up to ~100-1000X. These large factors also make
    retroactive estimates of energy cost difficult. To avoid miscalculations, we believe
    ML papers requiring large computational resources should make energy consumption
    and CO2e explicit when practical. We are working to be more transparent about
    energy use and …'
- title: 'Skipnet: Learning dynamic routing in convolutional networks'
  authors: Xin Wang and Fisher Yu and Zi-Yi Dou and Trevor Darrell and Joseph E Gonzalez
  venue: Proceedings of the European conference on computer vision (ECCV)
  year: ''
  citations: 781
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:fQNAKQ3IYiAC
  abstract: While deeper convolutional networks are needed to achieve maximum accuracy
    in visual perception tasks, for many inputs shallower networks are sufficient.
    We exploit this observation by learning to skip convolutional layers on a per-input
    basis. We introduce SkipNet, a modified residual network, that uses a gating network
    to selectively skip convolutional blocks based on the activations of the previous
    layer. We formulate the dynamic skipping problem in the context of sequential
    decision making and propose a hybrid learning algorithm that combines supervised
    learning and reinforcement learning to address the challenges of non-differentiable
    skipping decisions. We show SkipNet reduces computation by 30-90% while preserving
    the accuracy of the original model on four benchmark datasets and outperforms
    the state-of-the-art dynamic networks and static compression methods. We also
    qualitatively evaluate the gating policy to reveal a relationship between image
    scale and saliency and the number of layers skipped.
- title: 'Clipper: A {Low-Latency} online prediction serving system'
  authors: Daniel Crankshaw and Xin Wang and Guilio Zhou and Michael J Franklin and
    Joseph E Gonzalez and Ion Stoica
  venue: 14th USENIX Symposium on Networked Systems Design and Implementation (NSDI
    17)
  year: ''
  citations: 764
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:2osOgNQ5qMEC
  abstract: Machine learning is being deployed in a growing number of applications
    which demand real-time, accurate, and robust predictions under heavy query load.
    However, most machine learning frameworks and systems only address model training
    and not deployment.
- title: Frustratingly simple few-shot object detection
  authors: Xin Wang and Thomas E Huang and Trevor Darrell and Joseph E Gonzalez and
    Fisher Yu
  venue: arXiv preprint arXiv:2003.06957
  year: ''
  citations: 654
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:P5F9QuxV20EC
  abstract: 'Detecting rare objects from a few examples is an emerging problem. Prior
    works show meta-learning is a promising approach. But, fine-tuning techniques
    have drawn scant attention. We find that fine-tuning only the last layer of existing
    detectors on rare classes is crucial to the few-shot object detection task. Such
    a simple approach outperforms the meta-learning methods by roughly 2~20 points
    on current benchmarks and sometimes even doubles the accuracy of the prior methods.
    However, the high variance in the few samples often leads to the unreliability
    of existing benchmarks. We revise the evaluation protocols by sampling multiple
    groups of training examples to obtain stable comparisons and build new benchmarks
    based on three datasets: PASCAL VOC, COCO and LVIS. Again, our fine-tuning approach
    establishes a new state of the art on the revised benchmarks. The code as well
    as the pretrained models are available at https://github.com/ucbdrive/few-shot-object-detection.'
- title: 'Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality,
    March 2023'
  authors: Wei-Lin Chiang and Zhuohan Li and Zi Lin and Ying Sheng and Zhanghao Wu
    and Hao Zhang and Lianmin Zheng and Siyuan Zhuang and Yonghao Zhuang and Joseph
    E Gonzalez and Ion Stoica and Eric P Xing
  venue: URL https://lmsys. org/blog/2023-03-30-vicuna
  year: ''
  citations: 645
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:wMgC3FpKEyYC
  abstract: ''
- title: 'Visual transformers: Token-based image representation and processing for
    computer vision'
  authors: Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang
    and Zhicheng Yan and Masayoshi Tomizuka and Joseph Gonzalez and Kurt Keutzer and
    Peter Vajda
  venue: arXiv preprint arXiv:2006.03677
  year: ''
  citations: 616
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:WZBGuue-350C
  abstract: Computer vision has achieved remarkable success by (a) representing images
    as uniformly-arranged pixel arrays and (b) convolving highly-localized features.
    However, convolutions treat all image pixels equally regardless of importance;
    explicitly model all concepts across all images, regardless of content; and struggle
    to relate spatially-distant concepts. In this work, we challenge this paradigm
    by (a) representing images as semantic visual tokens and (b) running transformers
    to densely model token relationships. Critically, our Visual Transformer operates
    in a semantic token space, judiciously attending to different image parts based
    on context. This is in sharp contrast to pixel-space transformers that require
    orders-of-magnitude more compute. Using an advanced training recipe, our VTs significantly
    outperform their convolutional counterparts, raising ResNet accuracy on ImageNet
    top-1 by 4.6 to 7 points while using fewer FLOPs and parameters. For semantic
    segmentation on LIP and COCO-stuff, VT-based feature pyramid networks (FPN) achieve
    0.35 points higher mIoU while reducing the FPN module's FLOPs by 6.5x.
- title: 'Serverless computing: One step forward, two steps back'
  authors: Joseph M Hellerstein and Jose Faleiro and Joseph E Gonzalez and Johann
    Schleier-Smith and Vikram Sreekanti and Alexey Tumanov and Chenggang Wu
  venue: arXiv preprint arXiv:1812.03651
  year: ''
  citations: 537
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:BUYA1_V_uYcC
  abstract: 'Serverless computing offers the potential to program the cloud in an
    autoscaling, pay-as-you go manner. In this paper we address critical gaps in first-generation
    serverless computing, which place its autoscaling potential at odds with dominant
    trends in modern computing: notably data-centric and distributed computing, but
    also open source and custom hardware. Put together, these gaps make current serverless
    offerings a bad fit for cloud innovation and particularly bad for data systems
    innovation. In addition to pinpointing some of the main shortfalls of current
    serverless architectures, we raise a set of challenges we believe must be met
    to unlock the radical potential that the cloud---with its exabytes of storage
    and millions of cores---should offer to innovative developers.'
- title: 'Opaque: An oblivious and encrypted distributed analytics platform'
  authors: Wenting Zheng and Ankur Dave and Jethro G Beekman and Raluca Ada Popa and
    Joseph E Gonzalez and Ion Stoica
  venue: 14th USENIX Symposium on Networked Systems Design and Implementation (NSDI
    17)
  year: ''
  citations: 486
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:PR6Y55bgFSsC
  abstract: Many systems run rich analytics on sensitive data in the cloud, but are
    prone to data breaches. Hardware enclaves promise data confidentiality and secure
    execution of arbitrary computation, yet still suffer from access pattern leakage.
    We propose Opaque, a distributed data analytics platform supporting a wide range
    of queries while providing strong security guarantees. Opaque introduces new distributed
    oblivious relational operators that hide access patterns, and new query planning
    techniques to optimize these new operators. Opaque is implemented on Spark SQL
    with few changes to the underlying system. Opaque provides data encryption, authentication
    and computation verification with a performance ranging from 52% faster to 3.3
    x slower as compared to vanilla Spark SQL; obliviousness comes with a 1.6–46x
    overhead. Opaque provides an improvement of three orders of magnitude over state-of-the-art
    oblivious protocols, and our query optimization techniques improve performance
    by 2–5x.
- title: 'Shift: A zero flop, zero parameter alternative to spatial convolutions'
  authors: Bichen Wu and Alvin Wan and Xiangyu Yue and Peter Jin and Sicheng Zhao
    and Noah Golmant and Amir Gholaminejad and Joseph Gonzalez and Kurt Keutzer
  venue: Proceedings of the IEEE conference on computer vision and pattern recognition
  year: ''
  citations: 463
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:yD5IFk8b50cC
  abstract: Neural networks rely on convolutions to aggregate spatial information.
    However, spatial convolutions are expensive in terms of model size and computation,
    both of which grow quadratically with respect to kernel size. In this paper, we
    present a parameter-free, FLOP-free" shift" operation as an alternative to spatial
    convolutions. We fuse shifts and point-wise convolutions to construct end-to-end
    trainable shift-based modules, with a hyperparameter characterizing the tradeoff
    between accuracy and efficiency. To demonstrate the operation's efficacy, we replace
    ResNet's 3x3 convolutions with shift-based modules for improved CIFAR-10 and CIFAR-100
    accuracy using 60% fewer parameters; we additionally demonstrate the operation's
    resilience to parameter reduction on ImageNet, outperforming ResNet family members
    despite having millions fewer parameters. We further design a family of neural
    networks called ShiftNet, which achieve strong performance on classification,
    face verification and style transfer while demanding many fewer parameters.
- title: 'Graphlab: A new parallel framework for machine learning'
  authors: Yucheng Low and Joseph Gonzalez and Aapo Kyrola and Danny Bickson and Carlos
    Guestrin and Joseph M Hellerstein
  venue: Conference on uncertainty in artificial intelligence (UAI)
  year: ''
  citations: 456
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:M3ejUd6NZC8C
  abstract: ''
- title: 'Fetchsgd: Communication-efficient federated learning with sketching'
  authors: Daniel Rothchild and Ashwinee Panda and Enayat Ullah and Nikita Ivkin and
    Ion Stoica and Vladimir Braverman and Joseph Gonzalez and Raman Arora
  venue: International Conference on Machine Learning
  year: ''
  citations: 428
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:blknAaTinKkC
  abstract: Existing approaches to federated learning suffer from a communication
    bottleneck as well as convergence issues due to sparse client participation. In
    this paper we introduce a novel algorithm, called FetchSGD, to overcome these
    challenges. FetchSGD compresses model updates using a Count Sketch, and then takes
    advantage of the mergeability of sketches to combine model updates from many workers.
    A key insight in the design of FetchSGD is that, because the Count Sketch is linear,
    momentum and error accumulation can both be carried out within the sketch. This
    allows the algorithm to move momentum and error accumulation from clients to the
    central aggregator, overcoming the challenges of sparse client participation while
    still achieving high compression rates and good convergence. We prove that FetchSGD
    has favorable convergence guarantees, and we demonstrate its empirical effectiveness
    by training two residual networks and a transformer model.
- title: 'Ansor: Generating {High-Performance} tensor programs for deep learning'
  authors: Lianmin Zheng and Chengfan Jia and Minmin Sun and Zhao Wu and Cody Hao
    Yu and Ameer Haj-Ali and Yida Wang and Jun Yang and Danyang Zhuo and Koushik Sen
    and Joseph E Gonzalez and Ion Stoica
  venue: 14th USENIX symposium on operating systems design and implementation (OSDI
    20)
  year: ''
  citations: 410
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:zYLM7Y9cAGgC
  abstract: High-performance tensor programs are crucial to guarantee efficient execution
    of deep neural networks. However, obtaining performant tensor programs for different
    operators on various hardware platforms is notoriously challenging. Currently,
    deep learning systems rely on vendor-provided kernel libraries or various search
    strategies to get performant tensor programs. These approaches either require
    significant engineering effort to develop platform-specific optimization code
    or fall short of finding high-performance programs due to restricted search space
    and ineffective exploration strategy.
- title: 'Gorilla: Large language model connected with massive apis'
  authors: Shishir G Patil and Tianjun Zhang and Xin Wang and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2305.15334
  year: ''
  citations: 377
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:KbBQZpvPDL4C
  abstract: Large Language Models (LLMs) have seen an impressive wave of advances
    recently, with models now excelling in a variety of tasks, such as mathematical
    reasoning and program synthesis. However, their potential to effectively use tools
    via API calls remains unfulfilled. This is a challenging task even for today's
    state-of-the-art LLMs such as GPT-4, largely due to their inability to generate
    accurate input arguments and their tendency to hallucinate the wrong usage of
    an API call. We release Gorilla, a finetuned LLaMA-based model that surpasses
    the performance of GPT-4 on writing API calls. When combined with a document retriever,
    Gorilla demonstrates a strong capability to adapt to test-time document changes,
    enabling flexible user updates or version changes. It also substantially mitigates
    the issue of hallucination, commonly encountered when prompting LLMs directly.
    To evaluate the model's ability, we introduce APIBench, a comprehensive dataset
    consisting of HuggingFace, TorchHub, and TensorHub APIs. The successful integration
    of the retrieval system with Gorilla demonstrates the potential for LLMs to use
    tools more accurately, keep up with frequently updated documentation, and consequently
    increase the reliability and applicability of their outputs. Gorilla's code, model,
    data, and demo are available at https://gorilla.cs.berkeley.edu
- title: 'Fbnetv2: Differentiable neural architecture search for spatial and channel
    dimensions'
  authors: Alvin Wan and Xiaoliang Dai and Peizhao Zhang and Zijian He and Yuandong
    Tian and Saining Xie and Bichen Wu and Matthew Yu and Tao Xu and Kan Chen and
    Peter Vajda and Joseph E Gonzalez
  venue: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition
  year: ''
  citations: 360
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Fu2w8maKXqMC
  abstract: 'Differentiable Neural Architecture Search (DNAS) has demonstrated great
    success in designing state-of-the-art, efficient neural networks. However, DARTS-based
    DNAS''s search space is small when compared to other search methods'', since all
    candidate network layers must be explicitly instantiated in memory. To address
    this bottleneck, we propose a memory and computationally efficient DNAS variant:
    DMaskingNAS. This algorithm expands the search space by up to 10^ 14x over conventional
    DNAS, supporting searches over spatial and channel dimensions that are otherwise
    prohibitively expensive: input resolution and number of filters. We propose a
    masking mechanism for feature map reuse, so that memory and computational costs
    stay nearly constant as the search space expands. Furthermore, we employ effective
    shape propagation to maximize per-FLOP or per-parameter accuracy. The searched
    FBNetV2s yield state-of-the-art performance when compared with all previous architectures.
    With up to 421x less search cost, DMaskingNAS finds models with 0.9% higher accuracy,
    15% fewer FLOPs than MobileNetV3-Small; and with similar accuracy but 20% fewer
    FLOPs than Efficient-B0. Furthermore, our FBNetV2 outperforms MobileNetV3 by 2.6%
    in accuracy, with equivalent model size. FBNetV2 models are open-sourced at https://github.
    com/facebookresearch/mobile-vision.'
- title: Model-based value estimation for efficient model-free reinforcement learning
  authors: Vladimir Feinberg and Alvin Wan and Ion Stoica and Michael I Jordan and
    Joseph E Gonzalez and Sergey Levine
  venue: arXiv preprint arXiv:1803.00101
  year: ''
  citations: 357
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ILKRHgRFtOwC
  abstract: Recent model-free reinforcement learning algorithms have proposed incorporating
    learned dynamics models as a source of additional data with the intention of reducing
    sample complexity. Such methods hold the promise of incorporating imagined data
    coupled with a notion of model uncertainty to accelerate the learning of continuous
    control tasks. Unfortunately, they rely on heuristics that limit usage of the
    dynamics model. We present model-based value expansion, which controls for uncertainty
    in the model by only allowing imagination to fixed depth. By enabling wider use
    of learned dynamics models within a model-free reinforcement learning algorithm,
    we improve value estimation, which, in turn, reduces the sample complexity of
    learning.
- title: The carbon footprint of machine learning training will plateau, then shrink
  authors: David Patterson and Joseph Gonzalez and Urs Hölzle and Quoc Le and Chen
    Liang and Lluis-Miquel Munguia and Daniel Rothchild and David R So and Maud Texier
    and Jeff Dean
  venue: Computer
  year: ''
  citations: 338
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:hCrLmN-GePgC
  abstract: Machine learning (ML) workloads have rapidly grown, raising concerns about
    their carbon footprint. We show four best practices to reduce ML training energy
    and carbon dioxide emissions. If the whole ML field adopts best practices, we
    predict that by 2030, total carbon emissions from training will decline.
- title: 'Cloudburst: Stateful functions-as-a-service'
  authors: Vikram Sreekanti and Chenggang Wu and Xiayue Charles Lin and Johann Schleier-Smith
    and Jose M Faleiro and Joseph E Gonzalez and Joseph M Hellerstein and Alexey Tumanov
  venue: arXiv preprint arXiv:2001.04592
  year: ''
  citations: 335
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:kuK5TVdYjLIC
  abstract: Function-as-a-Service (FaaS) platforms and "serverless" cloud computing
    are becoming increasingly popular. Current FaaS offerings are targeted at stateless
    functions that do minimal I/O and communication. We argue that the benefits of
    serverless computing can be extended to a broader range of applications and algorithms.
    We present the design and implementation of Cloudburst, a stateful FaaS platform
    that provides familiar Python programming with low-latency mutable state and communication,
    while maintaining the autoscaling benefits of serverless computing. Cloudburst
    accomplishes this by leveraging Anna, an autoscaling key-value store, for state
    sharing and overlay routing combined with mutable caches co-located with function
    executors for data locality. Performant cache consistency emerges as a key challenge
    in this architecture. To this end, Cloudburst provides a combination of lattice-encapsulated
    state and new definitions and protocols for distributed session consistency. Empirical
    results on benchmarks and diverse applications show that Cloudburst makes stateful
    functions practical, reducing the state-management overheads of current FaaS platforms
    by orders of magnitude while also improving the state of the art in serverless
    consistency.
- title: Scalable inference in latent variable models
  authors: Amr Ahmed and Moahmed Aly and Joseph Gonzalez and Shravan Narayanamurthy
    and Alexander J Smola
  venue: ''
  year: ''
  citations: 333
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:tOudhMTPpwUC
  abstract: 'Latent variable techniques are pivotal in tasks ranging from predicting
    user click patterns and targeting ads to organizing the news and managing user
    generated content. Latent variable techniques like topic modeling, clustering,
    and subspace estimation provide substantial insight into the latent structure
    of complex data with little or no external guidance making them ideal for reasoning
    about large-scale, rapidly evolving datasets. Unfortunately, due to the data dependencies
    and global state introduced by latent variables and the iterative nature of latent
    variable inference, latent-variable techniques are often prohibitively expensive
    to apply to large-scale, streaming datasets.In this paper we present a scalable
    parallel framework for efficient inference in latent variable models over streaming
    web-scale data. Our framework addresses three key challenges: 1) synchronizing
    the global state which includes global latent …'
- title: 'Alpa: Automating inter-and {Intra-Operator} parallelism for distributed
    deep learning'
  authors: Lianmin Zheng and Zhuohan Li and Hao Zhang and Yonghao Zhuang and Zhifeng
    Chen and Yanping Huang and Yida Wang and Yuanzhong Xu and Danyang Zhuo and Eric
    P Xing and Joseph E Gonzalez and Ion Stoica
  venue: 16th USENIX Symposium on Operating Systems Design and Implementation (OSDI
    22)
  year: ''
  citations: 330
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:z_wVstp3MssC
  abstract: 'Alpa automates model-parallel training of large deep learning (DL) models
    by generating execution plans that unify data, operator, and pipeline parallelism.
    Existing model-parallel training systems either require users to manually create
    a parallelization plan or automatically generate one from a limited space of model
    parallelism configurations. They do not suffice to scale out complex DL models
    on distributed compute devices. Alpa distributes the training of large DL models
    by viewing parallelisms as two hierarchical levels: inter-operator and intra-operator
    parallelisms. Based on it, Alpa constructs a new hierarchical space for massive
    model-parallel execution plans. Alpa designs a number of compilation passes to
    automatically derive efficient parallel execution plans at each parallelism level.
    Alpa implements an efficient runtime to orchestrate the two-level parallel execution
    on distributed compute devices. Our evaluation shows Alpa generates parallelization
    plans that match or outperform hand-tuned model-parallel training systems even
    on models they are designed for. Unlike specialized systems, Alpa also generalizes
    to models with heterogeneous architectures and models without manually-designed
    plans. Alpa''s source code is publicly available at https://github. com/alpa-projects/alpa'
- title: 'Train big, then compress: Rethinking model size for efficient training and
    inference of transformers'
  authors: Zhuohan Li and Eric Wallace and Sheng Shen and Kevin Lin and Kurt Keutzer
    and Dan Klein and Joey Gonzalez
  venue: International Conference on machine learning
  year: ''
  citations: 315
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:hFOr9nPyWt4C
  abstract: 'Since hardware resources are limited, the objective of training deep
    learning models is typically to maximize accuracy subject to the time and memory
    constraints of training and inference. We study the impact of model size in this
    setting, focusing on Transformer models for NLP tasks that are limited by compute:
    self-supervised pretraining and high-resource machine translation. We first show
    that even though smaller Transformer models execute faster per iteration, wider
    and deeper models converge in significantly fewer steps. Moreover, this acceleration
    in convergence typically outpaces the additional computational overhead of using
    larger models. Therefore, the most compute-efficient training strategy is to counterintuitively
    train extremely large models but stop after a small number of iterations. This
    leads to an apparent trade-off between the training efficiency of large Transformer
    models and the inference efficiency of small Transformer models. However, we show
    that large models are more robust to compression techniques such as quantization
    and pruning than small models. Consequently, one can get the best of both worlds:
    heavily compressed, large models achieve higher accuracy than lightly compressed,
    small models.'
- title: 'Flexgen: High-throughput generative inference of large language models with
    a single gpu'
  authors: Ying Sheng and Lianmin Zheng and Binhang Yuan and Zhuohan Li and Max Ryabinin
    and Beidi Chen and Percy Liang and Christopher Ré and Ion Stoica and Ce Zhang
  venue: International Conference on Machine Learning
  year: ''
  citations: 309
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:OcBU2YAGkTUC
  abstract: The high computational and memory requirements of large language model
    (LLM) inference make it feasible only with multiple high-end accelerators. Motivated
    by the emerging demand for latency-insensitive tasks with batched processing,
    this paper initiates the study of high-throughput LLM inference using limited
    resources, such as a single commodity GPU. We present FlexGen, a high-throughput
    generation engine for running LLMs with limited GPU memory. FlexGen can be flexibly
    configured under various hardware resource constraints by aggregating memory and
    computation from the GPU, CPU, and disk. By solving a linear programming problem,
    it searches for efficient patterns to store and access tensors. FlexGen further
    compresses the weights and the attention cache to 4 bits with negligible accuracy
    loss. These techniques enable FlexGen to have a larger space of batch size choices
    and thus significantly increase maximum throughput. As a result, when running
    OPT-175B on a single 16GB GPU, FlexGen achieves significantly higher throughput
    compared to state-of-the-art offloading systems, reaching a generation throughput
    of 1 token/s for the first time with an effective batch size of 144. On the HELM
    benchmark, FlexGen can benchmark a 30B model with a 16GB GPU on 7 representative
    sub-scenarios in 21 hours. The code is available at https://github. com/FMInference/FlexGen.
- title: A review of single-source deep unsupervised visual domain adaptation
  authors: Sicheng Zhao and Xiangyu Yue and Shanghang Zhang and Bo Li and Han Zhao
    and Bichen Wu and Ravi Krishna and Joseph E Gonzalez and Alberto L Sangiovanni-Vincentelli
    and Sanjit A Seshia and Kurt Keutzer
  venue: ''
  year: ''
  citations: 304
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:4MWp96NkSFoC
  abstract: Large-scale labeled training datasets have enabled deep neural networks
    to excel across a wide range of benchmark vision tasks. However, in many applications,
    it is prohibitively expensive and time-consuming to obtain large quantities of
    labeled data. To cope with limited labeled training data, many have attempted
    to directly apply models trained on a large-scale labeled source domain to another
    sparsely labeled or unlabeled target domain. Unfortunately, direct transfer across
    domains often performs poorly due to the presence of  domain shift  or  dataset
    bias . Domain adaptation (DA) is a machine learning paradigm that aims to learn
    a model from a source domain that can perform well on a different (but related)
    target domain. In this article, we review the latest single-source deep unsupervised
    DA methods focused on visual tasks and discuss new perspectives for future research.
    We begin with the definitions …
- title: 'Chatbot arena: An open platform for evaluating llms by human preference'
  authors: Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas
    Angelopoulos and Tianle Li and Dacheng Li and Hao Zhang and Banghua Zhu and Michael
    Jordan and Joseph E Gonzalez and Ion Stoica
  venue: arXiv preprint arXiv:2403.04132
  year: ''
  citations: 300
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:otzGkya1bYkC
  abstract: Large Language Models (LLMs) have unlocked new capabilities and applications;
    however, evaluating the alignment with human preferences still poses significant
    challenges. To address this issue, we introduce Chatbot Arena, an open platform
    for evaluating LLMs based on human preferences. Our methodology employs a pairwise
    comparison approach and leverages input from a diverse user base through crowdsourcing.
    The platform has been operational for several months, amassing over 240K votes.
    This paper describes the platform, analyzes the data we have collected so far,
    and explains the tried-and-true statistical methods we are using for efficient
    and accurate evaluation and ranking of models. We confirm that the crowdsourced
    questions are sufficiently diverse and discriminating and that the crowdsourced
    human votes are in good agreement with those of expert raters. These analyses
    collectively establish a robust foundation for the credibility of Chatbot Arena.
    Because of its unique value and openness, Chatbot Arena has emerged as one of
    the most referenced LLM leaderboards, widely cited by leading LLM developers and
    companies. Our demo is publicly available at \url{https://chat.lmsys.org}.
- title: Representing long-range context for graph neural networks with global attention
  authors: Zhanghao Wu and Paras Jain and Matthew Wright and Azalia Mirhoseini and
    Joseph E Gonzalez and Ion Stoica
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 289
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:LjlpjdlvIbIC
  abstract: Graph neural networks are powerful architectures for structured datasets.
    However, current methods struggle to represent long-range dependencies. Scaling
    the depth or width of GNNs is insufficient to broaden receptive fields as larger
    GNNs encounter optimization instabilities such as vanishing gradients and representation
    oversmoothing, while pooling-based approaches have yet to become as universally
    useful as in computer vision. In this work, we propose the use of Transformer-based
    self-attention to learn long-range pairwise relationships, with a novel “readout”
    mechanism to obtain a global graph embedding. Inspired by recent computer vision
    results that find position-invariant attention performant in learning long-range
    relationships, our method, which we call GraphTrans, applies a permutation-invariant
    Transformer module after a standard GNN module. This simple architecture leads
    to state-of-the-art results on several graph classification tasks, outperforming
    methods that explicitly encode graph structure. Our results suggest that purely-learning-based
    approaches without graph structure may be suitable for learning high-level, long-range
    relationships on graphs. Code for GraphTrans is available at https://github. com/ucbrise/graphtrans.
- title: A berkeley view of systems challenges for ai
  authors: Ion Stoica and Dawn Song and Raluca Ada Popa and David Patterson and Michael
    W Mahoney and Randy Katz and Anthony D Joseph and Michael Jordan and Joseph M
    Hellerstein and Joseph E Gonzalez and Ken Goldberg and Ali Ghodsi and David Culler
    and Pieter Abbeel
  venue: arXiv preprint arXiv:1712.05855
  year: ''
  citations: 283
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:qxL8FJ1GzNcC
  abstract: With the increasing commoditization of computer vision, speech recognition
    and machine translation systems and the widespread deployment of learning-based
    back-end technologies such as digital advertising and intelligent infrastructures,
    AI (Artificial Intelligence) has moved from research labs to production. These
    changes have been made possible by unprecedented levels of data and computation,
    by methodological advances in machine learning, by innovations in systems software
    and architectures, and by the broad accessibility of these technologies. The next
    generation of AI systems promises to accelerate these developments and increasingly
    impact our lives via frequent interactions and making (often mission-critical)
    decisions on our behalf, often in highly personalized contexts. Realizing this
    promise, however, raises daunting challenges. In particular, we need AI systems
    that make timely and safe decisions in unpredictable environments, that are robust
    against sophisticated adversaries, and that can process ever increasing amounts
    of data across organizations and individuals without compromising confidentiality.
    These challenges will be exacerbated by the end of the Moore's Law, which will
    constrain the amount of data these technologies can store and process. In this
    paper, we propose several open research directions in systems, architectures,
    and security that can address these challenges and help unlock AI's potential
    to improve lives and society.
- title: 'What serverless computing is and should become: The next phase of cloud
    computing'
  authors: Johann Schleier-Smith and Vikram Sreekanti and Anurag Khandelwal and Joao
    Carreira and Neeraja J Yadwadkar and Raluca Ada Popa and Joseph E Gonzalez and
    Ion Stoica and David A Patterson
  venue: Communications of the ACM
  year: ''
  citations: 267
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:lmc2jWPfTJgC
  abstract: The evolution that serverless computing represents, the economic forces
    that shape it, why it could fail, and how it might fulfill its potential.
- title: 'Recovery rl: Safe reinforcement learning with learned recovery zones'
  authors: Brijen Thananjeyan and Ashwin Balakrishna and Suraj Nair and Michael Luo
    and Krishnan Srinivasan and Minho Hwang and Joseph E Gonzalez and Julian Ibarz
    and Chelsea Finn and Ken Goldberg
  venue: IEEE Robotics and Automation Letters
  year: ''
  citations: 253
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:LI9QrySNdTsC
  abstract: 'Safety remains a central obstacle preventing widespread use of RL in
    the real world: learning new tasks in uncertain environments requires extensive
    exploration, but safety requires limiting exploration. We propose Recovery RL,
    an algorithm which navigates this tradeoff by (1) leveraging offline data to learn
    about constraint violating zones  before  policy learning and (2)  separating  the
    goals of improving task performance and constraint satisfaction across two policies:
    a task policy that only optimizes the task reward and a recovery policy that guides
    the agent to safety when constraint violation is likely. We evaluate Recovery
    RL on 6 simulation domains, including two contact-rich manipulation tasks and
    an image-based navigation task, and an image-based obstacle avoidance task on
    a physical robot. We compare Recovery RL to 5 prior safe RL methods which jointly
    optimize for task performance and safety via …'
- title: 'MLI: An API for distributed machine learning'
  authors: Evan R Sparks and Ameet Talwalkar and Virginia Smith and Jey Kottalam and
    Xinghao Pan and Joseph Gonzalez and Michael J Franklin and Michael I Jordan and
    Tim Kraska
  venue: 2013 IEEE 13th International Conference on Data Mining
  year: ''
  citations: 247
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ZHo1McVdvXMC
  abstract: MLI is an Application Programming Interface designed to address the challenges
    of building Machine Learning algorithms in a distributed setting based on data-centric
    computing. Its primary goal is to simplify the development of high-performance,
    scalable, distributed algorithms. Our initial results show that, relative to existing
    systems, this interface can be used to build distributed implementations of a
    wide variety of common Machine Learning algorithms with minimal complexity and
    highly competitive performance and scalability.
- title: 'Selecting the best VM across multiple public clouds: a data-driven performance
    modeling approach'
  authors: Neeraja J Yadwadkar and Bharath Hariharan and Joseph E Gonzalez and Burton
    Smith and Randy H Katz
  venue: ''
  year: ''
  citations: 233
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:j3f4tGmQtD8C
  abstract: Users of cloud services are presented with a bewildering choice of VM
    types and the choice of VM can have significant implications on performance and
    cost. In this paper we address the fundamental problem of accurately and economically
    choosing the best VM for a given workload and user goals. To address the problem
    of optimal VM selection, we present PARIS, a data-driven system that uses a novel
    hybrid offline and online data collection and modeling framework to provide accurate
    performance estimates with minimal data collection. PARIS is able to predict workload
    performance for different user-specified metrics, and resulting costs for a wide
    range of VM types and workloads across multiple cloud providers. When compared
    to sophisticated baselines, including collaborative filtering and a linear interpolation
    model using measured workload performance on two VM types, PARIS produces significantly
    …
- title: 'NBDT: Neural-backed decision trees'
  authors: Alvin Wan and Lisa Dunlap and Daniel Ho and Jihan Yin and Scott Lee and
    Henry Jin and Suzanne Petryk and Sarah Adel Bargal and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2004.00221
  year: ''
  citations: 205
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:W7OEmFMy1HYC
  abstract: 'Machine learning applications such as finance and medicine demand accurate
    and justifiable predictions, barring most deep learning methods from use. In response,
    previous work combines decision trees with deep learning, yielding models that
    (1) sacrifice interpretability for accuracy or (2) sacrifice accuracy for interpretability.
    We forgo this dilemma by jointly improving accuracy and interpretability using
    Neural-Backed Decision Trees (NBDTs). NBDTs replace a neural network''s final
    linear layer with a differentiable sequence of decisions and a surrogate loss.
    This forces the model to learn high-level concepts and lessens reliance on highly-uncertain
    decisions, yielding (1) accuracy: NBDTs match or outperform modern neural networks
    on CIFAR, ImageNet and better generalize to unseen classes by up to 16%. Furthermore,
    our surrogate loss improves the original model''s accuracy by up to 2%. NBDTs
    also afford (2) interpretability: improving human trustby clearly identifying
    model mistakes and assisting in dataset debugging. Code and pretrained NBDTs are
    at https://github.com/alvinwan/neural-backed-decision-trees.'
- title: 'Ray rllib: A composable and scalable reinforcement learning library'
  authors: Eric Liang and Richard Liaw and Robert Nishihara and Philipp Moritz and
    Roy Fox and Joseph Gonzalez and Ken Goldberg and Ion Stoica
  venue: arXiv preprint arXiv:1712.09381
  year: ''
  citations: 202
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:bFI3QPDXJZMC
  abstract: Reinforcement learning (RL) algorithms involve the deep nesting of distinct
    components, where each component typically exhibits opportunities for distributed
    computation. Current RL libraries offer parallelism at the level of the entire
    program, coupling all the components together and making existing implementations
    difficult to extend, combine, and reuse. We argue for building composable RL components
    by encapsulating parallelism and resource requirements within individual components,
    which can be achieved by building on top of a flexible task-based programming
    model. We demonstrate this principle by building Ray RLlib 1 on top of Ray [41]
    and show that we can implement a wide range of state-of-the-art algorithms by
    composing and reusing a handful of standard components. This composability does
    not come at the cost of performance—in our experiments, RLlib matches or exceeds
    the performance of highly optimized reference implementations.
- title: 'Checkmate: Breaking the memory wall with optimal tensor rematerialization'
  authors: Paras Jain and Ajay Jain and Aniruddha Nrusimha and Amir Gholami and Pieter
    Abbeel and Joseph Gonzalez and Kurt Keutzer and Ion Stoica
  venue: Proceedings of Machine Learning and Systems
  year: ''
  citations: 196
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:xtRiw3GOFMkC
  abstract: Modern neural networks are increasingly bottlenecked by the limited capacity
    of on-device GPU memory. Prior work explores dropping activations as a strategy
    to scale to larger neural networks with fixed memory. However, these heuristics
    assume uniform cost per layer and only consider simple linear chain architectures,
    limiting their usability. In this paper, we formalize the problem of trading-off
    computation time and memory requirements for DNN training as the tensor rematerialization
    optimization problem. We develop a new system to optimally solve the problem in
    reasonable times (under an hour) using off-the-shelf MILP solvers. These schedules
    subsequently accelerate millions of training iterations. Our optimization pass
    in TensorFlow 2.0 automatically yields real training speedups of up to 4.8 x over
    prior work, and can enable up to 5x increase in input size for real-world large
    networks.
- title: 'Parallel gibbs sampling: From colored fields to thin junction trees'
  authors: Joseph Gonzalez and Yucheng Low and Arthur Gretton and Carlos Guestrin
  venue: Proceedings of the Fourteenth International Conference on Artificial Intelligence
    and Statistics
  year: ''
  citations: 193
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:u-x6o8ySG0sC
  abstract: We explore the task of constructing a parallel Gibbs sampler, to both
    improve mixing and the exploration of high likelihood states. Recent work in parallel
    Gibbs sampling has focused on update schedules which do not guarantee convergence
    to the intended stationary distribution. In this work, we propose two methods
    to construct parallel Gibbs samplers guaranteed to draw from the targeted distribution.
    The first method, called the Chromatic sampler, uses graph coloring to construct
    a direct parallelization of the classic sequential scan Gibbs sampler. In the
    case of 2-colorable models we relate the Chromatic sampler to the Synchronous
    Gibbs sampler (which draws all variables simultaneously in parallel), and reveal
    new ergodic properties of Synchronous Gibbs chains. Our second method, the Splash
    sampler, is a complementary strategy which can be used when the variables are
    tightly coupled. This constructs and samples multiple blocks in parallel, using
    a novel locking protocol and an iterative junction tree generation algorithm.
    We further improve the Splash sampler through adaptive tree construction. We demonstrate
    the benefits of our two sampling algorithms on large synthetic and real-world
    models using a 32 processor multi-core system.
- title: 'Helen: Maliciously secure coopetitive learning for linear models'
  authors: Wenting Zheng and Raluca Ada Popa and Joseph E Gonzalez and Ion Stoica
  venue: 2019 IEEE symposium on security and privacy (SP)
  year: ''
  citations: 188
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:NhqRSupF_l8C
  abstract: Many organizations wish to collaboratively train machine learning models
    on their combined datasets for a common benefit (e.g., better medical research,
    or fraud detection). However, they often cannot share their plaintext datasets
    due to privacy concerns and/or business competition. In this paper, we design
    and build Helen, a system that allows multiple parties to train a linear model
    without revealing their data, a setting we call coopetitive learning. Compared
    to prior secure training systems, Helen protects against a much stronger adversary
    who is malicious and can compromise m−1 out of m parties. Our evaluation shows
    that Helen can achieve up to five orders of magnitude of performance improvement
    when compared to training using an existing state-of-the-art secure multi-party
    computation framework.
- title: Residual splash for optimally parallelizing belief propagation
  authors: Joseph Gonzalez and Yucheng Low and Carlos Guestrin
  venue: Artificial Intelligence and Statistics
  year: ''
  citations: 185
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:5nxA0vEk-isC
  abstract: As computer architectures move towards parallelism we must build a new
    theoretical understanding of parallelism in machine learning. In this paper we
    focus on parallelizing message passing inference algorithms in graphical models.
    We develop a theoretical understanding of the limitations of parallelism in belief
    propagation and bound the optimal achievable running parallel performance on a
    certain class of graphical models. We demonstrate that the fully synchronous parallelization
    of belief propagation is highly inefficient. We provide a new parallel belief
    propagation which achieves optimal performance on a certain class of graphical
    models. Using two challenging real-world problems, we empirically evaluate the
    performance of our algorithm. On the real-world problems, we find that our new
    algorithm achieves near linear performance improvements and out performs alternative
    parallel belief propagation algorithms.
- title: 'Accel: A corrective fusion network for efficient semantic segmentation on
    video'
  authors: Samvit Jain and Xin Wang and Joseph E Gonzalez
  venue: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
  year: ''
  citations: 171
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:_xSYboBqXhAC
  abstract: 'We present Accel, a novel semantic video segmentation system that achieves
    high accuracy at low inference cost by combining the predictions of two network
    branches:(1) a reference branch that extracts high-detail features on a reference
    keyframe, and warps these features forward using frame-to-frame optical flow estimates,
    and (2) an update branch that computes features of adjustable quality on the current
    frame, performing a temporal update at each video frame. The modularity of the
    update branch, where feature subnetworks of varying layer depth can be inserted
    (eg ResNet-18 to ResNet-101), enables operation over a new, state-of-the-art accuracy-throughput
    trade-off spectrum. Over this curve, Accel models achieve both higher accuracy
    and faster inference times than the closest comparable single-frame segmentation
    networks. In general, Accel significantly outperforms previous work on efficient
    semantic video segmentation, correcting warping-related error that compounds on
    datasets with complex dynamics. Accel is end-to-end trainable and highly modular:
    the reference network, the optical flow network, and the update network can each
    be selected independently, depending on application requirements, and then jointly
    fine-tuned. The result is a robust, general system for fast, high-accuracy semantic
    segmentation on video.'
- title: Contrastive code representation learning
  authors: Paras Jain and Ajay Jain and Tianjun Zhang and Pieter Abbeel and Joseph
    E Gonzalez and Ion Stoica
  venue: arXiv preprint arXiv:2007.04973
  year: ''
  citations: 154
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:B3FOqHPlNUQC
  abstract: 'Recent work learns contextual representations of source code by reconstructing
    tokens from their context. For downstream semantic understanding tasks like summarizing
    code in English, these representations should ideally capture program functionality.
    However, we show that the popular reconstruction-based BERT model is sensitive
    to source code edits, even when the edits preserve semantics. We propose ContraCode:
    a contrastive pre-training task that learns code functionality, not form. ContraCode
    pre-trains a neural network to identify functionally similar variants of a program
    among many non-equivalent distractors. We scalably generate these variants using
    an automated source-to-source compiler as a form of data augmentation. Contrastive
    pre-training improves JavaScript summarization and TypeScript type inference accuracy
    by 2% to 13%. We also propose a new zero-shot JavaScript code clone detection
    dataset, showing that ContraCode is both more robust and semantically meaningful.
    On it, we outperform RoBERTa by 39% AUROC in an adversarial setting and up to
    5% on natural code.'
- title: 'Tafe-net: Task-aware feature embeddings for low shot learning'
  authors: Xin Wang and Fisher Yu and Ruth Wang and Trevor Darrell and Joseph E Gonzalez
  venue: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition
  year: ''
  citations: 146
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:IWHjjKOFINEC
  abstract: Learning good feature embeddings for images often requires substantial
    training data. As a consequence, in settings where training data is limited (eg,
    few-shot and zero-shot learning), we are typically forced to use a general feature
    embedding across prediction tasks. Ideally, we would like to construct feature
    embeddings that are tuned for the given task and even input image. In this work,
    we propose Task Aware Feature Embedding Networks (TAFE-Nets) to learn how to adapt
    the image representation to a new task in a meta learning fashion. Our network
    is composed of a meta learner and a prediction network, where the meta learner
    generates parameters for the feature layers in the prediction network based on
    a task input so that the feature embedding can be accurately adjusted for that
    task. We show that TAFE-Net is highly effective in generalizing to new tasks or
    concepts and evaluate the TAFE-Net on a range of benchmarks in zero-shot and few-shot
    learning. Our model matches or exceeds the state-of-the-art on all tasks. In particular,
    our approach improves the prediction accuracy of unseen attribute-object pairs
    by 4 to 15 points on the challenging visual attribute-object composition task.
- title: 'Neurotoxin: Durable backdoors in federated learning'
  authors: Zhengming Zhang and Ashwinee Panda and Linyue Song and Yaoqing Yang and
    Michael Mahoney and Prateek Mittal and Ramchandran Kannan and Joseph Gonzalez
  venue: International Conference on Machine Learning
  year: ''
  citations: 143
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:AvfA0Oy_GE0C
  abstract: 'Federated learning (FL) systems have an inherent vulnerability to adversarial
    backdoor attacks during training due to their decentralized nature. The goal of
    the attacker is to implant backdoors in the learned model with poisoned updates
    such that at test time, the model’s outputs can be fixed to a given target for
    certain inputs (eg, if a user types “people from New York” into a mobile keyboard
    app that uses a backdoored next word prediction model, the model will autocomplete
    their sentence to “people in New York are rude”). Prior work has shown that backdoors
    can be inserted in FL, but these backdoors are not durable: they do not remain
    in the model after the attacker stops uploading poisoned updates because training
    continues, and in production FL systems an inserted backdoor may not survive until
    deployment. We propose Neurotoxin, a simple one-line backdoor attack that functions
    by attacking parameters that are changed less in magnitude during training. We
    conduct an exhaustive evaluation across ten natural language processing and computer
    vision tasks and find that we can double the durability of state of the art backdoors
    by adding a single line with Neurotoxin.'
- title: Learning rope manipulation policies using dense object descriptors trained
    on synthetic depth data
  authors: Priya Sundaresan and Jennifer Grannen and Brijen Thananjeyan and Ashwin
    Balakrishna and Michael Laskey and Kevin Stone and Joseph E Gonzalez and Ken Goldberg
  venue: 2020 IEEE International Conference on Robotics and Automation (ICRA)
  year: ''
  citations: 143
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:aqlVkmm33-oC
  abstract: Robotic manipulation of deformable 1D objects such as ropes, cables, and
    hoses is challenging due to the lack of high-fidelity analytic models and large
    configuration spaces. Furthermore, learning end-to-end manipulation policies directly
    from images and physical interaction requires significant time on a robot and
    can fail to generalize across tasks. We address these challenges using interpretable
    deep visual representations for rope, extending recent work on dense object descriptors
    for robot manipulation. This facilitates the design of interpretable and transferable
    geometric policies built on top of the learned representations, decoupling visual
    reasoning and control. We present an approach that learns point-pair correspondences
    between initial and goal rope configurations, which implicitly encodes geometric
    structure, entirely in simulation from synthetic depth images. We demonstrate
    that the learned …
- title: 'InferLine: latency-aware provisioning and scaling for prediction serving
    pipelines'
  authors: Daniel Crankshaw and Gur-Eyal Sela and Xiangxi Mo and Corey Zumar and Ion
    Stoica and Joseph Gonzalez and Alexey Tumanov
  venue: ''
  year: ''
  citations: 136
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:XoXfffV-tXoC
  abstract: Serving ML prediction pipelines spanning multiple models and hardware
    accelerators is a key challenge in production machine learning. Optimally configuring
    these pipelines to meet tight end-to-end latency goals is complicated by the interaction
    between model batch size, the choice of hardware accelerator, and variation in
    the query arrival process.In this paper we introduce InferLine, a system which
    provisions and manages the individual stages of prediction pipelines to meet end-to-end
    tail latency constraints while minimizing cost. InferLine consists of a low-frequency
    combinatorial planner and a high-frequency auto-scaling tuner. The low-frequency
    planner leverages stage-wise profiling, discrete event simulation, and constrained
    combinatorial search to automatically select hardware type, replication, and batching
    parameters for each stage in the pipeline. The high-frequency tuner uses network
    calculus to …
- title: 'Idk cascades: Fast deep learning by learning not to overthink'
  authors: Xin Wang and Yujia Luo and Daniel Crankshaw and Alexey Tumanov and Fisher
    Yu and Joseph E Gonzalez
  venue: arXiv preprint arXiv:1706.00885
  year: ''
  citations: 134
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:roLk4NBRz8UC
  abstract: Advances in deep learning have led to substantial increases in prediction
    accuracy but have been accompanied by increases in the cost of rendering predictions.
    We conjecture that fora majority of real-world inputs, the recent advances in
    deep learning have created models that effectively "overthink" on simple inputs.
    In this paper, we revisit the classic question of building model cascades that
    primarily leverage class asymmetry to reduce cost. We introduce the "I Don't Know"(IDK)
    prediction cascades framework, a general framework to systematically compose a
    set of pre-trained models to accelerate inference without a loss in prediction
    accuracy. We propose two search based methods for constructing cascades as well
    as a new cost-aware objective within this framework. The proposed IDK cascade
    framework can be easily adopted in the existing model serving systems without
    additional model re-training. We evaluate the proposed techniques on a range of
    benchmarks to demonstrate the effectiveness of the proposed framework.
- title: 'The missing piece in complex analytics: Low latency, scalable model management
    and serving with velox'
  authors: Daniel Crankshaw and Peter Bailis and Joseph E Gonzalez and Haoyuan Li
    and Zhao Zhang and Michael J Franklin and Ali Ghodsi and Michael I Jordan
  venue: arXiv preprint arXiv:1409.3809
  year: ''
  citations: 131
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:70eg2SAEIzsC
  abstract: 'To support complex data-intensive applications such as personalized recommendations,
    targeted advertising, and intelligent services, the data management community
    has focused heavily on the design of systems to support training complex models
    on large datasets. Unfortunately, the design of these systems largely ignores
    a critical component of the overall analytics process: the deployment and serving
    of models at scale. In this work, we present Velox, a new component of the Berkeley
    Data Analytics Stack. Velox is a data management system for facilitating the next
    steps in real-world, large-scale analytics pipelines: online model management,
    maintenance, and serving. Velox provides end-user applications and services with
    a low-latency, intuitive interface to models, transforming the raw statistical
    models currently trained using existing offline large-scale compute frameworks
    into full-blown, end-to-end data products capable of recommending products, targeting
    advertisements, and personalizing web content. To provide up-to-date results for
    these complex models, Velox also facilitates lightweight online model maintenance
    and selection (i.e., dynamic weighting). In this paper, we describe the challenges
    and architectural considerations required to achieve this functionality, including
    the abilities to span online and offline systems, to adaptively adjust model materialization
    strategies, and to exploit inherent statistical properties such as model error
    tolerance, all while operating at "Big Data" scale.'
- title: Standards for graph algorithm primitives
  authors: Tim Mattson and David Bader and Jon Berry and Aydin Buluc and Jack Dongarra
    and Christos Faloutsos and John Feo and John Gilbert and Joseph Gonzalez and Bruce
    Hendrickson and Jeremy Kepner and Charles Leiserson and Andrew Lumsdaine and David
    Padua and Stephen Poole and Steve Reinhardt and Mike Stonebraker and Steve Wallach
    and Andrew Yoo
  venue: 2013 IEEE High Performance Extreme Computing Conference (HPEC)
  year: ''
  citations: 129
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:M05iB0D1s5AC
  abstract: It is our view that the state of the art in constructing a large collection
    of graph algorithms in terms of linear algebraic operations is mature enough to
    support the emergence of a standard set of primitive building blocks. This paper
    is a position paper defining the problem and announcing our intention to launch
    an open effort to define this standard.
- title: 'Ground: A Data Context Service.'
  authors: Joseph M Hellerstein and Vikram Sreekanti and Joseph E Gonzalez and James
    Dalton and Akon Dey and Sreyashi Nag and Krishna Ramachandran and Sudhanshu Arora
    and Arka Bhattacharyya and Shirshanka Das and Mark Donsky and Gabriel Fierro and
    Chang She and Carl Steinbach and Venkat Subramanian and Eric Sun
  venue: CIDR
  year: ''
  citations: 128
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:zA6iFVUQeVQC
  abstract: 'Ground is an open-source data context service, a system to manage all
    the information that informs the use of data. Data usage has changed both philosophically
    and practically in the last decade, creating an opportunity for new data context
    services to foster further innovation. In this paper we frame the challenges of
    managing data context with basic ABCs: Applications, Behavior, and Change. We
    provide motivation and design guidelines, present our initial design of a common
    metamodel and API, and explore the current state of the storage solutions that
    could serve the needs of a data context service. Along the way we highlight opportunities
    for new research and engineering solutions.'
- title: 'Graphframes: an integrated api for mixing graph and relational queries'
  authors: Ankur Dave and Alekh Jindal and Li Erran Li and Reynold Xin and Joseph
    Gonzalez and Matei Zaharia
  venue: ''
  year: ''
  citations: 127
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:hqOjcs7Dif8C
  abstract: Graph data is prevalent in many domains, but it has usually required specialized
    engines to analyze. This design is onerous for users and precludes optimization
    across complete workflows. We present GraphFrames, an integrated system that lets
    users combine graph algorithms, pattern matching and relational queries, and optimizes
    work across them. GraphFrames generalize the ideas in previous graph-on-RDBMS
    systems, such as GraphX and Vertexica, by letting the system materialize multiple
    views of the graph (not just the specific triplet views in these systems) and
    executing both iterative algorithms and pattern matching using joins. To make
    applications easy to write, GraphFrames provide a concise, declarative API based
    on the "data frame" concept in R that can be used for both interactive queries
    and standalone programs. Under this API, GraphFrames use a graph-aware join optimization
    algorithm …
- title: 'Fbnetv3: Joint architecture-recipe search using predictor pretraining'
  authors: Xiaoliang Dai and Alvin Wan and Peizhao Zhang and Bichen Wu and Zijian
    He and Zhen Wei and Kan Chen and Yuandong Tian and Matthew Yu and Peter Vajda
    and Joseph E Gonzalez
  venue: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
  year: ''
  citations: 126
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:epqYDVWIO7EC
  abstract: Neural Architecture Search (NAS) yields state-of-the-art neural networks
    that outperform their best manually-designed counterparts. However, previous NAS
    methods search for architectures under one set of training hyper-parameters (ie,
    a training recipe), overlooking superior architecture-recipe combinations. To
    address this, we present Neural Architecture-Recipe Search (NARS) to search both
    (a) architectures and (b) their corresponding training recipes, simultaneously.
    NARS utilizes an accuracy predictor that scores architecture and training recipes
    jointly, guiding both sample selection and ranking. Furthermore, to compensate
    for the enlarged search space, we leverage" free" architecture statistics (eg,
    FLOP count) to pretrain the predictor, significantly improving its sample efficiency
    and prediction reliability. After training the predictor via constrained iterative
    optimization, we run fast evolutionary searches in just CPU minutes to generate
    architecture-recipe pairs for a variety of resource constraints, called FBNetV3.
    FBNetV3 makes up a family of state-of-the-art compact neural networks that outperform
    both automatically and manually-designed competitors. For example, FBNetV3 matches
    both EfficientNet and ResNeSt accuracy on ImageNet with up to 2.0 x and 7.1 x
    fewer FLOPs, respectively. Furthermore, FBNetV3 yields significant performance
    gains for downstream object detection tasks, improving mAP despite 18% fewer FLOPs
    and 34% fewer parameters than EfficientNet-based equivalents.
- title: 'Graphx: Unifying data-parallel and graph-parallel analytics'
  authors: Reynold S Xin and Daniel Crankshaw and Ankur Dave and Joseph E Gonzalez
    and Michael J Franklin and Ion Stoica
  venue: arXiv preprint arXiv:1402.2394
  year: ''
  citations: 126
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:JV2RwH3_ST0C
  abstract: 'From social networks to language modeling, the growing scale and importance
    of graph data has driven the development of numerous new graph-parallel systems
    (e.g., Pregel, GraphLab). By restricting the computation that can be expressed
    and introducing new techniques to partition and distribute the graph, these systems
    can efficiently execute iterative graph algorithms orders of magnitude faster
    than more general data-parallel systems. However, the same restrictions that enable
    the performance gains also make it difficult to express many of the important
    stages in a typical graph-analytics pipeline: constructing the graph, modifying
    its structure, or expressing computation that spans multiple graphs. As a consequence,
    existing graph analytics pipelines compose graph-parallel and data-parallel systems
    using external storage systems, leading to extensive data movement and complicated
    programming model. To address these challenges we introduce GraphX, a distributed
    graph computation framework that unifies graph-parallel and data-parallel computation.
    GraphX provides a small, core set of graph-parallel operators expressive enough
    to implement the Pregel and PowerGraph abstractions, yet simple enough to be cast
    in relational algebra. GraphX uses a collection of query optimization techniques
    such as automatic join rewrites to efficiently implement these graph-parallel
    operators. We evaluate GraphX on real-world graphs and workloads and demonstrate
    that GraphX achieves comparable performance as specialized graph computation systems,
    while outperforming them in end-to-end graph pipelines. Moreover, GraphX achieves
    a …'
- title: '{AlpaServe}: Statistical multiplexing with model parallelism for deep learning
    serving'
  authors: Zhuohan Li and Lianmin Zheng and Yinmin Zhong and Vincent Liu and Ying
    Sheng and Xin Jin and Yanping Huang and Zhifeng Chen and Hao Zhang and Joseph
    E Gonzalez and Ion Stoica
  venue: 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI
    23)
  year: ''
  citations: 122
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:bKqednn6t2AC
  abstract: Model parallelism is conventionally viewed as a method to scale a single
    large deep learning model beyond the memory limits of a single device. In this
    paper, we demonstrate that model parallelism can be additionally used for the
    statistical multiplexing of multiple devices when serving multiple models, even
    when a single model can fit into a single device. Our work reveals a fundamental
    trade-off between the overhead introduced by model parallelism and the opportunity
    to exploit statistical multiplexing to reduce serving latency in the presence
    of bursty workloads. We explore the new trade-off space and present a novel serving
    system, AlpaServe, that determines an efficient strategy for placing and parallelizing
    collections of large deep learning models across a distributed cluster. Evaluation
    results on production workloads show that AlpaServe can process requests at up
    to 10× higher rates or 6× more burstiness while staying within latency constraints
    for more than 99% of requests.
- title: Deep mixture of experts via shallow embedding
  authors: Xin Wang and Fisher Yu and Lisa Dunlap and Yi-An Ma and Ruth Wang and Azalia
    Mirhoseini and Trevor Darrell and Joseph E Gonzalez
  venue: Uncertainty in artificial intelligence
  year: ''
  citations: 122
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:KlAtU1dfN6UC
  abstract: Larger networks generally have greater representational power at the cost
    of increased computational complexity. Sparsifying such networks has been an active
    area of research but has been generally limited to static regularization or dynamic
    approaches using reinforcement learning. We explore a mixture of experts (MoE)
    approach to deep dynamic routing, which activates certain experts in the network
    on a per-example basis. Our novel DeepMoE architecture increases the representational
    power of standard convolutional networks by adaptively sparsifying and recalibrating
    channel-wise features in each convolutional layer. We employ a multi-headed sparse
    gating network to determine the selection and scaling of channels for each input,
    leveraging exponential combinations of experts within a single convolutional network.
    Our proposed architecture is evaluated on four benchmark datasets and tasks, and
    we show that Deep-MoEs are able to achieve higher accuracy with lower computation
    than standard convolutional networks.
- title: Towards scalable dataframe systems
  authors: Devin Petersohn and Stephen Macke and Doris Xin and William Ma and Doris
    Lee and Xiangxi Mo and Joseph E Gonzalez and Joseph M Hellerstein and Anthony
    D Joseph and Aditya Parameswaran
  venue: arXiv preprint arXiv:2001.00888
  year: ''
  citations: 119
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:NMxIlDl6LWMC
  abstract: Dataframes are a popular abstraction to represent, prepare, and analyze
    data. Despite the remarkable success of dataframe libraries in Rand Python, dataframes
    face performance issues even on moderately large datasets. Moreover, there is
    significant ambiguity regarding dataframe semantics. In this paper we lay out
    a vision and roadmap for scalable dataframe systems. To demonstrate the potential
    in this area, we report on our experience building MODIN, a scaled-up implementation
    of the most widely-used and complex dataframe API today, Python's pandas. With
    pandas as a reference, we propose a simple data model and algebra for dataframes
    to ground discussion in the field. Given this foundation, we lay out an agenda
    of open research opportunities where the distinct features of dataframes will
    require extending the state of the art in many dimensions of data management.
    We discuss the implications of signature data-frame features including flexible
    schemas, ordering, row/column equivalence, and data/metadata fluidity, as well
    as the piecemeal, trial-and-error-based approach to interacting with dataframes.
- title: 'Safety augmented value estimation from demonstrations (saved): Safe deep
    model-based rl for sparse cost robotic tasks'
  authors: Brijen Thananjeyan and Ashwin Balakrishna and Ugo Rosolia and Felix Li
    and Rowan McAllister and Joseph E Gonzalez and Sergey Levine and Francesco Borrelli
    and Ken Goldberg
  venue: IEEE Robotics and Automation Letters
  year: ''
  citations: 117
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:q3oQSFYPqjQC
  abstract: Reinforcement learning (RL) for robotics is challenging due to the difficulty
    in hand-engineering a dense cost function, which can lead to unintended behavior,
    and dynamical uncertainty, which makes exploration and constraint satisfaction
    challenging. We address these issues with a new model-based reinforcement learning
    algorithm, Safety Augmented Value Estimation from Demonstrations (SAVED), which
    uses supervision that only identifies task completion and a modest set of suboptimal
    demonstrations to constrain exploration and learn efficiently while handling complex
    constraints. We then compare SAVED with 3 state-of-the-art model-based and model-free
    RL algorithms on 6 standard simulation benchmarks involving navigation and manipulation
    and a physical knot-tying task on the da Vinci surgical robot. Results suggest
    that SAVED outperforms prior methods in terms of success rate, constraint …
- title: 'Tempera: Test-time prompting via reinforcement learning'
  authors: Tianjun Zhang and Xuezhi Wang and Denny Zhou and Dale Schuurmans and Joseph
    E Gonzalez
  venue: arXiv preprint arXiv:2211.11890
  year: ''
  citations: 112
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:IRz6iEL74y4C
  abstract: Careful prompt design is critical to the use of large language models
    in zero-shot or few-shot learning. As a consequence, there is a growing interest
    in automated methods to design optimal prompts. In this work, we propose Test-time
    Prompt Editing using Reinforcement learning (TEMPERA). In contrast to prior prompt
    generation methods, TEMPERA can efficiently leverage prior knowledge, is adaptive
    to different queries and provides an interpretable prompt for every query. To
    achieve this, we design a novel action space that allows flexible editing of the
    initial prompts covering a wide set of commonly-used components like instructions,
    few-shot exemplars, and verbalizers. The proposed method achieves significant
    gains compared with recent SoTA approaches like prompt tuning, AutoPrompt, and
    RLPrompt, across a variety of tasks including sentiment analysis, topic classification,
    natural language inference, and reading comprehension. Our method achieves 5.33x
    on average improvement in sample efficiency when compared to the traditional fine-tuning
    methods.
- title: 'Ace: Adapting to changing environments for semantic segmentation'
  authors: Zuxuan Wu and Xin Wang and Joseph E Gonzalez and Tom Goldstein and Larry
    S Davis
  venue: Proceedings of the IEEE/CVF international conference on computer vision
  year: ''
  citations: 112
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:qUcmZB5y_30C
  abstract: Deep neural networks exhibit exceptional accuracy when they are trained
    and tested on the same data distributions. However, neural classifiers are often
    extremely brittle when confronted with domain shift---changes in the input distribution
    that occur over time. We present ACE, a framework for semantic segmentation that
    dynamically adapts to changing environments over time. By aligning the distribution
    of labeled training data from the original source domain with the distribution
    of incoming data in a shifted domain, ACE synthesizes labeled training data for
    environments as it sees them. This stylized data is then used to update a segmentation
    model so that it performs well in new environments. To avoid forgetting knowledge
    from past environments, we introduce a memory that stores feature statistics from
    previously seen domains. These statistics can be used to replay images in any
    of the previously observed domains, thus preventing catastrophic forgetting. In
    addition to standard batch training using stochastic gradient decent (SGD), we
    also experiment with fast adaptation methods based on adaptive meta-learning.
    Extensive experiments are conducted on two datasets from SYNTHIA, the results
    demonstrate the effectiveness of the proposed approach when adapting to a number
    of tasks.
- title: 'Spatula: Efficient cross-camera video analytics on large camera networks'
  authors: Samvit Jain and Xun Zhang and Yuhao Zhou and Ganesh Ananthanarayanan and
    Junchen Jiang and Yuanchao Shu and Paramvir Bahl and Joseph Gonzalez
  venue: 2020 IEEE/ACM Symposium on Edge Computing (SEC)
  year: ''
  citations: 110
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:q3CdL3IzO_QC
  abstract: Cameras are deployed at scale with the purpose of searching and tracking
    objects of interest (e.g., a suspected person) through the camera network on live
    videos. Such cross-camera analytics is data and compute intensive, whose costs
    grow with the number of cameras and time. We present Spatula, a cost-efficient
    system that enables scaling cross-camera analytics on edge compute boxes to large
    camera networks by leveraging the spatial and temporal cross-camera correlations.
    While such correlations have been used in computer vision community, Spatula uses
    them to drastically reduce the communication and computation costs by pruning
    search space of a query identity (e.g., ignoring frames not correlated with the
    query identity’s current position). Spatula provides the first system substrate
    on which cross-camera analytics applications can be built to efficiently harness
    the cross-camera correlations that are abundant …
- title: 'ANODEV2: A coupled neural ODE framework'
  authors: Tianjun Zhang and Zhewei Yao and Amir Gholami and Joseph E Gonzalez and
    Kurt Keutzer and Michael W Mahoney and George Biros
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 105
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:08ZZubdj9fEC
  abstract: It has been observed that residual networks can be viewed as the explicit
    Euler discretization of an Ordinary Differential Equation (ODE). This observation
    motivated the introduction of so-called Neural ODEs, in which other discretization
    schemes and/or adaptive time stepping techniques can be used to improve the performance
    of residual networks. Here, we propose\OURS, which extends this approach by introducing
    a framework that allows ODE-based evolution for both the weights and the activations,
    in a coupled formulation. Such an approach provides more modeling flexibility,
    and it can help with generalization performance. We present the formulation of\OURS,
    derive optimality conditions, and implement the coupled framework in PyTorch.
    We present empirical results using several different configurations of\OURS, testing
    them on the CIFAR-10 dataset. We report results showing that our coupled ODE-based
    framework is indeed trainable, and that it achieves higher accuracy, compared
    to the baseline ResNet network and the recently-proposed Neural ODE approach.
- title: 'Raft: Adapting language model to domain specific rag'
  authors: Tianjun Zhang and Shishir G Patil and Naman Jain and Sheng Shen and Matei
    Zaharia and Ion Stoica and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2403.10131
  year: ''
  citations: 102
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:48xauSegjOkC
  abstract: Pretraining Large Language Models (LLMs) on large corpora of textual data
    is now a standard paradigm. When using these LLMs for many downstream applications,
    it is common to additionally bake in new knowledge (e.g., time-critical news,
    or private domain knowledge) into the pretrained model either through RAG-based-prompting,
    or fine-tuning. However, the optimal methodology for the model to gain such new
    knowledge remains an open question. In this paper, we present Retrieval Augmented
    FineTuning (RAFT), a training recipe that improves the model's ability to answer
    questions in a "open-book" in-domain settings. In RAFT, given a question, and
    a set of retrieved documents, we train the model to ignore those documents that
    don't help in answering the question, which we call, distractor documents. RAFT
    accomplishes this by citing verbatim the right sequence from the relevant document
    that would help answer the question. This coupled with RAFT's chain-of-thought-style
    response helps improve the model's ability to reason. In domain-specific RAG,
    RAFT consistently improves the model's performance across PubMed, HotpotQA, and
    Gorilla datasets, presenting a post-training recipe to improve pre-trained LLMs
    to in-domain RAG. RAFT's code and demo are open-sourced at github.com/ShishirPatil/gorilla.
- title: 'A fog robotics approach to deep robot learning: Application to object recognition
    and grasp planning in surface decluttering'
  authors: Ajay Kumar Tanwani and Nitesh Mor and John Kubiatowicz and Joseph E Gonzalez
    and Ken Goldberg
  venue: 2019 international conference on robotics and automation (ICRA)
  year: ''
  citations: 102
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:g5m5HwL7SMYC
  abstract: The growing demand of industrial, automotive and service robots presents
    a challenge to the centralized Cloud Robotics model in terms of privacy, security,
    latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics'
    approach to deep robot learning that distributes compute, storage and networking
    resources between the Cloud and the Edge in a federated manner. Deep models are
    trained on non-private (public) synthetic images in the Cloud; the models are
    adapted to the private real images of the environment at the Edge within a trusted
    network and subsequently, deployed as a service for low-latency and secure inference/prediction
    for other robots in the network. We apply this approach to surface decluttering,
    where a mobile robot picks and sorts objects from a cluttered floor by learning
    a deep object recognition and a grasp planning model. Experiments suggest that
    Fog Robotics can improve …
- title: 'Memgpt: Towards llms as operating systems'
  authors: Charles Packer and Sarah Wooders and Kevin Lin and Vivian Fang and Shishir
    G Patil and Ion Stoica and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2310.08560
  year: ''
  citations: 100
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:5icHVeHT4IsC
  abstract: 'Large language models (LLMs) have revolutionized AI, but are constrained
    by limited context windows, hindering their utility in tasks like extended conversations
    and document analysis. To enable using context beyond limited context windows,
    we propose virtual context management, a technique drawing inspiration from hierarchical
    memory systems in traditional operating systems that provide the appearance of
    large memory resources through data movement between fast and slow memory. Using
    this technique, we introduce MemGPT (Memory-GPT), a system that intelligently
    manages different memory tiers in order to effectively provide extended context
    within the LLM''s limited context window, and utilizes interrupts to manage control
    flow between itself and the user. We evaluate our OS-inspired design in two domains
    where the limited context windows of modern LLMs severely handicaps their performance:
    document analysis, where MemGPT is able to analyze large documents that far exceed
    the underlying LLM''s context window, and multi-session chat, where MemGPT can
    create conversational agents that remember, reflect, and evolve dynamically through
    long-term interactions with their users. We release MemGPT code and data for our
    experiments at https://memgpt.ai.'
- title: Improving semi-supervised federated learning by reducing the gradient diversity
    of models
  authors: Zhengming Zhang and Yaoqing Yang and Zhewei Yao and Yujun Yan and Joseph
    E Gonzalez and Kannan Ramchandran and Michael W Mahoney
  venue: 2021 IEEE International Conference on Big Data (Big Data)
  year: ''
  citations: 99
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:p__nRnzSRKYC
  abstract: Federated learning (FL) is a promising way to use the computing power
    of mobile devices while maintaining the privacy of users. Current work in FL,
    however, makes the unrealistic assumption that the users have ground-truth labels
    on their devices, while also assuming that the server has neither data nor labels.
    In this work, we consider the more realistic scenario where the users have only
    unlabeled data, while the server has some labeled data, and where the amount of
    labeled data is smaller than the amount of unlabeled data. We call this learning
    problem semi-supervised federated learning (SSFL). For SSFL, we demonstrate that
    a critical issue that affects the test accuracy is the large gradient diversity
    of the models from different users. Based on this, we investigate several design
    choices. First, we find that the so-called consistency regularization loss (CRL),
    which is widely used in semi-supervised learning …
- title: Performance of a convolutional neural network and explainability technique
    for 12-lead electrocardiogram interpretation
  authors: J Weston Hughes and Jeffrey E Olgin and Robert Avram and Sean A Abreau
    and Taylor Sittler and Kaahan Radia and Henry Hsia and Tomos Walters and Byron
    Lee and Joseph E Gonzalez and Geoffrey H Tison
  venue: JAMA cardiology
  year: ''
  citations: 98
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:N5tVd3kTz84C
  abstract: Millions of clinicians rely daily on automated preliminary electrocardiogram
    (ECG) interpretation. Critical comparisons of machine learning–based automated
    analysis against clinically accepted standards of care are lacking.To use readily
    available 12-lead ECG data to train and apply an explainability technique to a
    convolutional neural network (CNN) that achieves high performance against clinical
    standards of care.This cross-sectional study was conducted using data from January
    1, 2003, to December 31, 2018. Data were obtained in a commonly available 12-lead
    ECG format from a single-center tertiary care institution. All patients aged 18
    years or older who received ECGs at the University of California, San Francisco,
    were included, yielding a total of 365 009 patients. Data were analyzed from January
    1, 2019, to March 2, 2021.A CNN was …
- title: Scaling video analytics systems to large camera deployments
  authors: Samvit Jain and Ganesh Ananthanarayanan and Junchen Jiang and Yuanchao
    Shu and Joseph Gonzalez
  venue: ''
  year: ''
  citations: 98
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:SeFeTyx0c_EC
  abstract: 'Driven by advances in computer vision and the falling costs of camera
    hardware, organizations are deploying video cameras en masse for the spatial monitoring
    of their physical premises. Scaling video analytics to massive camera deployments,
    however, presents a new and mounting challenge, as compute cost grows proportionally
    to the number of camera feeds. This paper is driven by a simple question: can
    we scale video analytics in such a way that cost grows sublinearly, or even remains
    constant, as we deploy more cameras, while inference accuracy remains stable,
    or even improves. We believe the answer is yes. Our key observation is that video
    feeds from wide-area camera deployments demonstrate significant content correlations
    (e.g. to other geographically proximate feeds), both in space and over time. These
    spatio-temporal correlations can be harnessed to dramatically reduce the size
    of the …'
- title: 'Lmsys-chat-1m: A large-scale real-world llm conversation dataset'
  authors: Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Tianle Li and Siyuan
    Zhuang and Zhanghao Wu and Yonghao Zhuang and Zhuohan Li and Zi Lin and Eric P
    Xing and Joseph E Gonzalez and Ion Stoica and Hao Zhang
  venue: arXiv preprint arXiv:2309.11998
  year: ''
  citations: 92
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:lvd772isFD0C
  abstract: 'Studying how people interact with large language models (LLMs) in real-world
    scenarios is increasingly important due to their widespread use in various applications.
    In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one
    million real-world conversations with 25 state-of-the-art LLMs. This dataset is
    collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot
    Arena website. We offer an overview of the dataset''s content, including its curation
    process, basic statistics, and topic distribution, highlighting its diversity,
    originality, and scale. We demonstrate its versatility through four use cases:
    developing content moderation models that perform similarly to GPT-4, building
    a safety benchmark, training instruction-following models that perform similarly
    to Vicuna, and creating challenging benchmark questions. We believe that this
    dataset will serve as a valuable resource for understanding and advancing LLM
    capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.'
- title: Dynamic space-time scheduling for gpu inference
  authors: Paras Jain and Xiangxi Mo and Ajay Jain and Harikaran Subbaraj and Rehan
    Sohail Durrani and Alexey Tumanov and Joseph Gonzalez and Ion Stoica
  venue: arXiv preprint arXiv:1901.00041
  year: ''
  citations: 91
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:J_g5lzvAfSwC
  abstract: Serving deep neural networks in latency critical interactive settings
    often requires GPU acceleration. However, the small batch sizes typical in online
    inference results in poor GPU utilization, a potential performance gap which GPU
    resource sharing can address. In this paper, we explore several techniques to
    leverage both temporal and spatial multiplexing to improve GPU utilization for
    deep learning inference workloads. We evaluate the performance trade-offs of each
    approach with respect to resource-efficiency, latency predictability, and isolation
    when compared with conventional batched inference. Our experimental analysis suggests
    at least a 5x potential for improved utilization through the exploration of more
    advanced spatial and temporal multiplexing strategies. Our preliminary prototype
    of a dynamic space-time scheduler demonstrates a 3.18 x speedup over space-only
    multiplexing and a 7.76 x speedup over time-only multiplexing, while also providing
    better isolation and latency predictability.
- title: Distributed parallel inference on large factor graphs
  authors: Joseph E Gonzalez and Yucheng Low and Carlos E Guestrin and David O'Hallaron
  venue: arXiv preprint arXiv:1205.2645
  year: ''
  citations: 88
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:-f6ydRqryjwC
  abstract: As computer clusters become more common and the size of the problems encountered
    in the field of AI grows, there is an increasing demand for efficient parallel
    inference algorithms. We consider the problem of parallel inference on large factor
    graphs in the distributed memory setting of computer clusters. We develop a new
    efficient parallel inference algorithm, DBRSplash, which incorporates over-segmented
    graph partitioning, belief residual scheduling, and uniform work Splash operations.
    We empirically evaluate the DBRSplash algorithm on a 120 processor cluster and
    demonstrate linear to super-linear performance gains on large factor graph models.
- title: On the computational inefficiency of large batch sizes for stochastic gradient
    descent
  authors: Noah Golmant and Nikita Vemuri and Zhewei Yao and Vladimir Feinberg and
    Amir Gholami and Kai Rothauge and Michael W Mahoney and Joseph Gonzalez
  venue: arXiv preprint arXiv:1811.12941
  year: ''
  citations: 87
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:9yKSN-GCB0IC
  abstract: Increasing the mini-batch size for stochastic gradient descent offers
    significant opportunities to reduce wall-clock training time, but there are a
    variety of theoretical and systems challenges that impede the widespread success
    of this technique. We investigate these issues, with an emphasis on time to convergence
    and total computational cost, through an extensive empirical analysis of network
    training across several architectures and problem domains, including image classification,
    image segmentation, and language modeling. Although it is common practice to increase
    the batch size in order to fully exploit available computational resources, we
    find a substantially more nuanced picture. Our main finding is that across a wide
    range of network architectures and problem domains, increasing the batch size
    beyond a certain point yields no decrease in wall-clock time to convergence for
    \emph{either} train or test loss. This batch size is usually substantially below
    the capacity of current systems. We show that popular training strategies for
    large batch size optimization begin to fail before we can populate all available
    compute resources, and we show that the point at which these methods break down
    depends more on attributes like model architecture and data complexity than it
    does directly on the size of the dataset.
- title: A fault-tolerance shim for serverless computing
  authors: Vikram Sreekanti and Chenggang Wu and Saurav Chhatrapati and Joseph E Gonzalez
    and Joseph M Hellerstein and Jose M Faleiro
  venue: ''
  year: ''
  citations: 85
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:_kc_bZDykSQC
  abstract: Serverless computing has grown in popularity in recent years, with an
    increasing number of applications being built on Functions-as-a-Service (FaaS)
    platforms. By default, FaaS platforms support retry-based fault tolerance, but
    this is insufficient for programs that modify shared state, as they can unwittingly
    persist partial sets of updates in case of failures. To address this challenge,
    we would like atomic visibility of the updates made by a FaaS application.In this
    paper, we present aft, an atomic fault tolerance shim for serverless applications.
    aft interposes between a commodity FaaS platform and storage engine and ensures
    atomic visibility of updates by enforcing the read atomic isolation guarantee.
    aft supports new protocols to guarantee read atomic isolation in the serverless
    setting. We demonstrate that aft introduces minimal overhead relative to existing
    storage engines and scales smoothly to thousands of …
- title: 'Noveld: A simple yet effective exploration criterion'
  authors: Tianjun Zhang and Huazhe Xu and Xiaolong Wang and Yi Wu and Kurt Keutzer
    and Joseph E Gonzalez and Yuandong Tian
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 81
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ZuybSZzF8UAC
  abstract: Efficient exploration under sparse rewards remains a key challenge in
    deep reinforcement learning. Previous exploration methods (eg, RND) have achieved
    strong results in multiple hard tasks. However, if there are multiple novel areas
    to explore, these methods often focus quickly on one without sufficiently trying
    others (like a depth-wise first search manner). In some scenarios (eg, four corridor
    environment in Sec 4.2), we observe they explore in one corridor for long and
    fail to cover all the states. On the other hand, in theoretical RL, with optimistic
    initialization and the inverse square root of visitation count as a bonus, it
    won't suffer from this and explores different novel regions alternatively (like
    a breadth-first search manner). In this paper, inspired by this, we propose a
    simple but effective criterion called NovelD by weighting every novel area approximately
    equally. Our algorithm is very simple but yet shows comparable performance or
    even outperforms multiple SOTA exploration methods in many hard exploration tasks.
    Specifically, NovelD solves all the static procedurally-generated tasks in Mini-Grid
    with just 120M environment steps, without any curriculum learning. In comparison,
    the previous SOTA only solves 50% of them. NovelD also achieves SOTA on multiple
    tasks in NetHack, a rogue-like game that contains more challenging procedurally-generated
    environments. In multiple Atari games (eg, MonteZuma's Revenge, Venture, Gravitar),
    NovelD outperforms RND. We analyze NovelD thoroughly in MiniGrid and found that
    empirically it helps the agent explore the environment more uniformly with a focus
    on exploring beyond the boundary.
- title: Model-based value expansion for efficient model-free reinforcement learning
  authors: Vladimir Feinberg and Alvin Wan and Ion Stoica and Michael I Jordan and
    Joseph E Gonzalez and Sergey Levine
  venue: Proceedings of the 35th International Conference on Machine Learning (ICML
    2018)
  year: ''
  citations: 77
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:LdasjJ6CEcoC
  abstract: ''
- title: Multi-task learning for straggler avoiding predictive job scheduling
  authors: Neeraja J Yadwadkar and Bharath Hariharan and Joseph E Gonzalez
  venue: Journal of Machine Learning Research
  year: ''
  citations: 77
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:u5HHmVD_uO8C
  abstract: Parallel processing frameworks (Dean and Ghemawat, 2004) accelerate jobs
    by breaking them into tasks that execute in parallel. However, slow running or
    straggler tasks can run up to 8 times slower than the median task on a production
    cluster (Ananthanarayanan et al., 2013), leading to delayed job completion and
    inefficient use of resources. Existing straggler mitigation techniques wait to
    detect stragglers and then relaunch them, delaying straggler detection and wasting
    resources. We built Wrangler (Yadwadkar et al., 2014), a system that predicts
    when stragglers are going to occur and makes scheduling decisions to avoid such
    situations. To capture node and workload variability, Wrangler built separate
    models for every node and workload, requiring the time-consuming collection of
    substantial training data. In this paper, we propose multi-task learning formulations
    that share information between the various models, allowing us to use less training
    data and bring training time down from 4 hours to 40 minutes. Unlike naive multi-task
    learning formulations, our formulations capture the shared structure in our data,
    improving generalization performance on limited data. Finally, we extend these
    formulations using group sparsity inducing norms to automatically discover the
    similarities between tasks and improve interpretability.
- title: 'Pylot: A modular platform for exploring latency-accuracy tradeoffs in autonomous
    vehicles'
  authors: Ionel Gog and Sukrit Kalra and Peter Schafhalter and Matthew A Wright and
    Joseph E Gonzalez and Ion Stoica
  venue: 2021 IEEE International Conference on Robotics and Automation (ICRA)
  year: ''
  citations: 74
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:EkHepimYqZsC
  abstract: We present Pylot, a platform for autonomous vehicle (AV) research and
    development, built with the goal to allow researchers to study the effects of
    the latency and accuracy of their models and algorithms on the end-to-end driving
    behavior of an AV. This is achieved through a modular structure enabled by our
    high-performance dataflow system that represents AV software pipeline components
    (object detectors, motion planners, etc.) as a dataflow graph of operators which
    communicate on data streams using timestamped messages. Pylot readily interfaces
    with popular AV simulators like CARLA, and is easily deployable to real-world
    vehicles with minimal code changes.To reduce the burden of developing an entire
    pipeline for evaluating a single component, Pylot provides several state-of-the-art
    reference implementations for the various components of an AV pipeline. Using
    these reference implementations, a Pylot …
- title: 'Actnn: Reducing training memory footprint via 2-bit activation compressed
    training'
  authors: Jianfei Chen and Lianmin Zheng and Zhewei Yao and Dequan Wang and Ion Stoica
    and Michael Mahoney and Joseph Gonzalez
  venue: International Conference on Machine Learning
  year: ''
  citations: 73
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:oNZyr7d5Mn4C
  abstract: The increasing size of neural network models has been critical for improvements
    in their accuracy, but device memory is not growing at the same rate. This creates
    fundamental challenges for training neural networks within limited memory environments.
    In this work, we propose ActNN, a memory-efficient training framework that stores
    randomly quantized activations for back propagation. We prove the convergence
    of ActNN for general network architectures, and we characterize the impact of
    quantization on the convergence via an exact expression for the gradient variance.
    Using our theory, we propose novel mixed-precision quantization strategies that
    exploit the activation’s heterogeneity across feature dimensions, samples, and
    layers. These techniques can be readily applied to existing dynamic graph frameworks,
    such as PyTorch, simply by substituting the layers. We evaluate ActNN on mainstream
    computer vision models for classification, detection, and segmentation tasks.
    On all these tasks, ActNN compresses the activation to 2 bits on average, with
    negligible accuracy loss. ActNN reduces the memory footprint of the activation
    by 12x, and it enables training with a 6.6 x to 14x larger batch size.
- title: Learning dense visual correspondences in simulation to smooth and fold real
    fabrics
  authors: Aditya Ganapathi and Priya Sundaresan and Brijen Thananjeyan and Ashwin
    Balakrishna and Daniel Seita and Jennifer Grannen and Minho Hwang and Ryan Hoque
    and Joseph E Gonzalez and Nawid Jamali and Katsu Yamane and Soshi Iba and Ken
    Goldberg
  venue: 2021 IEEE International Conference on Robotics and Automation (ICRA)
  year: ''
  citations: 73
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:9Nmd_mFXekcC
  abstract: Robotic fabric manipulation is challenging due to the infinite dimensional
    configuration space, self-occlusion, and complex dynamics of fabrics. There has
    been significant prior work on learning policies for specific fabric manipulation
    tasks, but comparatively less focus on algorithms which can perform many different
    tasks. We take a step towards this goal by learning point-pair correspondences
    across different fabric configurations in simulation. Then, given a single demonstration
    of a new task from an initial fabric configuration, these correspondences can
    be used to compute geometrically equivalent actions in a new fabric configuration.
    This makes it possible to define policies to robustly imitate a broad set of multi-step
    fabric smoothing and folding tasks. The resulting policies achieve 80.3% average
    task success rate across 10 fabric manipulation tasks on two different physical
    robotic systems. Results also suggest …
- title: 'S-lora: Serving thousands of concurrent lora adapters'
  authors: Ying Sheng and Shiyi Cao and Dacheng Li and Coleman Hooper and Nicholas
    Lee and Shuo Yang and Christopher Chou and Banghua Zhu and Lianmin Zheng and Kurt
    Keutzer and Joseph E Gonzalez and Ion Stoica
  venue: arXiv preprint arXiv:2311.03285
  year: ''
  citations: 71
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Ak0FvsSvgGUC
  abstract: The "pretrain-then-finetune" paradigm is commonly adopted in the deployment
    of large language models. Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning
    method, is often employed to adapt a base model to a multitude of tasks, resulting
    in a substantial collection of LoRA adapters derived from one base model. We observe
    that this paradigm presents significant opportunities for batched inference during
    serving. To capitalize on these opportunities, we present S-LoRA, a system designed
    for the scalable serving of many LoRA adapters. S-LoRA stores all adapters in
    the main memory and fetches the adapters used by the currently running queries
    to the GPU memory. To efficiently use the GPU memory and reduce fragmentation,
    S-LoRA proposes Unified Paging. Unified Paging uses a unified memory pool to manage
    dynamic adapter weights with different ranks and KV cache tensors with varying
    sequence lengths. Additionally, S-LoRA employs a novel tensor parallelism strategy
    and highly optimized custom CUDA kernels for heterogeneous batching of LoRA computation.
    Collectively, these features enable S-LoRA to serve thousands of LoRA adapters
    on a single GPU or across multiple GPUs with a small overhead. Compared to state-of-the-art
    libraries such as HuggingFace PEFT and vLLM (with naive support of LoRA serving),
    S-LoRA can improve the throughput by up to 4 times and increase the number of
    served adapters by several orders of magnitude. As a result, S-LoRA enables scalable
    serving of many task-specific fine-tuned models and offers the potential for large-scale
    customized fine-tuning services. The code is …
- title: 'Fbnetv3: Joint architecture-recipe search using neural acquisition function'
  authors: Xiaoliang Dai and Alvin Wan and Peizhao Zhang and Bichen Wu and Zijian
    He and Zhen Wei and Kan Chen and Yuandong Tian and Matthew Yu and Peter Vajda
    and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2006.02049
  year: ''
  citations: 69
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:pyW8ca7W8N0C
  abstract: ''
- title: 'Bev-seg: Bird''s eye view semantic segmentation using geometry and semantic
    point cloud'
  authors: Mong H Ng and Kaahan Radia and Jianfei Chen and Dequan Wang and Ionel Gog
    and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2006.11436
  year: ''
  citations: 67
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:YOwf2qJgpHMC
  abstract: 'Bird''s-eye-view (BEV) is a powerful and widely adopted representation
    for road scenes that captures surrounding objects and their spatial locations,
    along with overall context in the scene. In this work, we focus on bird''s eye
    semantic segmentation, a task that predicts pixel-wise semantic segmentation in
    BEV from side RGB images. This task is made possible by simulators such as Carla,
    which allow for cheap data collection, arbitrary camera placements, and supervision
    in ways otherwise not possible in the real world. There are two main challenges
    to this task: the view transformation from side view to bird''s eye view, as well
    as transfer learning to unseen domains. Existing work transforms between views
    through fully connected layers and transfer learns via GANs. This suffers from
    a lack of depth reasoning and performance degradation across domains. Our novel
    2-staged perception pipeline explicitly predicts pixel depths and combines them
    with pixel semantics in an efficient manner, allowing the model to leverage depth
    information to infer objects'' spatial locations in the BEV. In addition, we transfer
    learning by abstracting high-level geometric features and predicting an intermediate
    representation that is common across different domains. We publish a new dataset
    called BEVSEG-Carla and show that our approach improves state-of-the-art by 24%
    mIoU and performs well when transferred to a new domain.'
- title: Efficiently Programming Large Language Models using SGLang.
  authors: Lianmin Zheng and Liangsheng Yin and Zhiqiang Xie and Jeff Huang and Chuyue
    Sun and Cody_Hao Yu and Shiyi Cao and Christos Kozyrakis and Ion Stoica and Joseph
    E Gonzalez and Clark W Barrett and Ying Sheng
  venue: ''
  year: ''
  citations: 61
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:2tRrZ1ZAMYUC
  abstract: Large language models (LLMs) are increasingly used for complex tasks that
    require multiple generation calls, advanced prompting techniques, control flow,
    and structured inputs/outputs. However, efficient systems are lacking for programming
    and executing these applications. We introduce SGLang, a system for efficient
    execution of complex language model programs. SGLang consists of a frontend language
    and a runtime. The frontend simplifies programming with primitives for generation
    and parallelism control. The runtime accelerates execution with novel optimizations
    like RadixAttention for KV cache reuse and compressed finite state machines for
    faster structured output decoding. Experiments show that SGLang achieves up to
    6.4× higher throughput compared to state-of-the-art inference systems on various
    large language and multi-modal models on tasks including agent control, logical
    reasoning, few-shot learning benchmarks, JSON decoding, retrieval-augmented generation
    pipelines, and multi-turn chat. The code is publicly available at https://github.
    com/sgl-project/sglang.
- title: Untangling dense knots by learning task-relevant keypoints
  authors: Jennifer Grannen and Priya Sundaresan and Brijen Thananjeyan and Jeffrey
    Ichnowski and Ashwin Balakrishna and Minho Hwang and Vainavi Viswanath and Michael
    Laskey and Joseph E Gonzalez and Ken Goldberg
  venue: arXiv preprint arXiv:2011.04999
  year: ''
  citations: 61
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ZfRJV9d4-WMC
  abstract: 'Untangling ropes, wires, and cables is a challenging task for robots
    due to the high-dimensional configuration space, visual homogeneity, self-occlusions,
    and complex dynamics. We consider dense (tight) knots that lack space between
    self-intersections and present an iterative approach that uses learned geometric
    structure in configurations. We instantiate this into an algorithm, HULK: Hierarchical
    Untangling from Learned Keypoints, which combines learning-based perception with
    a geometric planner into a policy that guides a bilateral robot to untangle knots.
    To evaluate the policy, we perform experiments both in a novel simulation environment
    modelling cables with varied knot types and textures and in a physical system
    using the da Vinci surgical robot. We find that HULK is able to untangle cables
    with dense figure-eight and overhand knots and generalize to varied textures and
    appearances. We compare two variants of HULK to three baselines and observe that
    HULK achieves 43.3% higher success rates on a physical system compared to the
    next best baseline. HULK successfully untangles a cable from a dense initial configuration
    containing up to two overhand and figure-eight knots in 97.9% of 378 simulation
    experiments with an average of 12.1 actions per trial. In physical experiments,
    HULK achieves 61.7% untangling success, averaging 8.48 actions per trial. Supplementary
    material, code, and videos can be found at https://tinyurl.com/y3a88ycu.'
- title: 'From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and BenchBuilder
    Pipeline'
  authors: Tianle Li and Wei-Lin Chiang and Evan Frick and Lisa Dunlap and Tianhao
    Wu and Banghua Zhu and Joseph E Gonzalez and Ion Stoica
  venue: arXiv preprint arXiv:2406.11939
  year: ''
  citations: 60
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:kVjdVfd2voEC
  abstract: 'The rapid evolution of language models has necessitated the development
    of more challenging benchmarks. Current static benchmarks often struggle to consistently
    distinguish between the capabilities of different models and fail to align with
    real-world user preferences. On the other hand, live crowd-sourced platforms like
    the Chatbot Arena collect a wide range of natural prompts and user feedback. However,
    these prompts vary in sophistication and the feedback cannot be applied offline
    to new models. In order to ensure that benchmarks keep up with the pace of LLM
    development, we address how one can evaluate benchmarks on their ability to confidently
    separate models and their alignment with human preference. Under these principles,
    we developed BenchBuilder, a living benchmark that filters high-quality prompts
    from live data sources to enable offline evaluation on fresh, challenging prompts.
    BenchBuilder identifies seven indicators of a high-quality prompt, such as the
    requirement for domain knowledge, and utilizes an LLM annotator to select a high-quality
    subset of prompts from various topic clusters. The LLM evaluation process employs
    an LLM judge to ensure a fully automated, high-quality, and constantly updating
    benchmark. We apply BenchBuilder on prompts from the Chatbot Arena to create Arena-Hard-Auto
    v0.1: 500 challenging user prompts from a wide range of tasks. Arena-Hard-Auto
    v0.1 offers 3x tighter confidence intervals than MT-Bench and achieves a state-of-the-art
    89.1% agreement with human preference rankings, all at a cost of only $25 and
    without human labelers. The BenchBuilder pipeline enhances …'
- title: 'Remembering for the right reasons: Explanations reduce catastrophic forgetting'
  authors: Sayna Ebrahimi and Suzanne Petryk and Akash Gokul and William Gan and Joseph
    E Gonzalez and Marcus Rohrbach and Trevor Darrell
  venue: Applied AI letters
  year: ''
  citations: 59
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:2KloaMYe4IUC
  abstract: The goal of continual learning (CL) is to learn a sequence of tasks without
    suffering from the phenomenon of catastrophic forgetting. Previous work has shown
    that leveraging memory in the form of a replay buffer can reduce performance degradation
    on prior tasks. We hypothesize that forgetting can be further reduced when the
    model is encouraged to remember the evidence for previously made decisions. As
    a first step towards exploring this hypothesis, we propose a simple novel training
    paradigm, called Remembering for the Right Reasons (RRR), that additionally stores
    visual model explanations for each example in the buffer and ensures the model
    has “the right reasons” for its predictions by encouraging its explanations to
    remain consistent with those used to make decisions at training time. Without
    this constraint, there is a drift in explanations and increase in forgetting as
    conventional continual learning …
- title: 'Vicuna: an open-source chatbot impressing GPT-4 with 90%* chatgpt quality
    (2023)'
  authors: Wei-Lin Chiang and Zhuohan Li and Zi Lin and Ying Sheng and Zhanghao Wu
    and Hao Zhang and Lianmin Zheng and Siyuan Zhuang and Yonghao Zhuang and Joseph
    E Gonzalez and Ion Stoica and Eric P Xing
  venue: URL https://lmsys. org/blog/2023-03-30-vicuna
  year: ''
  citations: 57
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:U_HPUtbDl20C
  abstract: ''
- title: 'Hypersched: Dynamic resource reallocation for model development on a deadline'
  authors: Richard Liaw and Romil Bhardwaj and Lisa Dunlap and Yitian Zou and Joseph
    E Gonzalez and Ion Stoica and Alexey Tumanov
  venue: ''
  year: ''
  citations: 57
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ufrVoPGSRksC
  abstract: Prior research in resource scheduling for machine learning training workloads
    has largely focused on minimizing job completion times. Commonly, these model
    training workloads collectively search over a large number of parameter values
    that control the learning process in a hyperparameter search. It is preferable
    to identify and maximally provision the best-performing hyperparameter configuration
    (trial) to achieve the highest accuracy result as soon as possible.To optimally
    trade-off evaluating multiple configurations and training the most promising ones
    by a fixed deadline, we design and build HyperSched---a dynamic application-level
    resource scheduler to track, identify, and preferentially allocate resources to
    the best performing trials to maximize accuracy by the deadline. HyperSched leverages
    three properties of a hyperparameter search workload overlooked in prior work
    -- trial disposability, progressively …
- title: Rethinking benchmark and contamination for language models with rephrased
    samples
  authors: Shuo Yang and Wei-Lin Chiang and Lianmin Zheng and Joseph E Gonzalez and
    Ion Stoica
  venue: arXiv preprint arXiv:2311.04850
  year: ''
  citations: 56
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Bg7qf7VwUHIC
  abstract: Large language models are increasingly trained on all the data ever produced
    by humans. Many have raised concerns about the trustworthiness of public benchmarks
    due to potential contamination in pre-training or fine-tuning datasets. While
    most data decontamination efforts apply string matching (e.g., n-gram overlap)
    to remove benchmark data, we show that these methods are insufficient, and simple
    variations of test data (e.g., paraphrasing, translation) can easily bypass these
    decontamination measures. Furthermore, we demonstrate that if such variation of
    test data is not eliminated, a 13B model can easily overfit a test benchmark and
    achieve drastically high performance, on par with GPT-4. We validate such observations
    in widely used benchmarks such as MMLU, GSK8k, and HumanEval. To address this
    growing risk, we propose a stronger LLM-based decontamination method and apply
    it to widely used pre-training and fine-tuning datasets, revealing significant
    previously unknown test overlap. For example, in pre-training sets such as RedPajama-Data-1T
    and StarCoder-Data, we identified that 8-18\% of the HumanEval benchmark overlaps.
    Interestingly, we also find such contamination in synthetic dataset generated
    by GPT-3.5/4, suggesting a potential risk of unintentional contamination. We urge
    the community to adopt stronger decontamination approaches when using public benchmarks.
    Moreover, we call for the community to actively develop fresh one-time exams to
    evaluate models accurately. Our decontamination tool is publicly available at
    https://github.com/lm-sys/llm-decontaminator.
- title: Large batch size training of neural networks with adversarial training and
    second-order information
  authors: Zhewei Yao and Amir Gholami and Daiyaan Arfeen and Richard Liaw and Joseph
    Gonzalez and Kurt Keutzer and Michael Mahoney
  venue: arXiv preprint arXiv:1810.01021
  year: ''
  citations: 55
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:i2xiXl-TujoC
  abstract: The most straightforward method to accelerate Stochastic Gradient Descent
    (SGD) computation is to distribute the randomly selected batch of inputs over
    multiple processors. To keep the distributed processors fully utilized requires
    commensurately growing the batch size. However, large batch training often leads
    to poorer generalization. A recently proposed solution for this problem is to
    use adaptive batch sizes in SGD. In this case, one starts with a small number
    of processes and scales the processes as training progresses. Two major challenges
    with this approach are (i) that dynamically resizing the cluster can add non-trivial
    overhead, in part since it is currently not supported, and (ii) that the overall
    speed up is limited by the initial phase with smaller batches. In this work, we
    address both challenges by developing a new adaptive batch size framework, with
    autoscaling based on the Ray framework. This allows very efficient elastic scaling
    with negligible resizing overhead (0.32\% of time for ResNet18 ImageNet training).
    Furthermore, we propose a new adaptive batch size training scheme using second
    order methods and adversarial training. These enable increasing batch sizes earlier
    during training, which leads to better training time. We extensively evaluate
    our method on Cifar-10/100, SVHN, TinyImageNet, and ImageNet datasets, using multiple
    neural networks, including ResNets and smaller networks such as SqueezeNext. Our
    method exceeds the performance of existing solutions in terms of both accuracy
    and the number of SGD iterations (up to 1\% and , respectively). Importantly,
    this is achieved without any additional hyper …
- title: Multitask vision-language prompt tuning
  authors: Sheng Shen and Shijia Yang and Tianjun Zhang and Bohan Zhai and Joseph
    E Gonzalez and Kurt Keutzer and Trevor Darrell
  venue: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer
    Vision
  year: ''
  citations: 52
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:WJVC3Jt7v1AC
  abstract: Prompt Tuning, conditioning on task-specific learned prompt vectors, has
    emerged as a data-efficient and parameter-efficient method for adapting large
    pretrained vision-language models to multiple downstream tasks. However, existing
    approaches usually consider learning prompt vectors for each task independently
    from scratch, thereby failing to exploit the rich shareable knowledge across different
    vision-language tasks. In this paper, we propose multitask vision-language prompt
    tuning (MVLPT), which incorporates cross-task knowledge into prompt tuning for
    vision-language models. Specifically,(i) we demonstrate the effectiveness of learning
    a single transferable prompt from multiple source tasks to initialize the prompt
    for each target task;(ii) we show many target tasks can benefit each other from
    sharing prompt vectors and thus can be jointly learned via multitask prompt tuning.
    We benchmark the proposed MVLPT using three representative prompt tuning methods,
    namely text prompt tuning, visual prompt tuning, and the unified vision-language
    prompt tuning. Results in 20 vision tasks demonstrate that the proposed approach
    outperforms all single-task baseline prompt tuning methods, setting the new state-of-the-art
    on the few-shot ELEVATER benchmarks and cross-task generalization benchmarks.
    To understand where the cross-task knowledge is most effective, we also conduct
    a large-scale study on task transferability with 20 vision tasks in 400 combinations
    for each prompt tuning method. It shows that the most performant MVLPT for each
    prompt tuning method prefers different task combinations and many tasks can benefit
    each other …
- title: Boundary thickness and robustness in learning models
  authors: Yaoqing Yang and Rajiv Khanna and Yaodong Yu and Amir Gholami and Kurt
    Keutzer and Joseph E Gonzalez and Kannan Ramchandran and Michael W Mahoney
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 52
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:TFP_iSt0sucC
  abstract: Robustness of machine learning models to various adversarial and non-adversarial
    corruptions continues to be of interest. In this paper, we introduce the notion
    of the boundary thickness of a classifier, and we describe its connection with
    and usefulness for model robustness. Thick decision boundaries lead to improved
    performance, while thin decision boundaries lead to overfitting (eg, measured
    by the robust generalization gap between training and testing) and lower robustness.
    We show that a thicker boundary helps improve robustness against adversarial examples
    (eg, improving the robust test accuracy of adversarial training), as well as so-called
    out-of-distribution (OOD) transforms, and we show that many commonly-used regularization
    and data augmentation procedures can increase boundary thickness. On the theoretical
    side, we establish that maximizing boundary thickness is akin to minimizing the
    so-called mixup loss. Using these observations, we can show that noise-augmentation
    on mixup training further increases boundary thickness, thereby combating vulnerability
    to various forms of adversarial attacks and OOD transforms. We can also show that
    the performance improvement in several recent lines of work happens in conjunction
    with a thicker boundary.
- title: How Long Can Context Length of Open-Source LLMs truly Promise?
  authors: Dacheng Li and Rulin Shao and Anze Xie and Ying Sheng and Lianmin Zheng
    and Joseph Gonzalez and Ion Stoica and Xuezhe Ma and Hao Zhang
  venue: NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following
  year: ''
  citations: 51
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:4X0JR2_MtJMC
  abstract: Large language models (LLMs) with long-context instruction following ability
    has unlocked new potentials, such as supporting long interactive chat sessions.
    In this paper, we introduce a test suite, LongEval, which enables us to evaluate
    the long-range retrieval ability of LLMs at various context lengths. We use LongEval
    to evaluate open-sourced LLMs, and surprisingly, we find many of them fail to
    achieve their promised context length. In addition, we present a recipe to fine
    tune a long-context chatbot based on LLaMA models, and introduce LongChat models
    that supporting conversations of up to 16,384 tokens. We have released our code
    at https://github.com/DachengLi1/LongChat.
- title: 'Reliable visual question answering: Abstain rather than answer incorrectly'
  authors: Spencer Whitehead and Suzanne Petryk and Vedaad Shakib and Joseph Gonzalez
    and Trevor Darrell and Anna Rohrbach and Marcus Rohrbach
  venue: ''
  year: ''
  citations: 50
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:0N-VGjzr574C
  abstract: Machine learning has advanced dramatically, narrowing the accuracy gap
    to humans in multimodal tasks like visual question answering (VQA). However, while
    humans can say “I don’t know” when they are uncertain (i.e., abstain from answering
    a question), such ability has been largely neglected in multimodal research, despite
    the importance of this problem to the usage of VQA in real settings. In this work,
    we promote a problem formulation for reliable VQA, where we prefer abstention
    over providing an incorrect answer. We first enable abstention capabilities for
    several VQA models, and analyze both their coverage, the portion of questions
    answered, and risk, the error on that portion. For that, we explore several abstention
    approaches. We find that although the best performing models achieve over 71%
    accuracy on the VQA v2 dataset, introducing the option to abstain by directly
    using a model’s softmax scores limits …
- title: Making linear mdps practical via contrastive representation learning
  authors: Tianjun Zhang and Tongzheng Ren and Mengjiao Yang and Joseph Gonzalez and
    Dale Schuurmans and Bo Dai
  venue: International Conference on Machine Learning
  year: ''
  citations: 50
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:PVjk1bu6vJQC
  abstract: It is common to address the curse of dimensionality in Markov decision
    processes (MDPs) by exploiting low-rank representations. This motivates much of
    the recent theoretical study on linear MDPs. However, most approaches require
    a given representation under unrealistic assumptions about the normalization of
    the decomposition or introduce unresolved computational challenges in practice.
    Instead, we consider an alternative definition of linear MDPs that automatically
    ensures normalization while allowing efficient representation learning via contrastive
    estimation. The framework also admits confidence-adjusted index algorithms, enabling
    an efficient and principled approach to incorporating optimism or pessimism in
    the face of uncertainty. To the best of our knowledge, this provides the first
    practical representation learning method for linear MDPs that achieves both strong
    theoretical guarantees and empirical performance. Theoretically, we prove that
    the proposed algorithm is sample efficient in both the online and offline settings.
    Empirically, we demonstrate superior performance over existing state-of-the-art
    model-based and model-free algorithms on several benchmarks.
- title: 'Context: The missing piece in the machine learning lifecycle'
  authors: Rolando Garcia and Vikram Sreekanti and Neeraja Yadwadkar and Daniel Crankshaw
    and Joseph E Gonzalez and Joseph M Hellerstein
  venue: KDD CMI Workshop
  year: ''
  citations: 49
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:HDshCWvjkbEC
  abstract: Machine learning models have become ubiquitous in modern applications.
    The ML Lifecycle describes a three-phase process used by data scientists and data
    engineers to develop, train, and serve models. Unfortunately, context around the
    data, code, people, and systems involved in these pipelines is not captured today.
    In this paper, we first discuss common pitfalls that missing context creates.
    Some examples where context is missing include tracking the relationships between
    code and data and capturing experimental processes over time. We then discuss
    techniques to address these challenges and briefly mention future work around
    designing and implementing systems in this space.
- title: Neural code completion
  authors: Chang Liu and Xin Wang and Richard Shin and Joseph E Gonzalez and Dawn
    Song
  venue: ''
  year: ''
  citations: 49
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:k_IJM867U9cC
  abstract: Code completion, an essential part of modern software development, yet
    can bechallenging for dynamically typed programming languages.  In this paper
    we ex-plore the use of neural network techniques to automatically learn code completionfrom  a  large  corpus  of  dynamically  typed  JavaScript  code.   We  show  differentneural
    networks that leverage not only token level information but also structuralinformation,  and  evaluate  their  performance  on  different  prediction  tasks.   Wedemonstrate
    that our models can outperform the state-of-the-art approach, whichis based on
    decision tree techniques, on both next non-terminal and next terminalprediction
    tasks by 3.8 points and 0.5 points respectively.  We believe that neuralnetwork
    techniques can play a transformative role in helping software developersmanage
    the growing complexity of software systems, and we see this work as afirst step
    in that direction.
- title: 'POET: Training neural networks on tiny devices with integrated rematerialization
    and paging'
  authors: Shishir G Patil and Paras Jain and Prabal Dutta and Ion Stoica and Joseph
    Gonzalez
  venue: International Conference on Machine Learning
  year: ''
  citations: 48
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:86PQX7AUzd4C
  abstract: Fine-tuning models on edge devices like mobile phones would enable privacy-preserving
    personalization over sensitive data. However, edge training has historically been
    limited to relatively small models with simple architectures because training
    is both memory and energy intensive. We present POET, an algorithm to enable training
    large neural networks on memory-scarce battery-operated edge devices. POET jointly
    optimizes the integrated search search spaces of rematerialization and paging,
    two algorithms to reduce the memory consumption of backpropagation. Given a memory
    budget and a run-time constraint, we formulate a mixed-integer linear program
    (MILP) for energy-optimal training. Our approach enables training significantly
    larger models on embedded devices while reducing energy consumption while not
    modifying mathematical correctness of backpropagation. We demonstrate that it
    is possible to fine-tune both ResNet-18 and BERT within the memory constraints
    of a Cortex-M class embedded device while outperforming current edge training
    methods in energy efficiency. POET is an open-source project available at https://github.
    com/ShishirPatil/poet
- title: 'Bebold: Exploration beyond the boundary of explored regions'
  authors: Tianjun Zhang and Huazhe Xu and Xiaolong Wang and Yi Wu and Kurt Keutzer
    and Joseph E Gonzalez and Yuandong Tian
  venue: arXiv preprint arXiv:2012.08621
  year: ''
  citations: 48
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:bnK-pcrLprsC
  abstract: Efficient exploration under sparse rewards remains a key challenge in
    deep reinforcement learning. To guide exploration, previous work makes extensive
    use of intrinsic reward (IR). There are many heuristics for IR, including visitation
    counts, curiosity, and state-difference. In this paper, we analyze the pros and
    cons of each method and propose the regulated difference of inverse visitation
    counts as a simple but effective criterion for IR. The criterion helps the agent
    explore Beyond the Boundary of explored regions and mitigates common issues in
    count-based methods, such as short-sightedness and detachment. The resulting method,
    BeBold, solves the 12 most challenging procedurally-generated tasks in MiniGrid
    with just 120M environment steps, without any curriculum learning. In comparison,
    the previous SoTA only solves 50% of the tasks. BeBold also achieves SoTA on multiple
    tasks in NetHack, a popular rogue-like game that contains more challenging procedurally-generated
    environments.
- title: Diversify your vision datasets with automatic diffusion-based augmentation
  authors: Lisa Dunlap and Alyssa Umino and Han Zhang and Jiezhi Yang and Joseph E
    Gonzalez and Trevor Darrell
  venue: Advances in neural information processing systems
  year: ''
  citations: 47
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:HeT0ZceujKMC
  abstract: Many fine-grained classification tasks, like rare animal identification,
    have limited training data and consequently classifiers trained on these datasets
    often fail to generalize to variations in the domain like changes in weather or
    location. As such, we explore how natural language descriptions of the domains
    seen in training data can be used with large vision models trained on diverse
    pretraining datasets to generate useful variations of the training data. We introduce
    ALIA (Automated Language-guided Image Augmentation), a method which utilizes large
    vision and language models to automatically generate natural language descriptions
    of a dataset's domains and augment the training data via language-guided image
    editing. To maintain data integrity, a model trained on the original dataset filters
    out minimal image edits and those which corrupt class-relevant information. The
    resulting dataset is visually consistent with the original training data and offers
    significantly enhanced diversity. We show that ALIA is able to surpasses traditional
    data augmentation and text-to-image generated data on fine-grained classification
    tasks, including cases of domain generalization and contextual bias. Code is available
    at https://github. com/lisadunlap/ALIA.
- title: 'Made: Exploration via maximizing deviation from explored regions'
  authors: Tianjun Zhang and Paria Rashidinejad and Jiantao Jiao and Yuandong Tian
    and Joseph E Gonzalez and Stuart Russell
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 47
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:kzcrU_BdoSEC
  abstract: In online reinforcement learning (RL), efficient exploration remains particularly
    challenging in high-dimensional environments with sparse rewards. In low-dimensional
    environments, where tabular parameterization is possible, count-based upper confidence
    bound (UCB) exploration methods achieve minimax near-optimal rates. However, it
    remains unclear how to efficiently implement UCB in realistic RL tasks that involve
    non-linear function approximation. To address this, we propose a new exploration
    approach via maximizing the deviation of the occupancy of the next policy from
    the explored regions. We add this term as an adaptive regularizer to the standard
    RL objective to balance exploration vs. exploitation. We pair the new objective
    with a provably convergent algorithm, giving rise to a new intrinsic reward that
    adjusts existing bonuses. The proposed intrinsic reward is easy to implement and
    combine with other existing RL algorithms to conduct exploration. As a proof of
    concept, we evaluate the new intrinsic reward on tabular examples across a variety
    of model-based and model-free algorithms, showing improvements over count-only
    exploration strategies. When tested on navigation and locomotion tasks from MiniGrid
    and DeepMind Control Suite benchmarks, our approach significantly improves sample
    efficiency over state-of-the-art methods.
- title: The wisdom of hindsight makes language models better instruction followers
  authors: Tianjun Zhang and Fangchen Liu and Justin Wong and Pieter Abbeel and Joseph
    E Gonzalez
  venue: International Conference on Machine Learning
  year: ''
  citations: 46
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:HtS1dXgVpQUC
  abstract: 'Reinforcement learning has seen wide success in finetuning large language
    models to better align with instructions via human feedback. The so-called algorithm,
    Reinforcement Learning with Human Feedback (RLHF) demonstrates impressive performance
    on the GPT series models. However, the underlying reinforcement learning algorithm
    is complex and requires additional training for reward and value networks. In
    this paper, we consider an alternative approach: converting feedback to instruction
    by relabeling the original one and training the model for better alignment in
    a supervised manner. Such an algorithm doesn’t require any additional parameters
    except for the original language model and maximally reuses the pretraining pipeline.
    To achieve this, we formulate instruction alignment problem for language models
    as a goal-reaching problem in decision making. We propose Hindsight Instruction
    Relabeling (HIR), a novel algorithm for aligning language models with instructions.
    The resulting two-stage algorithm shed light to a family of reward-free approaches
    that utilize the hindsightly relabeled instructions based on feedback. We evaluate
    the performance of HIR extensively on 12 challenging BigBench reasoning tasks
    and show that HIR outperforms the baseline algorithms and is comparable to or
    even surpasses supervised fine-tuning. The implementation of HIR is available
    at https://github. com/tianjunz/HIR.'
- title: A statistical framework for low-bitwidth training of deep neural networks
  authors: Jianfei Chen and Yu Gai and Zhewei Yao and Michael W Mahoney and Joseph
    E Gonzalez
  venue: Advances in neural information processing systems
  year: ''
  citations: 46
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:VLnqNzywnoUC
  abstract: Fully quantized training (FQT), which uses low-bitwidth hardware by quantizing
    the activations, weights, and gradients of a neural network model, is a promising
    approach to accelerate the training of deep neural networks. One major challenge
    with FQT is the lack of theoretical understanding, in particular of how gradient
    quantization impacts convergence properties. In this paper, we address this problem
    by presenting a statistical framework for analyzing FQT algorithms. We view the
    quantized gradient of FQT as a stochastic estimator of its full precision counterpart,
    a procedure known as quantization-aware training (QAT). We show that the FQT gradient
    is an unbiased estimator of the QAT gradient, and we discuss the impact of gradient
    quantization on its variance. Inspired by these theoretical results, we develop
    two novel gradient quantizers, and we show that these have smaller variance than
    the existing per-tensor quantizer. For training ResNet-50 on ImageNet, our 5-bit
    block Householder quantizer achieves only 0.5% validation accuracy loss relative
    to QAT, comparable to the existing INT8 baseline.
- title: A view on deep reinforcement learning in system optimization
  authors: Ameer Haj-Ali and Nesreen K Ahmed and Ted Willke and Joseph Gonzalez and
    Krste Asanovic and Ion Stoica
  venue: arXiv preprint arXiv:1908.01275
  year: ''
  citations: 46
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:a0OBvERweLwC
  abstract: Many real-world systems problems require reasoning about the long term
    consequences of actions taken to configure and manage the system. These problems
    with delayed and often sequentially aggregated reward, are often inherently reinforcement
    learning problems and present the opportunity to leverage the recent substantial
    advances in deep reinforcement learning. However, in some cases, it is not clear
    why deep reinforcement learning is a good fit for the problem. Sometimes, it does
    not perform better than the state-of-the-art solutions. And in other cases, random
    search or greedy algorithms could outperform deep reinforcement learning. In this
    paper, we review, discuss, and evaluate the recent trends of using deep reinforcement
    learning in system optimization. We propose a set of essential metrics to guide
    future works in evaluating the efficacy of using deep reinforcement learning in
    system optimization. Our evaluation includes challenges, the types of problems,
    their formulation in the deep reinforcement learning setting, embedding, the model
    used, efficiency, and robustness. We conclude with a discussion on open challenges
    and potential directions for pushing further the integration of reinforcement
    learning in system optimization.
- title: 'RSa, W Pa, D Ta, A Ma, D Aa, M Xa, R Ja, V Sa, F MJ. Apache Spark: A Unified
    Engine for Big Data Processing'
  authors: X Zaharia Ma
  venue: Commun ACM
  year: ''
  citations: 44
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:7wO8s98CvbsC
  abstract: ''
- title: Parallel double greedy submodular maximization
  authors: Xinghao Pan and Stefanie Jegelka and Joseph E Gonzalez and Joseph K Bradley
    and Michael I Jordan
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 44
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:IjCSPb-OGe4C
  abstract: Many machine learning problems can be reduced to the maximization of submodular
    functions. Although well understood in the serial setting, the parallel maximization
    of submodular functions remains an open area of research with recent results only
    addressing monotone functions. The optimal algorithm for maximizing the more general
    class of non-monotone submodular functions was introduced by Buchbinder et al.
    and follows a strongly serial double-greedy logic and program analysis. In this
    work, we propose two methods to parallelize the double-greedy algorithm. The first,
    coordination-free approach emphasizes speed at the cost of a weaker approximation
    guarantee. The second, concurrency control approach guarantees a tight 1/2-approximation,
    at the quantifiable cost of additional coordination and reduced parallelism. As
    a consequence we explore the trade off space between guaranteed performance and
    objective optimality. We implement and evaluate both algorithms on multi-core
    hardware and billion edge graphs, demonstrating both the scalability and tradeoffs
    of each approach.
- title: 'Visual transformers: Token-based image representation and processing for
    computer vision. arXiv 2020'
  authors: Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang
    and Z Yan and M Tomizuka and J Gonzalez and K Keutzer and P Vajda
  venue: arXiv preprint arXiv:2006.03677
  year: ''
  citations: 44
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:xtoqd-5pKcoC
  abstract: ''
- title: 'Skyplane: Optimizing transfer cost and throughput using {Cloud-Aware} overlays'
  authors: Paras Jain and Sam Kumar and Sarah Wooders and Shishir G Patil and Joseph
    E Gonzalez and Ion Stoica
  venue: 20th USENIX Symposium on Networked Systems Design and Implementation (NSDI
    23)
  year: ''
  citations: 43
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:sNmaIFBj_lkC
  abstract: Cloud applications are increasingly distributing data across multiple
    regions and cloud providers. Unfortunately, widearea bulk data transfers are often
    slow, bottlenecking applications. We demonstrate that it is possible to significantly
    improve inter-region cloud bulk transfer throughput by adapting network overlays
    to the cloud setting—that is, by routing data through indirect paths at the application
    layer. However, directly applying network overlays in this setting can result
    in unacceptable increases in cloud egress prices. We present Skyplane, a system
    for bulk data transfer between cloud object stores that uses cloud-aware network
    overlays to optimally navigate the trade-off between price and performance. Skyplane's
    planner uses mixed-integer linear programming to determine the optimal overlay
    path and resource allocation for data transfer, subject to user-provided constraints
    on price or performance. Skyplane outperforms public cloud transfer services by
    up to 4.6× for transfers within one cloud and by up to 5.0× across clouds.
- title: 'D3: a dynamic deadline-driven approach for building autonomous vehicles'
  authors: Ionel Gog and Sukrit Kalra and Peter Schafhalter and Joseph E Gonzalez
    and Ion Stoica
  venue: ''
  year: ''
  citations: 43
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:5awf1xo2G04C
  abstract: Autonomous vehicles (AVs) must drive across a variety of challenging environments
    that impose continuously-varying deadlines and runtime-accuracy tradeoffs on their
    software pipelines. A deadline-driven execution of such AV pipelines requires
    a new class of systems that enable the computation to maximize accuracy under
    dynamically-varying deadlines. Designing these systems presents interesting challenges
    that arise from combining ease-of-development of AV pipelines with deadline specification
    and enforcement mechanisms.Our work addresses these challenges through D3 (Dynamic
    Deadline-Driven), a novel execution model that centralizes the deadline management,
    and allows applications to adjust their computation by modeling missed deadlines
    as exceptions. Further, we design and implement ERDOS, an open-source realization
    of D3 for AV pipelines that exposes finegrained execution events …
- title: Data efficient language-supervised zero-shot recognition with optimal transport
    distillation
  authors: Bichen Wu and Ruizhe Cheng and Peizhao Zhang and Tianren Gao and Peter
    Vajda and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2112.09445
  year: ''
  citations: 43
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:vbGhcppDl1QC
  abstract: Traditional computer vision models are trained to predict a fixed set
    of predefined categories. Recently, natural language has been shown to be a broader
    and richer source of supervision that provides finer descriptions to visual concepts
    than supervised "gold" labels. Previous works, such as CLIP, use InfoNCE loss
    to train a model to predict the pairing between images and text captions. CLIP,
    however, is data hungry and requires more than 400M image-text pairs for training.
    The inefficiency can be partially attributed to the fact that the image-text pairs
    are noisy. To address this, we propose OTTER (Optimal TransporT distillation for
    Efficient zero-shot Recognition), which uses online entropic optimal transport
    to find a soft image-text match as labels for contrastive learning. Based on pretrained
    image and text encoders, models trained with OTTER achieve strong performance
    with only 3M image text pairs. Compared with InfoNCE loss, label smoothing, and
    knowledge distillation, OTTER consistently outperforms these baselines in zero
    shot evaluation on Google Open Images (19,958 classes) and multi-labeled ImageNet
    10K (10032 classes) from Tencent ML-Images. Over 42 evaluations on 7 different
    dataset/architecture settings x 6 metrics, OTTER outperforms (32) or ties (2)
    all baselines in 34 of them.
- title: Multi-agent collaboration via reward attribution decomposition
  authors: Tianjun Zhang and Huazhe Xu and Xiaolong Wang and Yi Wu and Kurt Keutzer
    and Joseph E Gonzalez and Yuandong Tian
  venue: arXiv preprint arXiv:2010.08531
  year: ''
  citations: 42
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:WA5NYHcadZ8C
  abstract: 'Recent advances in multi-agent reinforcement learning (MARL) have achieved
    super-human performance in games like Quake 3 and Dota 2. Unfortunately, these
    techniques require orders-of-magnitude more training rounds than humans and don''t
    generalize to new agent configurations even on the same game. In this work, we
    propose Collaborative Q-learning (CollaQ) that achieves state-of-the-art performance
    in the StarCraft multi-agent challenge and supports ad hoc team play. We first
    formulate multi-agent collaboration as a joint optimization on reward assignment
    and show that each agent has an approximately optimal policy that decomposes into
    two parts: one part that only relies on the agent''s own state, and the other
    part that is related to states of nearby agents. Following this novel finding,
    CollaQ decomposes the Q-function of each agent into a self term and an interactive
    term, with a Multi-Agent Reward Attribution (MARA) loss that regularizes the training.
    CollaQ is evaluated on various StarCraft maps and shows that it outperforms existing
    state-of-the-art techniques (i.e., QMIX, QTRAN, and VDN) by improving the win
    rate by 40% with the same number of samples. In the more challenging ad hoc team
    play setting (i.e., reweight/add/remove units without re-training or finetuning),
    CollaQ outperforms previous SoTA by over 30%.'
- title: Oblivious coopetitive analytics using hardware enclaves
  authors: Ankur Dave and Chester Leung and Raluca Ada Popa and Joseph E Gonzalez
    and Ion Stoica
  venue: ''
  year: ''
  citations: 42
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:hC7cP41nSMkC
  abstract: Coopetitive analytics refers to cooperation among competing parties to
    run queries over their joint data. Regulatory, business, and liability concerns
    prevent these organizations from sharing their sensitive data in plaintext.We
    propose Oblivious Coopetitive Queries (OCQ), an efficient, general framework for
    oblivious coopetitive analytics using hardware enclaves. OCQ builds on Opaque,
    a Spark-based framework for secure distributed analytics, to execute coopetitive
    queries using hardware enclaves in a decentralized manner. Its query planner chooses
    how and where to execute each relational operator to prevent data leakage through
    side channels such as memory access patterns, network traffic statistics, and
    cardinality, while minimizing overhead.We implemented OCQ as an extension to Apache
    Spark SQL. We find that OCQ is up to 9.9x faster than Opaque, a state-of-the-art
    secure analytics framework which …
- title: 'Tenset: A large-scale program performance dataset for learned tensor compilers'
  authors: Lianmin Zheng and Ruochen Liu and Junru Shao and Tianqi Chen and Joseph
    E Gonzalez and Ion Stoica and Ameer Haj Ali
  venue: Thirty-fifth Conference on Neural Information Processing Systems Datasets
    and Benchmarks Track (Round 1)
  year: ''
  citations: 40
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:nrtMV_XWKgEC
  abstract: Search-based tensor compilers can greatly accelerate the execution of
    machine learning models by generating high-performance tensor programs, such as
    matrix multiplications and convolutions. These compilers take a high-level mathematical
    expression as input and search for the fastest low-level implementations. At the
    core of the search procedure is a cost model which estimates the performance of
    different candidates to reduce the frequency of time-consuming on-device measurements.
    There has been a growing interest in using machine learning techniques to learn
    a cost model to ease the effort of building an analytical model. However, a standard
    dataset for pre-training and benchmarking learned cost models is lacking.  We
    introduce TenSet, a large-scale tensor program performance dataset. TenSet contains
    52 million program performance records collected from 6 hardware platforms. We
    provide comprehensive studies on how to learn and evaluate the cost models, including
    data collection, model architectures, loss functions, transfer learning, and evaluation
    metrics. We also show that a cost model pre-trained on TenSet can accelerate the
    search time in the state-of-the-art tensor compiler by up to 10. The dataset is
    available at https://github.com/tlc-pack/tenset.
- title: 'RILaaS: Robot inference and learning as a service'
  authors: Ajay Kumar Tanwani and Raghav Anand and Joseph E Gonzalez and Ken Goldberg
  venue: IEEE Robotics and Automation Letters
  year: ''
  citations: 39
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:mVmsd5A6BfQC
  abstract: 'Programming robots is complicated due to the lack of `plug-and-play''
    modules for skill acquisition. Virtualizing deployment of deep learning models
    can facilitate large-scale use/re-use of off-the-shelf functional behaviors. Deploying
    deep learning models on robots entails real-time, accurate and reliable inference
    service under varying query load. This letter introduces a novel Robot-Inference-and-Learning-as-a-Service
    (RILaaS) platform for low-latency and secure inference serving of deep models
    that can be deployed on robots. Unique features of RILaaS include: 1) low-latency
    and reliable serving with gRPC under dynamic loads by distributing queries over
    multiple servers on Edge and Cloud, 2) SSH based authentication coupled with SSL/TLS
    based encryption for security and privacy of the data, and 3) front-end REST API
    for sharing, monitoring and visualizing performance metrics of the available models.
    We …'
- title: 'Inferline: Ml inference pipeline composition framework'
  authors: Daniel Crankshaw and Gur-Eyal Sela and Corey Zumar and Xiangxi Mo and Joseph
    E Gonzalez and Ion Stoica and Alexey Tumanov
  venue: arXiv preprint arXiv:1812.01776
  year: ''
  citations: 39
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:UebtZRa9Y70C
  abstract: The dominant cost in production machine learning workloads is not training
    individual models but serving predictions from increasingly complex prediction
    pipelines spanning multiple models, machine learning frameworks, and parallel
    hardware accelerators. Due to the complex interaction between model configurations
    and parallel hardware, prediction pipelines are challenging to provision and costly
    to execute when serving interactive latency-sensitive applications. This challenge
    is exacerbated by the unpredictable dynamics of bursty workloads.In this paper
    we introduce InferLine, a system which efficiently provisions and executes ML
    inference pipelines subject to end-to-end latency constraints by proactively optimizing
    and reactively controlling permodel configuration in a fine-grained fashion. Unpredictable
    changes in the serving workload are dynamically and cost-optimally accommodated
    with minimal service level degradation. InferLine introduces (1) automated model
    profiling and pipeline lineage extraction,(2) a fine-grain, cost-minimizing pipeline
    configuration planner, and (3) a fine-grain reactive controller. Infer-Line is
    able to configure and deploy prediction pipelines across a wide range of workload
    patterns and latency goals. It outperforms coarse-grained configuration alternatives
    by up 7.6 x in cost while achieving up to 32x lower SLO miss rate on real workloads
    and generalizes across state-of-the-art model serving frameworks.
- title: Benchmarking semi-supervised federated learning
  authors: Zhengming Zhang and Zhewei Yao and Yaoqing Yang and Yujun Yan and Joseph
    E Gonzalez and Michael W Mahoney
  venue: arXiv preprint arXiv:2008.11364
  year: ''
  citations: 38
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Z5m8FVwuT1cC
  abstract: Federated learning promises to use the computational power of edge devices
    while maintaining user data privacy. Current frameworks, however, typically make
    the unrealistic assumption that the data stored on user devices come with ground
    truth labels, while the server has no data. In this work, we consider the more
    realistic scenario where the users have only unlabeled data and the server has
    a limited amount of labeled data. In this semi-supervised federated learning (SSFL)
    setting, the data distribution can be non-iid, in the sense of different distributions
    of classes at different users. We define a metric, R, to measure this non-iidness
    in class distributions. In this setting, we provide a thorough study on different
    factors that can affect the final test accuracy, including algorithm design (such
    as training objective), the non-iidness R, the communication period T, the number
    of users K, the amount of labeled data in the server Ns, and the number of users
    Ck≤ K that communicate with the server in each communication round. We evaluate
    our SSFL framework on Cifar-10, SVHN, and EMNIST. Overall, we find that a simple
    consistency loss-based method, along with group normalization, achieves better
    generalization performance, even compared to previous supervised federated learning
    settings. Furthermore, we propose a novel grouping-based model average method
    to improve convergence efficiency, and we show that this can boost performance
    by up to 10.79% on EMNIST, compared to the non-grouping based method.
- title: 'Squeezewave: Extremely lightweight vocoders for on-device speech synthesis'
  authors: Bohan Zhai and Tianren Gao and Flora Xue and Daniel Rothchild and Bichen
    Wu and Joseph E Gonzalez and Kurt Keutzer
  venue: arXiv preprint arXiv:2001.05685
  year: ''
  citations: 38
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:_Qo2XoVZTnwC
  abstract: Automatic speech synthesis is a challenging task that is becoming increasingly
    important as edge devices begin to interact with users through speech. Typical
    text-to-speech pipelines include a vocoder, which translates intermediate audio
    representations into an audio waveform. Most existing vocoders are difficult to
    parallelize since each generated sample is conditioned on previous samples. WaveGlow
    is a flow-based feed-forward alternative to these auto-regressive models (Prenger
    et al., 2019). However, while WaveGlow can be easily parallelized, the model is
    too expensive for real-time speech synthesis on the edge. This paper presents
    SqueezeWave, a family of lightweight vocoders based on WaveGlow that can generate
    audio of similar quality to WaveGlow with 61x - 214x fewer MACs. Code, trained
    models, and generated audio are publicly available at https://github.com/tianrengao/SqueezeWave.
- title: 'Fogros: An adaptive framework for automating fog robotics deployment'
  authors: Kaiyuan Eric Chen and Yafei Liang and Nikhil Jha and Jeffrey Ichnowski
    and Michael Danielczuk and Joseph Gonzalez and John Kubiatowicz and Ken Goldberg
  venue: 2021 IEEE 17th International Conference on Automation Science and Engineering
    (CASE)
  year: ''
  citations: 37
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Ug5p-4gJ2f0C
  abstract: As many robot automation applications increasingly rely on multi-core
    processing or deep-learning models, cloud computing is becoming an attractive
    and economically viable resource for systems that do not contain high computing
    power onboard. Despite its immense computing capacity, it is often underused by
    the robotics and automation community due to lack of expertise in cloud computing
    and cloud-based infrastructure. Fog Robotics balances computing and data between
    cloud edge devices. We propose a software framework, FogROS, as an extension of
    the Robot Operating System (ROS), the defacto standard for creating robot automation
    applications and components. It allows researchers to deploy components of their
    software to the cloud with minimal effort, and correspondingly gain access to
    additional computing cores, GPUs, FPGAs, and TPUs, as well as predeployed software
    made available by …
- title: 'Intermittent visual servoing: Efficiently learning policies robust to instrument
    changes for high-precision surgical manipulation'
  authors: Samuel Paradis and Minho Hwang and Brijen Thananjeyan and Jeffrey Ichnowski
    and Daniel Seita and Danyal Fer and Thomas Low and Joseph E Gonzalez and Ken Goldberg
  venue: 2021 IEEE International Conference on Robotics and Automation (ICRA)
  year: ''
  citations: 37
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:-_dYPAW6P2MC
  abstract: Assisting surgeons with automation of surgical subtasks is challenging
    due to backlash, hysteresis, and variable tensioning in cable-driven robots. These
    issues are exacerbated as surgical instruments are changed during an operation.
    In this work, we propose a framework for automation of high- precision surgical
    subtasks by learning local, sample-efficient, accurate, closed-loop policies that
    use visual feedback instead of robot encoder estimates. This framework, which
    we call deep Intermittent Visual Servoing (IVS), switches to a learned visual
    servo policy for high-precision segments of repetitive surgical tasks while relying
    on a coarse open-loop policy for the segments where precision is not necessary.
    We train the policy using only 180 human demonstrations that are roughly 2 seconds
    each. Results on a da Vinci Research Kit suggest that combining the coarse policy
    with half a second of corrections from the …
- title: '{TEGRA}: Efficient {Ad-Hoc} analytics on evolving graphs'
  authors: Anand Padmanabha Iyer and Qifan Pu and Kishan Patel and Joseph E Gonzalez
    and Ion Stoica
  venue: 18th USENIX Symposium on Networked Systems Design and Implementation (NSDI
    21)
  year: ''
  citations: 37
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:tYavs44e6CUC
  abstract: Several emerging evolving graph application workloads demand support for
    efficient ad-hoc analytics—the ability to perform ad-hoc queries on arbitrary
    time windows of the graph. We present TEGRA, a system that enables efficient ad-hoc
    window operations on evolving graphs. TEGRA allows efficient access to the state
    of the graph at arbitrary windows, and significantly accelerates ad-hoc window
    queries by using a compact in-memory representation for both graph and intermediate
    computation state. For this, it leverages persistent data structures to build
    a versioned, distributed graph state store, and couples it with an incremental
    computation model which can leverage these compact states. For users, it exposes
    these compact states using Timelapse, a natural abstraction. We evaluate TEGRA
    against existing evolving graph analysis techniques, and show that it significantly
    outperforms state-of-the-art systems (by up to 30×) for ad-hoc window operation
    workloads.
- title: 'Visual transformers: Token-based image representation and processing for
    computer vision. arXiv'
  authors: B Wu and C Xu and X Dai and A Wan and P Zhang and Z Yan and M Tomizuka
    and J Gonzalez and K Keutzer and P Vajda
  venue: arXiv preprint arXiv:2006.03677
  year: ''
  citations: 37
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:foquWX3nUaYC
  abstract: ''
- title: Optimistic concurrency control for distributed unsupervised learning
  authors: Xinghao Pan and Joseph E Gonzalez and Stefanie Jegelka and Tamara Broderick
    and Michael I Jordan
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 37
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:tS2w5q8j5-wC
  abstract: 'Research on distributed machine learning algorithms has focused primarily
    on one of two extremes---algorithms that obey strict concurrency constraints or
    algorithms that obey few or no such constraints. We consider an intermediate alternative
    in which algorithms optimistically assume that conflicts are unlikely and if conflicts
    do arise a conflict-resolution protocol is invoked. We view this optimistic concurrency
    control''''paradigm as particularly appropriate for large-scale machine learning
    algorithms, particularly in the unsupervised setting. We demonstrate our approach
    in three problem areas: clustering, feature learning and online facility location.
    We evaluate our methods via large-scale experiments in a cluster computing environment."'
- title: Fairness in serving large language models
  authors: Ying Sheng and Shiyi Cao and Dacheng Li and Banghua Zhu and Zhuohan Li
    and Danyang Zhuo and Joseph E Gonzalez and Ion Stoica
  venue: 18th USENIX Symposium on Operating Systems Design and Implementation (OSDI
    24)
  year: ''
  citations: 36
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:NyGDZy8z5eUC
  abstract: High-demand LLM inference services (eg, ChatGPT and BARD) support a wide
    range of requests from short chat conversations to long document reading. To ensure
    that all client requests are processed fairly, most major LLM inference services
    have request rate limits, to ensure that no client can dominate the request queue.
    However, this rudimentary notion of fairness also results in under-utilization
    of the resources and poor client experience when there is spare capacity. While
    there is a rich literature on fair scheduling, serving LLMs presents new challenges
    due to their unpredictable request lengths and their unique batching characteristics
    on parallel accelerators. This paper introduces the definition of LLM serving
    fairness based on a cost function that accounts for the number of input and output
    tokens processed. To achieve fairness in serving, we propose a novel scheduling
    algorithm, the Virtual Token Counter (VTC), a fair scheduler based on the continuous
    batching mechanism. We prove a 2× tight upper bound on the service difference
    between two backlogged clients, adhering to the requirement of work-conserving.
    Through extensive experiments, we demonstrate the superior performance of VTC
    in ensuring fairness, especially in contrast to other baseline methods, which
    exhibit shortcomings under various conditions. The reproducible code is available
    at https://github. com/Ying1123/VTC-artifact.
- title: Using Language to Extend to Unseen Domains.
  authors: Lisa Dunlap and Clara Mohri and Devin Guillory and Han Zhang and Trevor
    Darrell and Joseph E Gonzalez and Aditi Raghunathan and Anna Rohrbach
  venue: ''
  year: ''
  citations: 36
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:DUooU5lO8OsC
  abstract: It is expensive to collect training data for every possible domain that
    a vision model may encounter when deployed. We instead consider how simply verbalizing
    the training domain (eg “photos of birds”) as well as domains we want to extend
    to but do not have data for (eg “paintings of birds”) can improve robustness.
    Using a multimodal model with a joint image and language embedding space, our
    method LADS learns a transformation of the image embeddings from the training
    domain to each unseen test domain, while preserving task relevant information.
    Without using any images from the unseen test domain, we show that over the extended
    domain containing both training and unseen test domains, LADS outperforms standard
    fine-tuning and ensemble approaches over a suite of four benchmarks targeting
    domain adaptation and dataset bias. Code is available at https://github. com/lisadunlap/LADS.
- title: Accelerating quadratic optimization with reinforcement learning
  authors: Jeffrey Ichnowski and Paras Jain and Bartolomeo Stellato and Goran Banjac
    and Michael Luo and Francesco Borrelli and Joseph E Gonzalez and Ion Stoica and
    Ken Goldberg
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 36
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Y5dfb0dijaUC
  abstract: 'First-order methods for quadratic optimization such as OSQP are widely
    used for large-scale machine learning and embedded optimal control, where many
    related problems must be rapidly solved. These methods face two persistent challenges:
    manual hyperparameter tuning and convergence time to high-accuracy solutions.
    To address these, we explore how Reinforcement Learning (RL) can learn a policy
    to tune parameters to accelerate convergence. In experiments with well-known QP
    benchmarks we find that our RL policy, RLQP, significantly outperforms state-of-the-art
    QP solvers by up to 3x. RLQP generalizes surprisingly well to previously unseen
    problems with varying dimension and structure from different applications, including
    the QPLIB, Netlib LP and Maros-M {\''e} sz {\''a} ros problems. Code, models,
    and videos are available at https://berkeleyautomation. github. io/rlqp/.'
- title: Data-efficient language-supervised zero-shot learning with self-distillation
  authors: Ruizhe Cheng and Bichen Wu and Peizhao Zhang and Peter Vajda and Joseph
    E Gonzalez
  venue: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
  year: ''
  citations: 36
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:tKAzc9rXhukC
  abstract: Traditional computer vision models are trained to predict a fixed set
    of predefined categories. Recently, natural language has been shown to be a broader
    and richer source of supervision that provides finer descriptions to visual concepts
    than supervised" gold" labels. Previous works, such as CLIP, use a simple pretraining
    task of predicting the pairings between images and text captions. CLIP, however,
    is data hungry and requires more than 400M image text pairs for training. We propose
    a data-efficient contrastive distillation method that uses soft labels to learn
    from noisy image-text pairs. Our model transfers knowledge from pretrained image
    and sentence encoders and achieves strong performance with only 3M image text
    pairs, 133x smaller than CLIP. Our method exceeds the previous SoTA of general
    zero-shot learning on ImageNet 21k+ 1k by 73% relatively with a ResNet50 image
    encoder and DeCLUTR text encoder. We also beat CLIP by 10.5% relatively on zero-shot
    evaluation on Google Open Images (19,958 classes).
- title: Taxonomizing local versus global structure in neural network loss landscapes
  authors: Yaoqing Yang and Liam Hodgkinson and Ryan Theisen and Joe Zou and Joseph
    E Gonzalez and Kannan Ramchandran and Michael W Mahoney
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 35
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:PELIpwtuRlgC
  abstract: 'Viewing neural network models in terms of their loss landscapes has a
    long history in the statistical mechanics approach to learning, and in recent
    years it has received attention within machine learning proper. Among other things,
    local metrics (such as the smoothness of the loss landscape) have been shown to
    correlate with global properties of the model (such as good generalization performance).
    Here, we perform a detailed empirical analysis of the loss landscape structure
    of thousands of neural network models, systematically varying learning tasks,
    model architectures, and/or quantity/quality of data. By considering a range of
    metrics that attempt to capture different aspects of the loss landscape, we demonstrate
    that the best test accuracy is obtained when: the loss landscape is globally well-connected;
    ensembles of trained models are more similar to each other; and models converge
    to locally smooth regions. We also show that globally poorly-connected landscapes
    can arise when models are small or when they are trained to lower quality data;
    and that, if the loss landscape is globally poorly-connected, then training to
    zero loss can actually lead to worse test accuracy. Our detailed empirical results
    shed light on phases of learning (and consequent double descent behavior), fundamental
    versus incidental determinants of good generalization, the role of load-like and
    temperature-like parameters in the learning process, different influences on the
    loss landscape from model and data, and the relationships between local and global
    metrics, all topics of recent interest.'
- title: Learning to smooth and fold real fabric using dense object descriptors trained
    on synthetic color images
  authors: Aditya Ganapathi and Priya Sundaresan and Brijen Thananjeyan and Ashwin
    Balakrishna and Daniel Seita and Jennifer Grannen and Minho Hwang and Ryan Hoque
    and Joseph E Gonzalez and Nawid Jamali and Katsu Yamane and Soshi Iba and Ken
    Goldberg
  venue: arXiv preprint arXiv:2003.12698
  year: ''
  citations: 35
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:GnPB-g6toBAC
  abstract: Robotic fabric manipulation is challenging due to the infinite dimensional
    configuration space and complex dynamics. In this paper, we learn visual representations
    of deformable fabric by training dense object descriptors that capture correspondences
    across images of fabric in various configurations. The learned descriptors capture
    higher level geometric structure, facilitating design of explainable policies.
    We demonstrate that the learned representation facilitates multistep fabric smoothing
    and folding tasks on two real physical systems, the da Vinci surgical robot and
    the ABB YuMi given high level demonstrations from a supervisor. The system achieves
    a 78.8% average task success rate across six fabric manipulation tasks. See https://tinyurl.
    com/fabric-descriptors for supplementary material and videos.
- title: Contextual multi-armed bandits for link adaptation in cellular networks
  authors: Vidit Saxena and Joakim Jaldén and Joseph E Gonzalez and Mats Bengtsson
    and Hugo Tullberg and Ion Stoica
  venue: ''
  year: ''
  citations: 35
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:R3hNpaxXUhUC
  abstract: Cellular networks dynamically adjust the transmission parameters for a
    wireless link in response to its time-varying channel state. This is known as
    link adaptation, where the typical goal is to maximize the link throughput. State-of-the-art
    outer loop link adaptation (OLLA) selects the optimal transmission parameters
    based on an approximate, offline, model of the wireless link. Further, OLLA refines
    the offline model by dynamically compensating any deviations from the observed
    link performance. However, in practice, OLLA suffers from slow convergence and
    a sub-optimal link throughput. In this paper, we propose a link adaptation approach
    that overcomes the shortcomings of OLLA through a novel learning scheme. Our approach
    relies on contextual multi-armed bandits (MAB), where the context vector is composed
    of the instantaneous wireless channel state along with side information about
    the link. For a given …
- title: On optimizing the communication of model parallelism
  authors: Yonghao Zhuang and Lianmin Zheng and Zhuohan Li and Eric Xing and Qirong
    Ho and Joseph Gonzalez and Ion Stoica and Hao Zhang and Hexu Zhao
  venue: Proceedings of Machine Learning and Systems
  year: ''
  citations: 34
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:2VqYfGB8ITEC
  abstract: 'We study a novel and important communication pattern in large-scale model-parallel
    deep learning (DL), which we call cross-mesh resharding. This pattern emerges
    when the two paradigms of model parallelism–intra-operator and inter-operator
    parallelism–are combined to support large models on large clusters. In cross-mesh
    resharding, a sharded tensor needs to be sent from a source device mesh to a destination
    device mesh, on which the tensor may be distributed with the same or different
    layouts. We formalize this as a many-to-many multicast communication problem,
    and show that existing approaches either are sub-optimal or do not generalize
    to different network topologies or tensor layouts, which result from different
    model architectures and parallelism strategies. We then propose two contributions
    to address cross-mesh resharding: an efficient broadcast-based communication system,
    and an “overlapping-friendly" pipeline schedule. On microbenchmarks, our overall
    system outperforms existing ones by up to 10x across various tensor and mesh layouts.
    On end-to-end training of two large models, GPT-3 and U-Transformer, we improve
    throughput by 10% and 50%, respectively.'
- title: The sky above the clouds
  authors: Sarah Chasins and Alvin Cheung and Natacha Crooks and Ali Ghodsi and Ken
    Goldberg and Joseph E Gonzalez and Joseph M Hellerstein and Michael I Jordan and
    Anthony D Joseph and Michael W Mahoney and Aditya Parameswaran and David Patterson
    and Raluca Ada Popa and Koushik Sen and Scott Shenker and Dawn Song and Ion Stoica
  venue: arXiv preprint arXiv:2205.07147
  year: ''
  citations: 34
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:olpn-zPbct0C
  abstract: Technology ecosystems often undergo significant transformations as they
    mature. For example, telephony, the Internet, and PCs all started with a single
    provider, but in the United States each is now served by a competitive market
    that uses comprehensive and universal technology standards to provide compatibility.
    This white paper presents our view on how the cloud ecosystem, barely over fifteen
    years old, could evolve as it matures.
- title: 'Contingencies from observations: Tractable contingency planning with learned
    behavior models'
  authors: Nicholas Rhinehart and Jeff He and Charles Packer and Matthew A Wright
    and Rowan McAllister and Joseph E Gonzalez and Sergey Levine
  venue: 2021 IEEE International Conference on Robotics and Automation (ICRA)
  year: ''
  citations: 34
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:uLbwQdceFCQC
  abstract: 'Humans have a remarkable ability to accurately reason about future events,
    including the behaviors and states of mind of other agents. Consider driving a
    car through a busy intersection: it is necessary to reason about the physics of
    the vehicle, the intentions of other drivers, and their beliefs about your own
    intentions. For example, if you signal a turn, another driver might yield to you;
    or if you enter the passing lane, another driver might decelerate to give you
    room to merge in front. Competent drivers must plan how they can safely react
    to a variety of potential future behaviors of other agents before they make their
    next move. This requires contingency planning: explicitly planning a set of conditional
    actions that depend on the stochastic outcome of future events. In this work,
    we develop a general-purpose contingency planner that is learned end-to-end using
    high-dimensional scene observations and low …'
- title: 'Cloud programming simplified: A berkeley view on serverless computing. arXiv
    2019'
  authors: Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-Che
    Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira
    and Karl Krauth and Neeraja Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa
    and Ion Stoica and David A Patterson
  venue: arXiv preprint arXiv:1902.03383
  year: ''
  citations: 34
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:yB1At4FlUx8C
  abstract: ''
- title: 'C5t5: Controllable generation of organic molecules with transformers'
  authors: Daniel Rothchild and Alex Tamkin and Julie Yu and Ujval Misra and Joseph
    Gonzalez
  venue: arXiv preprint arXiv:2108.10307
  year: ''
  citations: 33
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:M7yex6snE4oC
  abstract: 'Methods for designing organic materials with desired properties have
    high potential impact across fields such as medicine, renewable energy, petrochemical
    engineering, and agriculture. However, using generative modeling to design substances
    with desired properties is difficult because candidate compounds must satisfy
    multiple constraints, including synthetic accessibility and other metrics that
    are intuitive to domain experts but challenging to quantify. We propose C5T5,
    a novel self-supervised pretraining method that enables transformers to make zero-shot
    select-and-replace edits, altering organic substances towards desired property
    values. C5T5 operates on IUPAC names -- a standardized molecular representation
    that intuitively encodes rich structural information for organic chemists but
    that has been largely ignored by the ML community. Our technique requires no edited
    molecule pairs to train and only a rough estimate of molecular properties, and
    it has the potential to model long-range dependencies and symmetric molecular
    structures more easily than graph-based methods. C5T5 also provides a powerful
    interface to domain experts: it grants users fine-grained control over the generative
    process by selecting and replacing IUPAC name fragments, which enables experts
    to leverage their intuitions about structure-activity relationships. We demonstrate
    C5T5''s effectiveness on four physical properties relevant for drug discovery,
    showing that it learns successful and chemically intuitive strategies for altering
    molecules towards desired property values.'
- title: Robust object detection via instance-level temporal cycle confusion
  authors: Xin Wang and Thomas E Huang and Benlin Liu and Fisher Yu and Xiaolong Wang
    and Joseph E Gonzalez and Trevor Darrell
  venue: Proceedings of the IEEE/CVF International Conference on Computer Vision
  year: ''
  citations: 33
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ye4kPcJQO24C
  abstract: Building reliable object detectors that are robust to domain shifts, such
    as various changes in context, viewpoint, and object appearances, is critical
    for real-world applications. In this work, we study the effectiveness of auxiliary
    self-supervised tasks to improve the out-of-distribution generalization of object
    detectors. Inspired by the principle of maximum entropy, we introduce a novel
    self-supervised task, instance-level temporal cycle confusion (CycConf), which
    operates on the region features of the object detectors. For each object, the
    task is to find the most different object proposals in the adjacent frame in a
    video and then cycle back to itself for self-supervision. CycConf encourages the
    object detector to explore invariant structures across instances under various
    motions, which leads to improved model robustness in unseen domains at test time.
    We observe consistent out-of-domain performance improvements when training object
    detectors in tandem with self-supervised tasks on various domain adaptation benchmarks
    with static images (Cityscapes, Foggy Cityscapes, Sim10K) and large-scale video
    datasets (BDD100K and Waymo open data). The code and models are released at https://xinw.
    ai/cyc-conf.
- title: 'Cloud Programming Simplified: A Berkeley View on Serverless Computing. CoRR
    abs/1902.03383 (2019)'
  authors: Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-che
    Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira
    and Karl Krauth and Neeraja Jayant Yadwadkar and Joseph E Gonzalez and Raluca
    Ada Popa and Ion Stoica and David A Patterson
  venue: arXiv preprint arXiv:1902.03383
  year: ''
  citations: 33
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:9vf0nzSNQJEC
  abstract: ''
- title: Fog robotics algorithms for distributed motion planning using lambda serverless
    computing
  authors: Jeffrey Ichnowski and William Lee and Victor Murta and Samuel Paradis and
    Ron Alterovitz and Joseph E Gonzalez and Ion Stoica and Ken Goldberg
  venue: 2020 IEEE International Conference on Robotics and Automation (ICRA)
  year: ''
  citations: 32
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:V3AGJWp-ZtQC
  abstract: For robots using motion planning algorithms such as RRT and RRT*, the
    computational load can vary by orders of magnitude as the complexity of the local
    environment changes. To adaptively provide such computation, we propose Fog Robotics
    algorithms in which cloud-based serverless lambda computing provides parallel
    computation on demand. To use this parallelism, we propose novel motion planning
    algorithms that scale effectively with an increasing number of serverless computers.
    However, given that the allocation of computing is typically bounded by both monetary
    and time constraints, we show how prior learning can be used to efficiently allocate
    resources at runtime. We demonstrate the algorithms and application of learned
    parallel allocation in both simulation and with the Fetch commercial mobile manipulator
    using Amazon Lambda to complete a sequence of sporadically computationally intensive
    …
- title: 'Hemingway: Modeling distributed optimization algorithms'
  authors: Xinghao Pan and Shivaram Venkataraman and Zizheng Tai and Joseph Gonzalez
  venue: arXiv preprint arXiv:1702.05865
  year: ''
  citations: 32
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:kNdYIx-mwKoC
  abstract: 'Distributed optimization algorithms are widely used in many industrial
    machine learning applications. However choosing the appropriate algorithm and
    cluster size is often difficult for users as the performance and convergence rate
    of optimization algorithms vary with the size of the cluster. In this paper we
    make the case for an ML-optimizer that can select the appropriate algorithm and
    cluster size to use for a given problem. To do this we propose building two models:
    one that captures the system level characteristics of how computation, communication
    change as we increase cluster sizes and another that captures how convergence
    rates change with cluster sizes. We present preliminary results from our prototype
    implementation called Hemingway and discuss some of the challenges involved in
    developing such a system.'
- title: Spectral decomposition representation for reinforcement learning
  authors: Tongzheng Ren and Tianjun Zhang and Lisa Lee and Joseph E Gonzalez and
    Dale Schuurmans and Bo Dai
  venue: arXiv preprint arXiv:2208.09515
  year: ''
  citations: 30
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:LO7wyVUgiFcC
  abstract: Representation learning often plays a critical role in reinforcement learning
    by managing the curse of dimensionality. A representative class of algorithms
    exploits a spectral decomposition of the stochastic transition dynamics to construct
    representations that enjoy strong theoretical properties in an idealized setting.
    However, current spectral methods suffer from limited applicability because they
    are constructed for state-only aggregation and derived from a policy-dependent
    transition kernel, without considering the issue of exploration. To address these
    issues, we propose an alternative spectral method, Spectral Decomposition Representation
    (SPEDER), that extracts a state-action abstraction from the dynamics without inducing
    spurious dependence on the data collection policy, while also balancing the exploration-versus-exploitation
    trade-off during learning. A theoretical analysis establishes the sample efficiency
    of the proposed algorithm in both the online and offline settings. In addition,
    an experimental investigation demonstrates superior performance over current state-of-the-art
    algorithms across several benchmarks.
- title: On guiding visual attention with language specification
  authors: Suzanne Petryk and Lisa Dunlap and Keyan Nasseri and Joseph Gonzalez and
    Trevor Darrell and Anna Rohrbach
  venue: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
  year: ''
  citations: 30
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:SpbeaW3--B0C
  abstract: While real world challenges typically define visual categories with language
    words or phrases, most visual classification methods define categories with numerical
    indicies. However, the language specification of the classes provides an especially
    useful prior for biased and noisy datasets, where it can help disambiguate what
    features are task-relevant. Recently, large-scale multimodal models have been
    shown to recognize a wide variety of high-level concepts from a language specification
    even without additional image training data, but they are often unable to distinguish
    classes for more fine-grained tasks. CNNs, in contrast, can extract subtle image
    features that are required for fine-grained discrimination, but will overfit to
    any bias or noise in datasets. Our insight is to use high-level language specification
    as advice for constraining the prediction evidence to task-relevant features,
    instead of distractors. To do this, we ground task-relevant words or phrases with
    attention maps from a pretrained large-scale model. We then use this grounding
    to supervise a classifier's spatial attention away from distracting context. We
    show that supervising spatial attention in this way improves performance on classification
    tasks with biased and noisy data, including 3-15% worst-group accuracy improvements
    and 41-45% relative improvements on fairness metrics.
- title: Untangling dense non-planar knots by learning manipulation features and recovery
    policies
  authors: Priya Sundaresan and Jennifer Grannen and Brijen Thananjeyan and Ashwin
    Balakrishna and Jeffrey Ichnowski and Ellen Novoseller and Minho Hwang and Michael
    Laskey and Joseph E Gonzalez and Ken Goldberg
  venue: arXiv preprint arXiv:2107.08942
  year: ''
  citations: 30
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:wbdj-CoPYUoC
  abstract: Robot manipulation for untangling 1D deformable structures such as ropes,
    cables, and wires is challenging due to their infinite dimensional configuration
    space, complex dynamics, and tendency to self-occlude. Analytical controllers
    often fail in the presence of dense configurations, due to the difficulty of grasping
    between adjacent cable segments. We present two algorithms that enhance robust
    cable untangling, LOKI and SPiDERMan, which operate alongside HULK, a high-level
    planner from prior work. LOKI uses a learned model of manipulation features to
    refine a coarse grasp keypoint prediction to a precise, optimized location and
    orientation, while SPiDERMan uses a learned model to sense task progress and apply
    recovery actions. We evaluate these algorithms in physical cable untangling experiments
    with 336 knots and over 1500 actions on real cables using the da Vinci surgical
    robot. We find that the combination of HULK, LOKI, and SPiDERMan is able to untangle
    dense overhand, figure-eight, double-overhand, square, bowline, granny, stevedore,
    and triple-overhand knots. The composition of these methods successfully untangles
    a cable from a dense initial configuration in 68.3% of 60 physical experiments
    and achieves 50% higher success rates than baselines from prior work. Supplementary
    material, code, and videos can be found at https://tinyurl.com/rssuntangling.
- title: 'Rubberband: cloud-based hyperparameter tuning'
  authors: Ujval Misra and Richard Liaw and Lisa Dunlap and Romil Bhardwaj and Kirthevasan
    Kandasamy and Joseph E Gonzalez and Ion Stoica and Alexey Tumanov
  venue: ''
  year: ''
  citations: 30
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:BwyfMAYsbu0C
  abstract: Hyperparameter tuning is essential to achieving state-of-the-art accuracy
    in machine learning (ML), but requires substantial compute resources to perform.
    Existing systems primarily focus on effectively allocating resources for a hyperparameter
    tuning job under fixed resource constraints. We show that the available parallelism
    in such jobs changes dynamically over the course of execution and, therefore,
    presents an opportunity to leverage the elasticity of the cloud.In particular,
    we address the problem of minimizing the financial cost of executing a hyperparameter
    tuning job, subject to a time constraint. We present RubberBand---the first framework
    for cost-efficient, elastic execution of hyperparameter tuning jobs in the cloud.
    RubberBand utilizes performance instrumentation and cloud pricing to model job
    completion time and cost prior to runtime, and generate a cost-efficient, elastic
    resource allocation plan …
- title: Optimizing prediction serving on low-latency serverless dataflow
  authors: Vikram Sreekanti and Harikaran Subbaraj and Chenggang Wu and Joseph E Gonzalez
    and Joseph M Hellerstein
  venue: arXiv preprint arXiv:2007.05832
  year: ''
  citations: 30
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:uc_IGeMz5qoC
  abstract: Prediction serving systems are designed to provide large volumes of low-latency
    inferences machine learning models. These systems mix data processing and computationally
    intensive model inference and benefit from multiple heterogeneous processors and
    distributed computing resources. In this paper, we argue that a familiar dataflow
    API is well-suited to this latency-sensitive task, and amenable to optimization
    even with unmodified black-box ML models. We present the design of Cloudflow,
    a system that provides this API and realizes it on an autoscaling serverless backend.
    Cloudflow transparently implements performance-critical optimizations including
    operator fusion and competitive execution. Our evaluation shows that Cloudflow's
    optimizations yield significant performance improvements on synthetic workloads
    and that Cloudflow outperforms state-of-the-art prediction serving systems by
    as much as 2x on real-world prediction pipelines, meeting latency goals of demanding
    applications like real-time video analysis.
- title: Phase II trial of a novel capecitabine dosing schedule in combination with
    lapatinib for the treatment of patients with HER2-positive metastatic breast cancer
  authors: Devika Gajria and Joseph Gonzalez and Kimberly Feigin and Sujata Patil
    and Carol Chen and Maria Theodoulou and Pamela Drullinsky and Gabriella D’Andrea
    and Diana Lake and Larry Norton and Clifford A Hudis and Tiffany A Traina
  venue: Breast cancer research and treatment
  year: ''
  citations: 30
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:1Ye0OR6EYb4C
  abstract: Our group applied mathematical modeling to capecitabine dosing and predicted
    7 days of treatment followed by 7 days of rest (7–7) would improve efficacy and
    minimize toxicity. The conventional schedule of capecitabine limits full dosing
    in combination with other agents due to toxicity. Lapatinib inhibits the tyrosine
    kinase of HER2 and has activity when added to conventionally scheduled capecitabine
    for the treatment of patients with trastuzumab-refractory, HER2-positive, metastatic
    breast cancer (MBC). We performed this study to evaluate the activity and tolerability
    of capecitabine 7–7 with lapatinib in patients with trastuzumab-refractory MBC.
    Eligible patients had measurable, HER2-positive, MBC that progressed following
    exposure to trastuzumab. Treatment consisted of capecitabine 2,000 mg orally twice
    daily, 7–7 and lapatinib 1,250 mg orally daily. The primary endpoint was response
    rate …
- title: 'Graphlab: A distributed framework for machine learning in the cloud'
  authors: Yucheng Low and Joseph Gonzalez and Aapo Kyrola and Danny Bickson and Carlos
    Guestrin
  venue: arXiv preprint arXiv:1107.0922
  year: ''
  citations: 30
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:SP6oXDckpogC
  abstract: Machine Learning (ML) techniques are indispensable in a wide range of
    fields. Unfortunately, the exponential increase of dataset sizes are rapidly extending
    the runtime of sequential algorithms and threatening to slow future progress in
    ML. With the promise of affordable large-scale parallel computing, Cloud systems
    offer a viable platform to resolve the computational challenges in ML. However,
    designing and implementing efficient, provably correct distributed ML algorithms
    is often prohibitively challenging. To enable ML researchers to easily and efficiently
    use parallel systems, we introduced the GraphLab abstraction which is designed
    to represent the computational patterns in ML algorithms while permitting efficient
    parallel and distributed implementations. In this paper we provide a formal description
    of the GraphLab parallel abstraction and present an efficient distributed implementation.
    We conduct a comprehensive evaluation of GraphLab on three state-of-the-art ML
    algorithms using real large-scale data and a 64 node EC2 cluster of 512 processors.
    We find that GraphLab achieves orders of magnitude performance gains over Hadoop
    while performing comparably or superior to hand-tuned MPI implementations.
- title: 'CLAIR: Evaluating image captions with large language models'
  authors: David Chan and Suzanne Petryk and Joseph E Gonzalez and Trevor Darrell
    and John Canny
  venue: arXiv preprint arXiv:2310.12971
  year: ''
  citations: 29
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:tH6gc1N1XXoC
  abstract: The evaluation of machine-generated image captions poses an interesting
    yet persistent challenge. Effective evaluation measures must consider numerous
    dimensions of similarity, including semantic relevance, visual structure, object
    interactions, caption diversity, and specificity. Existing highly-engineered measures
    attempt to capture specific aspects, but fall short in providing a holistic score
    that aligns closely with human judgments. Here, we propose CLAIR, a novel method
    that leverages the zero-shot language modeling capabilities of large language
    models (LLMs) to evaluate candidate captions. In our evaluations, CLAIR demonstrates
    a stronger correlation with human judgments of caption quality compared to existing
    measures. Notably, on Flickr8K-Expert, CLAIR achieves relative correlation improvements
    over SPICE of 39.6% and over image-augmented methods such as RefCLIP-S of 18.3%.
    Moreover, CLAIR provides noisily interpretable results by allowing the language
    model to identify the underlying reasoning behind its assigned score. Code is
    available at https://davidmchan.github.io/clair/
- title: 'Fogros 2: An adaptive and extensible platform for cloud and fog robotics
    using ros 2'
  authors: Jeffrey Ichnowski and Kaiyuan Chen and Karthik Dharmarajan and Simeon Adebola
    and Michael Danielczuk and Vıctor Mayoral-Vilches and Hugo Zhan and Derek Xu and
    Ramtin Ghassemi and John Kubiatowicz and Ion Stoica and Joseph Gonzalez and Ken
    Goldberg
  venue: Proceedings IEEE International Conference on Robotics and Automation
  year: ''
  citations: 29
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:e_rmSamDkqQC
  abstract: Mobility, power, and price points often dictate that robots do not have
    sufficient computing power on board to run contemporary robot algorithms at desired
    rates. Cloud computing providers such as AWS, GCP, and Azure offer immense computing
    power on demand, but tapping into that power from a robot is non-trivial. We present
    FogROS2, an open-source platform to facilitate cloud and fog robotics that is
    compatible with the emerging Robot Operating System 2 (ROS 2) standard. FogROS2
    is completely redesigned and distinct from its predecessor FogROS1 in 9 ways,
    and has lower latency, overhead, and startup times; improved usability, and additional
    automa-tion, such as region and computer type selection. Additionally, FogROS2
    was added to the official distribution of ROS 2, gaining performance, timing,
    and additional improvements associated with ROS 2. In examples, FogROS2 reduces
    SLAM latency by 50 %, reduces grasp planning time from 14 s to 1.2 s, and speeds
    up motion planning 28x. When compared to FogROS1, FogROS2 reduces network utilization
    by up to 3.8x, improves startup time by 63 %, and network round-trip latency by
    97 %for images using video compression. The source code, examples, and documentation
    for FogROS2 are available at https://github.com/BerkeleyAutomation/FogROS2, and
    is available through the official ROS 2 repository at https://index.ros.org/p/fogros2/
- title: 'Visual transformers: Where do transformers really belong in vision models?'
  authors: Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang
    and Zhicheng Yan and Masayoshi Tomizuka and Joseph E Gonzalez and Kurt Keutzer
    and Peter Vajda
  venue: Proceedings of the IEEE/CVF International Conference on Computer Vision
  year: ''
  citations: 29
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:35r97b3x0nAC
  abstract: 'A recent trend in computer vision is to replace convolutions with transformers.
    However, the performance gain of transformers is attained at a steep cost, requiring
    GPU years and hundreds of millions of samples for training. This excessive resource
    usage compensates for a misuse of transformers: Transformers densely model relationships
    between its inputs--ideal for late stages of a neural network, when concepts are
    sparse and spatially-distant, but extremely inefficient for early stages of a
    network, when patterns are redundant and localized. To address these issues, we
    leverage the respective strengths of both operations, building convolution-transformer
    hybrids. Critically, in sharp contrast to pixel-space transformers, our Visual
    Transformer (VT) operates in a semantic token space, judiciously attending to
    different image parts based on context. Our VTs significantly outperforms baselines:
    On ImageNet, our VT-ResNets outperform convolution-only ResNet by 4.6 to 7 points
    and transformer-only ViT-B by 2.6 points with 2.5 times fewer FLOPs, 2.1 times
    fewer parameters. For semantic segmentation on LIP and COCO-stuff, VT-based feature
    pyramid networks (FPN) achieve 0.35 points higher mIoU while reducing the FPN
    module''s FLOPs by 6.5 x.'
- title: 'Sysml: The new frontier of machine learning systems'
  authors: Alexander Ratner and Dan Alistarh and Gustavo Alonso and Peter Bailis and
    Sarah Bird and Nicholas Carlini and Bryan Catanzaro and Eric Chung and Bill Dally
    and Jeff Dean
  venue: arXiv preprint arXiv:1904.03257
  year: ''
  citations: 29
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:CHSYGLWDkRkC
  abstract: ''
- title: Self-correcting llm-controlled diffusion models
  authors: Tsung-Han Wu and Long Lian and Joseph E Gonzalez and Boyi Li and Trevor
    Darrell
  venue: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
  year: ''
  citations: 27
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:F1b5ZUV5XREC
  abstract: 'Text-to-image generation has witnessed significant progress with the
    advent of diffusion models. Despite the ability to generate photorealistic images
    current text-to-image diffusion models still often struggle to accurately interpret
    and follow complex input text prompts. In contrast to existing models that aim
    to generate images only with their best effort we introduce Self-correcting LLM-controlled
    Diffusion (SLD). SLD is a framework that generates an image from the input prompt
    assesses its alignment with the prompt and performs self-corrections on the inaccuracies
    in the generated image. Steered by an LLM controller SLD turns text-to-image generation
    into an iterative closed-loop process ensuring correctness in the resulting image.
    SLD is not only training-free but can also be seamlessly integrated with diffusion
    models behind API access such as DALL-E 3 to further boost the performance of
    state-of-the-art diffusion models. Experimental results show that our approach
    can rectify a majority of incorrect generations particularly in generative numeracy
    attribute binding and spatial relationships. Furthermore by simply adjusting the
    instructions to the LLM SLD can perform image editing tasks bridging the gap between
    text-to-image generation and image editing pipelines. Our code is available at:
    https://self-correcting-llm-diffusion. github. io.'
- title: 'Gact: Activation compressed training for generic network architectures'
  authors: Xiaoxuan Liu and Lianmin Zheng and Dequan Wang and Yukuo Cen and Weize
    Chen and Xu Han and Jianfei Chen and Zhiyuan Liu and Jie Tang and Joey Gonzalez
    and Michael Mahoney and Alvin Cheung
  venue: International Conference on Machine Learning
  year: ''
  citations: 27
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:rmuvC79q63oC
  abstract: Training large neural network (NN) models requires extensive memory resources,
    and Activation Compression Training (ACT) is a promising approach to reduce training
    memory footprint. This paper presents GACT, an ACT framework to support a broad
    range of machine learning tasks for generic NN architectures with limited domain
    knowledge. By analyzing a linearized version of ACT’s approximate gradient, we
    prove the convergence of GACT without prior knowledge on operator type or model
    architecture. To make training stable, we propose an algorithm that decides the
    compression ratio for each tensor by estimating its impact on the gradient at
    run time. We implement GACT as a PyTorch library that readily applies to any NN
    architecture. GACT reduces the activation memory for convolutional NNs, transformers,
    and graph NNs by up to 8.1 x, enabling training with a 4.2 x to 24.7 x larger
    batch size, with negligible accuracy loss.
- title: Transformers are deep infinite-dimensional non-mercer binary kernel machines
  authors: Matthew A Wright and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2106.01506
  year: ''
  citations: 26
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:NJ774b8OgUMC
  abstract: Despite their ubiquity in core AI fields like natural language processing,
    the mechanics of deep attention-based neural networks like the Transformer model
    are not fully understood. In this article, we present a new perspective towards
    understanding how Transformers work. In particular, we show that the "dot-product
    attention" that is the core of the Transformer's operation can be characterized
    as a kernel learning method on a pair of Banach spaces. In particular, the Transformer's
    kernel is characterized as having an infinite feature dimension. Along the way
    we consider an extension of the standard kernel learning problem to a binary setting,
    where data come from two input domains and a response is defined for every cross-domain
    pair. We prove a new representer theorem for these binary kernel machines with
    non-Mercer (indefinite, asymmetric) kernels (implying that the functions learned
    are elements of reproducing kernel Banach spaces rather than Hilbert spaces),
    and also prove a new universal approximation theorem showing that the Transformer
    calculation can learn any binary non-Mercer reproducing kernel Banach space pair.
    We experiment with new kernels in Transformers, and obtain results that suggest
    the infinite dimensionality of the standard Transformer kernel is partially responsible
    for its performance. This paper's results provide a new theoretical understanding
    of a very important but poorly understood model in modern machine~learning.
- title: On-policy robot imitation learning from a converging supervisor
  authors: Ashwin Balakrishna and Brijen Thananjeyan and Jonathan Lee and Felix Li
    and Arsh Zahed and Joseph E Gonzalez and Ken Goldberg
  venue: Conference on Robot Learning
  year: ''
  citations: 26
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:eflP2zaiRacC
  abstract: Existing on-policy imitation learning algorithms, such as DAgger, assume
    access to a fixed supervisor. However, there are many settings where the supervisor
    may evolve during policy learning, such as a human performing a novel task or
    an improving algorithmic controller. We formalize imitation learning from a “converging
    supervisor” and provide sublinear static and dynamic regret guarantees against
    the best policy in hindsight with labels from the converged supervisor, even when
    labels during learning are only from intermediate supervisors. We then show that
    this framework is closely connected to a class of reinforcement learning (RL)
    algorithms known as dual policy iteration (DPI), which alternate between training
    a reactive learner with imitation learning and a model-based supervisor with data
    from the learner. Experiments suggest that when this framework is applied with
    the state-of-the-art deep model-based RL algorithm PETS as an improving supervisor,
    it outperforms deep RL baselines on continuous control tasks and provides up to
    an 80-fold speedup in policy evaluation.
- title: Disentangling dense multi-cable knots
  authors: Vainavi Viswanath and Jennifer Grannen and Priya Sundaresan and Brijen
    Thananjeyan and Ashwin Balakrishna and Ellen Novoseller and Jeffrey Ichnowski
    and Michael Laskey and Joseph E Gonzalez and Ken Goldberg
  venue: 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems
    (IROS)
  year: ''
  citations: 25
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:_Re3VWB3Y0AC
  abstract: Disentangling two or more cables often requires many steps to remove crossings
    between and within cables. We formalize the problem of disentangling multiple
    cables and present an algorithm, Iterative Reduction Of Non-planar Multiple cAble
    kNots (IRON-MAN), that outputs robot actions to remove crossings from multi-cable
    knotted structures. IRON-MAN uses a learned perception system inspired by prior
    work in single-cable untying to imitate a graph-based supervisor, and operates
    on RGB image inputs of the workspace. Given a sequence of images as input, the
    system can disentangle two-cable twists, three-cable braids, and knots of two
    or three cables, such as overhand, square, carrick bend, sheet bend, crown, and
    fisherman’s knots. IRON-MAN keeps track of task-relevant keypoints corresponding
    to cable endpoints and crossings and iteratively disentangles the cables by identifying
    and undoing crossings …
- title: Fast semantic segmentation on video using block motion-based feature interpolation
  authors: Samvit Jain and Joseph E Gonzalez
  venue: Proceedings of the European Conference on Computer Vision (ECCV) Workshops
  year: ''
  citations: 24
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:TQgYirikUcIC
  abstract: Convolutional networks optimized for accuracy on challenging, dense prediction
    tasks are often prohibitively slow to run on each frame in a video. The spatial
    similarity of nearby video frames, however, suggests opportunity to reuse computation.
    Existing work has explored basic feature reuse and feature warping based on optical
    flow, but has encountered limits to the speedup attainable with these techniques.
    In this paper, we present a new, two part approach to accelerating inference on
    video. First, we propose a fast feature propagation technique that utilizes the
    block motion vectors present in compressed video (eg H. 264 codecs) to cheaply
    propagate features from frame to frame. Second, we develop a novel feature estimation
    scheme, termed feature interpolation, that fuses features propagated from enclosing
    keyframes to render accurate feature estimates, even at sparse keyframe frequencies.
    We evaluate our system on the Cityscapes and CamVid datasets, comparing to both
    a frame-by-frame baseline and related work. We find that we are able to substantially
    accelerate semantic segmentation on video, achieving twice the average inference
    speed as prior work at any target accuracy level.
- title: VCG Mechanism Design with Unknown Agent Values under Stochastic Bandit Feedback
  authors: Kirthevasan Kandasamy and Joseph E Gonzalez and Michael I Jordan and Ion
    Stoica
  venue: arXiv preprint arXiv:2004.08924
  year: ''
  citations: 23
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:cK4Rrx0J3m0C
  abstract: We study a multi-round welfare-maximising mechanism design problem in
    instances where agents do not know their values. On each round, a mechanism first
    assigns an allocation each to a set of agents and charges them a price; at the
    end of the round, the agents provide (stochastic) feedback to the mechanism for
    the allocation they received. This setting is motivated by applications in cloud
    markets and online advertising where an agent may know her value for an allocation
    only after experiencing it. Therefore, the mechanism needs to explore different
    allocations for each agent so that it can learn their values, while simultaneously
    attempting to find the socially optimal set of allocations. Our focus is on truthful
    and individually rational mechanisms which imitate the classical VCG mechanism
    in the long run. To that end, we first define three notions of regret for the
    welfare, the individual utilities of each agent and that of the mechanism. We
    show that these three terms are interdependent via an  lower bound for the maximum
    of these three terms after  rounds of allocations, and describe an algorithm which
    essentially achieves this rate. Our framework also provides flexibility to control
    the pricing scheme so as to trade-off between the agent and seller regrets. Next,
    we define asymptotic variants for the truthfulness and individual rationality
    requirements and provide asymptotic rates to quantify the degree to which both
    properties are satisfied by the proposed algorithm.
- title: Composing meta-policies for autonomous driving using hierarchical deep reinforcement
    learning
  authors: Richard Liaw and Sanjay Krishnan and Animesh Garg and Daniel Crankshaw
    and Joseph E Gonzalez and Ken Goldberg
  venue: arXiv preprint arXiv:1711.01503
  year: ''
  citations: 23
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:sSrBHYA8nusC
  abstract: Rather than learning new control policies for each new task, it is possible,
    when tasks share some structure, to compose a "meta-policy" from previously learned
    policies. This paper reports results from experiments using Deep Reinforcement
    Learning on a continuous-state, discrete-action autonomous driving simulator.
    We explore how Deep Neural Networks can represent meta-policies that switch among
    a set of previously learned policies, specifically in settings where the dynamics
    of a new scenario are composed of a mixture of previously learned dynamics and
    where the state observation is possibly corrupted by sensing noise. We also report
    the results of experiments varying dynamics mixes, distractor policies, magnitudes/distributions
    of sensing noise, and obstacles. In a fully observed experiment, the meta-policy
    learning algorithm achieves 2.6x the reward achieved by the next best policy composition
    technique with 80% less exploration. In a partially observed experiment, the meta-policy
    learning algorithm converges after 50 iterations while a direct application of
    RL fails to converge even after 200 iterations.
- title: 'Extracellular tau oligomers produce an immediate impairment of LTP and memory.
    Sci Rep 6: 19393'
  authors: M Fá and D Puzzo and R Piacentini and A Staniszewski and H Zhang and MA
    Baltrons and DD Li Puma and I Chatterjee and J Li and F Saeed and HL Berman and
    C Ripoli and W Gulisano and J Gonzalez and H Tian and JA Costa and P Lopez and
    E Davidowitz and WH Yu and V Haroutunian and LM Brown and A Palmeri and EM Sigurdsson
    and KE Duff and AF Teich and LS Honig and M Sierks and JG Moe and L D’Adamio and
    C Grassi and NM Kanaan and PE Fraser and O Arancio
  venue: ''
  year: ''
  citations: 23
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:fbc8zXXH2BUC
  abstract: ''
- title: Neural code completion.(2016)
  authors: Chang Liu and Xin Wang and Richard Shin and Joseph E Gonzalez and Dawn
    Song
  venue: URL https://openreview. net/forum
  year: ''
  citations: 23
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:JQOojiI6XY0C
  abstract: ''
- title: Autonomously untangling long cables
  authors: Vainavi Viswanath and Kaushik Shivakumar and Justin Kerr and Brijen Thananjeyan
    and Ellen Novoseller and Jeffrey Ichnowski and Alejandro Escontrela and Michael
    Laskey and Joseph E Gonzalez and Ken Goldberg
  venue: arXiv preprint arXiv:2207.07813
  year: ''
  citations: 22
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Ri6SYOTghG4C
  abstract: 'Cables are ubiquitous in many settings and it is often useful to untangle
    them. However, cables are prone to self-occlusions and knots, making them difficult
    to perceive and manipulate. The challenge increases with cable length: long cables
    require more complex slack management to facilitate observability and reachability.
    In this paper, we focus on autonomously untangling cables up to 3 meters in length
    using a bilateral robot. We develop RGBD perception and motion primitives to efficiently
    untangle long cables and novel gripper jaws specialized for this task. We present
    Sliding and Grasping for Tangle Manipulation (SGTM), an algorithm that composes
    these primitives to iteratively untangle cables with success rates of 67% on isolated
    overhand and figure-eight knots and 50% on more complex configurations. Supplementary
    material, visualizations, and videos can be found at https://sites.google.com/view/rss-2022-untangling/home.'
- title: 'Flexible rule-based decomposition and metadata independence in modin: a
    parallel dataframe system'
  authors: Devin Petersohn and Dixin Tang and Rehan Durrani and Areg Melik-Adamyan
    and Joseph E Gonzalez and Anthony D Joseph and Aditya G Parameswaran
  venue: Proceedings of the VLDB Endowment
  year: ''
  citations: 22
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:eq2jaN3J8jMC
  abstract: Dataframes have become universally popular as a means to represent data
    in various stages of structure, and manipulate it using a rich set of operators---thereby
    becoming an essential tool in the data scientists' toolbox. However, dataframe
    systems, such as pandas, scale poorly---and are non-interactive on moderate to
    large datasets. We discuss our experiences developing Modin, our first cut at
    a parallel dataframe system, which already has users across several industries
    and over 1M downloads. Modin translates pandas functions into a core set of operators
    that are individually parallelized via columnar, row-wise, or cell-wise decomposition
    rules that we formalize in this paper. We also introduce metadata independence
    to allow metadata---such as order and type---to be decoupled from the physical
    representation and maintained lazily. Using rule-based decomposition and metadata
    independence, along with careful engineering, Modin is able to support pandas
    operations across both rows and columns on very large dataframes---unlike Koalas
    and Dask DataFrames that either break down or are unable to support such operations,
    while also being much faster than pandas.
- title: 'Mlsys: The new frontier of machine learning systems'
  authors: Alexander Ratner and Dan Alistarh and Gustavo Alonso and David G Andersen
    and Peter Bailis and Sarah Bird and Nicholas Carlini and Bryan Catanzaro and Jennifer
    Chayes and Eric Chung and Bill Dally and Jeff Dean and Inderjit S Dhillon and
    Alexandros Dimakis and Pradeep Dubey and Charles Elkan and Grigori Fursin and
    Gregory R Ganger and Lise Getoor and Phillip B Gibbons and Garth A Gibson and
    Joseph E Gonzalez and Justin Gottschlich and Song Han and Kim Hazelwood and Furong
    Huang and Martin Jaggi and Kevin Jamieson and Michael I Jordan and Gauri Joshi
    and Rania Khalaf and Jason Knight and Jakub Konečný and Tim Kraska and Arun Kumar
    and Anastasios Kyrillidis and Aparna Lakshmiratan and Jing Li and Samuel Madden
    and H Brendan McMahan and Erik Meijer and Ioannis Mitliagkas and Rajat Monga and
    Derek Murray and Kunle Olukotun and Dimitris Papailiopoulos and Gennady Pekhimenko
    and Theodoros Rekatsinas and Afshin Rostamizadeh and Christopher Ré and Christopher
    De Sa and Hanie Sedghi and Siddhartha Sen and Virginia Smith and Alex Smola and
    Dawn Song and Evan Sparks and Ion Stoica and Vivienne Sze and Madeleine Udell
    and Joaquin Vanschoren and Shivaram Venkataraman and Rashmi Vinayak and Markus
    Weimer and Andrew Gordon Wilson and Eric Xing and Matei Zaharia and Ce Zhang and
    Ameet Talwalkar
  venue: arXiv preprint arXiv:1904.03257
  year: ''
  citations: 22
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:qjMakFHDy7sC
  abstract: Machine learning (ML) techniques are enjoying rapidly increasing adoption.
    However, designing and implementing the systems that support ML models in real-world
    deployments remains a significant obstacle, in large part due to the radically
    different development and deployment profile of modern ML methods, and the range
    of practical concerns that come with broader adoption. We propose to foster a
    new systems machine learning research community at the intersection of the traditional
    systems and ML communities, focused on topics such as hardware systems for ML,
    software systems for ML, and ML optimized for metrics beyond predictive accuracy.
    To do this, we describe a new conference, MLSys, that explicitly targets research
    at the intersection of systems and machine learning with a program committee split
    evenly between experts in systems and ML, and an explicit focus on topics at the
    intersection of the two.
- title: Describing differences in image sets with natural language
  authors: Lisa Dunlap and Yuhui Zhang and Xiaohan Wang and Ruiqi Zhong and Trevor
    Darrell and Jacob Steinhardt and Joseph E Gonzalez and Serena Yeung-Levy
  venue: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
  year: ''
  citations: 21
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:AHdEip9mkN0C
  abstract: How do two sets of images differ? Discerning set-level differences is
    crucial for understanding model behaviors and analyzing datasets yet manually
    sifting through thousands of images is impractical. To aid in this discovery process
    we explore the task of automatically describing the differences between two sets
    of images which we term Set Difference Captioning. This task takes in image sets\mathcal
    D _A and\mathcal D _B and outputs a description that is more often true on\mathcal
    D _A than\mathcal D _B. We outline a two-stage approach that first proposes candidate
    difference descriptions from image sets and then re-ranks the candidates by checking
    how well they can differentiate the two sets. We introduce VisDiff which first
    captions the images and prompts a language model to propose candidate descriptions
    then re-ranks these descriptions using CLIP. To evaluate VisDiff we collect VisDiffBench
    a dataset with 187 paired image sets with ground truth difference descriptions.
    We apply VisDiff to various domains such as comparing datasets (eg ImageNet vs.
    ImageNetV2) comparing classification models (eg zero-shot CLIP vs. supervised
    ResNet) characterizing differences between generative models (eg StableDiffusionV1
    and V2) and discovering what makes images memorable. Using VisDiff we are able
    to find interesting and previously unknown differences in datasets and models
    demonstrating its utility in revealing nuanced insights.
- title: 'FogROS2: An adaptive platform for cloud and fog robotics using ros 2'
  authors: Jeffrey Ichnowski and Kaiyuan Chen and Karthik Dharmarajan and Simeon Adebola
    and Michael Danielczuk and Víctor Mayoral-Vilches and Nikhil Jha and Hugo Zhan
    and Edith LLontop and Derek Xu and Camilo Buscaron and John Kubiatowicz and Ion
    Stoica and Joseph Gonzalez and Ken Goldberg
  venue: 2023 IEEE International Conference on Robotics and Automation (ICRA)
  year: ''
  citations: 21
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:nZcligLrVowC
  abstract: Mobility, power, and price points often dictate that robots do not have
    sufficient computing power on board to run contemporary robot algorithms at desired
    rates. Cloud computing providers such as AWS, GCP, and Azure offer immense computing
    power and increasingly low latency on demand, but tapping into that power from
    a robot is non-trivial. We present FogROS2, an open-source platform to facilitate
    cloud and fog robotics that is included in the Robot Operating System 2 (ROS 2)
    distribution. FogROS2 is distinct from its predecessor FogROS1 in 9 ways, including
    lower latency, overhead, and startup times; improved usability, and additional
    automation, such as region and computer type selection. Additionally, FogROS2
    gains performance, timing, and additional improvements associated with ROS 2.
    In common robot applications, FogROS2 reduces SLAM latency by 50 %, reduces grasp
    planning time from 14 …
- title: 'Hindsight task relabelling: Experience replay for sparse reward meta-rl'
  authors: Charles Packer and Pieter Abbeel and Joseph E Gonzalez
  venue: Advances in neural information processing systems
  year: ''
  citations: 21
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:XiVPGOgt02cC
  abstract: Meta-reinforcement learning (meta-RL) has proven to be a successful framework
    for leveraging experience from prior tasks to rapidly learn new related tasks,
    however, current meta-RL approaches struggle to learn in sparse reward environments.
    Although existing meta-RL algorithms can learn strategies for adapting to new
    sparse reward tasks, the actual adaptation strategies are learned using hand-shaped
    reward functions, or require simple environments where random exploration is sufficient
    to encounter sparse reward. In this paper we present a formulation of hindsight
    relabelling for meta-RL, which relabels experience during meta-training to enable
    learning to learn entirely using sparse reward. We demonstrate the effectiveness
    of our approach on a suite of challenging sparse reward environments that previously
    required dense reward during meta-training to solve. Our approach solves these
    environments using the true sparse reward function, with performance comparable
    to training with a proxy dense reward function.
- title: 'Rexcam: Resource-efficient, cross-camera video analytics at scale'
  authors: Samvit Jain and Xun Zhang and Yuhao Zhou and Ganesh Ananthanarayanan and
    Junchen Jiang and Yuanchao Shu and Joseph Gonzalez
  venue: arXiv preprint arXiv:1811.01268
  year: ''
  citations: 21
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:pqnbT2bcN3wC
  abstract: 'Enterprises are increasingly deploying large camera networks for video
    analytics. Many target applications entail a common problem template: searching
    for and tracking an object or activity of interest (e.g. a speeding vehicle, a
    break-in) through a large camera network in live video. Such cross-camera analytics
    is compute and data intensive, with cost growing with the number of cameras and
    time. To address this cost challenge, we present ReXCam, a new system for efficient
    cross-camera video analytics. ReXCam exploits spatial and temporal locality in
    the dynamics of real camera networks to guide its inference-time search for a
    query identity. In an offline profiling phase, ReXCam builds a cross-camera correlation
    model that encodes the locality observed in historical traffic patterns. At inference
    time, ReXCam applies this model to filter frames that are not spatially and temporally
    correlated with the query identity''s current position. In the cases of occasional
    missed detections, ReXCam performs a fast-replay search on recently filtered video
    frames, enabling gracefully recovery. Together, these techniques allow ReXCam
    to reduce compute workload by 8.3x on an 8-camera dataset, and by 23x - 38x on
    a simulated 130-camera dataset. ReXCam has been implemented and deployed on a
    testbed of 5 AWS DeepLens cameras.'
- title: 'Mlbase: A distributed machine learning wrapper'
  authors: Ameet Talwalkar and Tim Kraska and Rean Griffith and John Duchi and Joseph
    Gonzalez and Denny Britz and Xinghao Pan and Virginia Smith and Evan Sparks and
    Andre Wibisono and Michael J Franklin and Michael I Jordan
  venue: NIPS Big Learning Workshop
  year: ''
  citations: 21
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Y0pCki6q_DkC
  abstract: Machine learning (ML) and statistical techniques are key to transforming
    big data into actionable knowledge. In spite of the modern primacy of data, the
    complexity of existing ML algorithms is often overwhelming—many users do not understand
    the trade-offs and challenges of parameterizing and choosing between different
    learning techniques. Furthermore, existing scalable systems that support machine
    learning are typically not accessible to ML researchers without a strong background
    in distributed systems and low-level primitives. In this work, we present our
    vision for MLbase, a novel system harnessing the power of machine learning for
    both end-users and ML researchers. MLbase provides (1) a simple declarative way
    to specify ML tasks,(2) a novel optimizer to select and dynamically adapt the
    choice of learning algorithm,(3) a set of high-level operators to enable ML researchers
    to scalably implement a wide range of ML methods without deep systems knowledge,
    and (4) a new run-time optimized for the data-access patterns of these high-level
    operators.
- title: Llm-assisted code cleaning for training accurate code generators
  authors: Naman Jain and Tianjun Zhang and Wei-Lin Chiang and Joseph E Gonzalez and
    Koushik Sen and Ion Stoica
  venue: arXiv preprint arXiv:2311.14904
  year: ''
  citations: 19
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:LgRImbQfgY4C
  abstract: Natural language to code generation is an important application area of
    LLMs and has received wide attention from the community. The majority of relevant
    studies have exclusively concentrated on increasing the quantity and functional
    correctness of training sets while disregarding other stylistic elements of programs.
    More recently, data quality has garnered a lot of interest and multiple works
    have showcased its importance for improving performance. In this work, we investigate
    data quality for code and find that making the code more structured and readable
    leads to improved code generation performance of the system. We build a novel
    data-cleaning pipeline that uses these principles to transform existing programs
    by 1.) renaming variables, 2.) modularizing and decomposing complex code into
    smaller helper sub-functions, and 3.) inserting natural-language based plans via
    LLM based transformations. We evaluate our approach on two challenging algorithmic
    code generation benchmarks and find that fine-tuning CodeLLaMa-7B on our transformed
    modularized programs improves the performance by up to 30% compared to fine-tuning
    on the original dataset. Additionally, we demonstrate improved performance from
    using a smaller amount of higher-quality data, finding that a model fine-tuned
    on the entire original dataset is outperformed by a model trained on 15% of our
    cleaned dataset. Even in comparison to closed-source models, our models outperform
    the much larger AlphaCoder models.
- title: 'CathAI: fully automated coronary angiography interpretation and stenosis
    estimation'
  authors: Robert Avram and Jeffrey E Olgin and Zeeshan Ahmed and Louis Verreault-Julien
    and Alvin Wan and Joshua Barrios and Sean Abreau and Derek Wan and Joseph E Gonzalez
    and Jean-Claude Tardif and Derek Y So and Krishan Soni and Geoffrey H Tison
  venue: npj Digital Medicine
  year: ''
  citations: 19
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:GFxP56DSvIMC
  abstract: Coronary angiography is the primary procedure for diagnosis and management
    decisions in coronary artery disease (CAD), but ad-hoc visual assessment of angiograms
    has high variability. Here we report a fully automated approach to interpret angiographic
    coronary artery stenosis from standard coronary angiograms. Using 13,843 angiographic
    studies from 11,972 adult patients at University of California, San Francisco
    (UCSF), between April 1, 2008 and December 31, 2019, we train neural networks
    to accomplish four sequential necessary tasks for automatic coronary artery stenosis
    localization and estimation. Algorithms are internally validated against criterion-standard
    labels for each task in hold-out test datasets. Algorithms are then externally
    validated in real-world angiograms from the University of Ottawa Heart Institute
    (UOHI) and also retrained using quantitative coronary angiography (QCA) data from
    the …
- title: 'C-planning: An automatic curriculum for learning goal-reaching tasks'
  authors: Tianjun Zhang and Benjamin Eysenbach and Ruslan Salakhutdinov and Sergey
    Levine and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2110.12080
  year: ''
  citations: 19
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:eMMeJKvmdy0C
  abstract: 'Goal-conditioned reinforcement learning (RL) can solve tasks in a wide
    range of domains, including navigation and manipulation, but learning to reach
    distant goals remains a central challenge to the field. Learning to reach such
    goals is particularly hard without any offline data, expert demonstrations, and
    reward shaping. In this paper, we propose an algorithm to solve the distant goal-reaching
    task by using search at training time to automatically generate a curriculum of
    intermediate states. Our algorithm, Classifier-Planning (C-Planning), frames the
    learning of the goal-conditioned policies as expectation maximization: the E-step
    corresponds to planning an optimal sequence of waypoints using graph search, while
    the M-step aims to learn a goal-conditioned policy to reach those waypoints. Unlike
    prior methods that combine goal-conditioned RL with graph search, ours performs
    search only during training and not testing, significantly decreasing the compute
    costs of deploying the learned policy. Empirically, we demonstrate that our method
    is more sample efficient than prior methods. Moreover, it is able to solve very
    long horizons manipulation and navigation tasks, tasks that prior goal-conditioned
    methods and methods based on graph search fail to solve.'
- title: Asynchronous complex analytics in a distributed dataflow architecture
  authors: Joseph E Gonzalez and Peter Bailis and Michael I Jordan and Michael J Franklin
    and Joseph M Hellerstein and Ali Ghodsi and Ion Stoica
  venue: arXiv preprint arXiv:1510.07092
  year: ''
  citations: 19
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Se3iqnhoufwC
  abstract: 'Scalable distributed dataflow systems have recently experienced widespread
    adoption, with commodity dataflow engines such as Hadoop and Spark, and even commodity
    SQL engines routinely supporting increasingly sophisticated analytics tasks (e.g.,
    support vector machines, logistic regression, collaborative filtering). However,
    these systems'' synchronous (often Bulk Synchronous Parallel) dataflow execution
    model is at odds with an increasingly important trend in the machine learning
    community: the use of asynchrony via shared, mutable state (i.e., data races)
    in convex programming tasks, which has---in a single-node context---delivered
    noteworthy empirical performance gains and inspired new research into asynchronous
    algorithms. In this work, we attempt to bridge this gap by evaluating the use
    of lightweight, asynchronous state transfer within a commodity dataflow engine.
    Specifically, we investigate the use of asynchronous sideways information passing
    (ASIP) that presents single-stage parallel iterators with a Volcano-like intra-operator
    iterator that can be used for asynchronous information passing. We port two synchronous
    convex programming algorithms, stochastic gradient descent and the alternating
    direction method of multipliers (ADMM), to use ASIPs. We evaluate an implementation
    of ASIPs within on Apache Spark that exhibits considerable speedups as well as
    a rich set of performance trade-offs in the use of these asynchronous algorithms.'
- title: The Graph BLAS effort and its implications for Exascale
  authors: David Bader and Aydın Buluç and John Gilbert and Joseph Gonzalez and Jeremy
    Kepner and Timothy Mattson
  venue: SIAM Workshop on Exascale Applied Mathematics Challenges and Opportunities
    (EX14)
  year: ''
  citations: 19
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:35N4QoGY0k4C
  abstract: It is our view that the state of the art in constructing a large collection
    of graph algorithms in terms of linear algebraic operations is mature enough to
    support the emergence of a standard set of primitive building blocks. This paper
    is a position paper defining the problem and announcing our intention to launch
    an open effort to define this standard.
- title: 'Lightseq: Sequence level parallelism for distributed training of long context
    transformers'
  authors: Dacheng Li and Rulin Shao and Anze Xie and Eric P Xing and Joseph E Gonzalez
    and Ion Stoica and Xuezhe Ma and Hao Zhang
  venue: arXiv preprint arXiv:2310.03294
  year: ''
  citations: 18
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:vDZJ-YLwNdEC
  abstract: Increasing the context length of large language models (LLMs) unlocks
    fundamentally new capabilities, but also significantly increases the memory footprints
    of training. Previous model-parallel systems such as Megatron-LM partition and
    compute different attention heads in parallel, resulting in large communication
    volumes, so they cannot scale beyond the number of attention heads, thereby hindering
    its adoption. In this paper, we introduce a new approach, LightSeq, for long-context
    LLMs training. LightSeq has many notable advantages. First, LightSeq partitions
    over the sequence dimension, hence is agnostic to model architectures and readily
    applicable for models with varying numbers of attention heads, such as Multi-Head,
    Multi-Query and Grouped-Query attention. Second, LightSeq not only requires up
    to 4.7x less communication than Megatron-LM on popular LLMs but also overlaps
    the communication with computation. To further reduce the training time, LightSeq
    features a novel gradient checkpointing scheme to bypass an forward computation
    for memory-efficient attention. We evaluate LightSeq on Llama-7B and its variants
    with sequence lengths from 32K to 512K. Through comprehensive experiments on single
    and cross-node training, we show that LightSeq achieves up to 1.24-2.01x end-to-end
    speedup, and a 2-8x longer sequence length on models with fewer heads, compared
    to Megatron-LM. Codes will be available at https://github.com/RulinShao/LightSeq.
- title: 'sensai: Convnets decomposition via class parallelism for fast inference
    on live data'
  authors: Guanhua Wang and Zhuang Liu and Brandon Hsieh and Siyuan Zhuang and Joseph
    Gonzalez and Trevor Darrell and Ion Stoica
  venue: Proceedings of Machine Learning and Systems
  year: ''
  citations: 18
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ruyezt5ZtCIC
  abstract: Convolutional Neural Networks (ConvNets) enable computers to excel on
    vision learning tasks such as image classification, object detection. Recently,
    real-time inference on live data is becoming more and more important. From a system
    perspective, it requires fast inference on each single, incoming data item (eg
    1 image). Two main-stream distributed model serving paradigms–data parallelism
    and model parallelism–are not necessarily desirable here, because we cannot further
    split a single input data piece via data parallelism, and model parallelism introduces
    huge communication overhead. To achieve live data inference with low latency,
    we propose sensAI, a novel and generic approach that decouples a CNN model into
    disconnected subnets, each is responsible for predicting certain class (es). We
    call this new model distribution paradigm as class parallelism. Experimental results
    show that, sensAI achieves up to 18x faster inference on single input data item
    with no or negligible accuracy loss on CIFAR-10, CIFAR-100 and ImageNet-1K datasets.
- title: Serverless boom or bust? An analysis of economic incentives
  authors: Xiayue Charles Lin and Joseph E Gonzalez and Joseph M Hellerstein
  venue: 12th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 20)
  year: ''
  citations: 18
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:dfsIfKJdRG4C
  abstract: Serverless computing is a new paradigm that promises to free cloud users
    from the burden of having to provision and manage resources. However, the degree
    to which serverless computing will replace provisioned servers remains an open
    question.
- title: Task-aware feature generation for zero-shot compositional learning
  authors: Xin Wang and Fisher Yu and Trevor Darrell and Joseph E Gonzalez
  venue: arXiv preprint arXiv:1906.04854
  year: ''
  citations: 18
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:VOx2b1Wkg3QC
  abstract: Visual concepts (e.g., red apple, big elephant) are often semantically
    compositional and each element of the compositions can be reused to construct
    novel concepts (e.g., red elephant). Compositional feature synthesis, which generates
    image feature distributions exploiting the semantic compositionality, is a promising
    approach to sample-efficient model generalization. In this work, we propose a
    task-aware feature generation (TFG) framework for compositional learning, which
    generates features of novel visual concepts by transferring knowledge from previously
    seen concepts. These synthetic features are then used to train a classifier to
    recognize novel concepts in a zero-shot manner. Our novel TFG design injects task-conditioned
    noise layer-by-layer, producing task-relevant variation at each level. We find
    the proposed generator design improves classification accuracy and sample efficiency.
    Our model establishes a new state of the art on three zero-shot compositional
    learning (ZSCL) benchmarks, outperforming the previous discriminative models by
    a large margin. Our model improves the performance of the prior arts by over 2x
    in the generalized ZSCL setting.
- title: The ooo vliw jit compiler for gpu inference
  authors: Paras Jain and Xiangxi Mo and Ajay Jain and Alexey Tumanov and Joseph E
    Gonzalez and Ion Stoica
  venue: arXiv preprint arXiv:1901.10008
  year: ''
  citations: 18
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:_FxGoFyzp5QC
  abstract: Current trends in Machine Learning~(ML) inference on hardware accelerated
    devices (e.g., GPUs, TPUs) point to alarmingly low utilization. As ML inference
    is increasingly time-bounded by tight latency SLOs, increasing data parallelism
    is not an option. The need for better efficiency motivates GPU multiplexing. Furthermore,
    existing GPU programming abstractions force programmers to micro-manage GPU resources
    in an early-binding, context-free fashion. We propose a VLIW-inspired Out-of-Order
    (OoO) Just-in-Time (JIT) compiler that coalesces and reorders execution kernels
    at runtime for throughput-optimal device utilization while satisfying latency
    SLOs. We quantify the inefficiencies of space-only and time-only multiplexing
    alternatives and demonstrate an achievable 7.7x opportunity gap through spatial
    coalescing.
- title: 'Visual transformers: Token-based image representation and processing for
    computer vision (2020)'
  authors: Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang
    and Zhicheng Yan and Masayoshi Tomizuka and Joseph Gonzalez and Kurt Keutzer and
    Peter Vajda
  venue: arXiv preprint arXiv:2006.03677
  year: ''
  citations: 18
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:0izLItjtcgwC
  abstract: ''
- title: 'Routellm: Learning to route llms with preference data'
  authors: Isaac Ong and Amjad Almahairi and Vincent Wu and Wei-Lin Chiang and Tianhao
    Wu and Joseph E Gonzalez and M Waleed Kadous and Ion Stoica
  venue: arXiv preprint arXiv:2406.18665
  year: ''
  citations: 17
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:7Hz3ACDFbsoC
  abstract: Large language models (LLMs) exhibit impressive capabilities across a
    wide range of tasks, yet the choice of which model to use often involves a trade-off
    between performance and cost. More powerful models, though effective, come with
    higher expenses, while less capable models are more cost-effective. To address
    this dilemma, we propose several efficient router models that dynamically select
    between a stronger and a weaker LLM during inference, aiming to optimize the balance
    between cost and response quality. We develop a training framework for these routers
    leveraging human preference data and data augmentation techniques to enhance performance.
    Our evaluation on widely-recognized benchmarks shows that our approach significantly
    reduces costs-by over 2 times in certain cases-without compromising the quality
    of responses. Interestingly, our router models also demonstrate significant transfer
    learning capabilities, maintaining their performance even when the strong and
    weak models are changed at test time. This highlights the potential of these routers
    to provide a cost-effective yet high-performance solution for deploying LLMs.
- title: 'See Say and Segment: Teaching LMMs to Overcome False Premises'
  authors: Tsung-Han Wu and Giscard Biamby and David Chan and Lisa Dunlap and Ritwik
    Gupta and Xudong Wang and Joseph E Gonzalez and Trevor Darrell
  venue: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
  year: ''
  citations: 17
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:sJsF-0ZLhtgC
  abstract: Current open-source Large Multimodal Models (LMMs) excel at tasks such
    as open-vocabulary language grounding and segmentation but can suffer under false
    premises when queries imply the existence of something that is not actually present
    in the image. We observe that existing methods that fine-tune an LMM to segment
    images significantly degrade their ability to reliably determine (" see") if an
    object is present and to interact naturally with humans (" say") a form of catastrophic
    forgetting. In this work we propose a cascading and joint training approach for
    LMMs to solve this task avoiding catastrophic forgetting of previous skills. Our
    resulting model can" see" by detecting whether objects are present in an image"
    say" by telling the user if they are not proposing alternative queries or correcting
    semantic errors in the query and finally" segment" by outputting the mask of the
    desired objects if they exist. Additionally we introduce a novel False Premise
    Correction benchmark dataset an extension of existing RefCOCO (+/g) referring
    segmentation datasets (which we call FP-RefCOCO (+/g)). The results show that
    our method not only detects false premises up to 55% better than existing approaches
    but under false premise conditions produces relative cIOU improvements of more
    than 31% over baselines and produces natural language feedback judged helpful
    up to 67% of the time.
- title: Evaluating natural language processing models with generalization metrics
    that do not need access to any training or testing data
  authors: Yaoqing Yang and Ryan Theisen and Liam Hodgkinson and Joseph E Gonzalez
    and Kannan Ramchandran and Charles H Martin and Michael W Mahoney
  venue: arXiv preprint arXiv:2202.02842
  year: ''
  citations: 17
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:EYYDruWGBe4C
  abstract: 'Selecting suitable architecture parameters and training hyperparameters
    is essential for enhancing machine learning (ML) model performance. Several recent
    empirical studies conduct large-scale correlational analysis on neural networks
    (NNs) to search for effective \emph{generalization metrics} that can guide this
    type of model selection. Effective metrics are typically expected to correlate
    strongly with test performance. In this paper, we expand on prior analyses by
    examining generalization-metric-based model selection with the following objectives:
    (i) focusing on natural language processing (NLP) tasks, as prior work primarily
    concentrates on computer vision (CV) tasks; (ii) considering metrics that directly
    predict \emph{test error} instead of the \emph{generalization gap}; (iii) exploring
    metrics that do not need access to data to compute. From these objectives, we
    are able to provide the first model selection results on large pretrained Transformers
    from Huggingface using generalization metrics. Our analyses consider (I) hundreds
    of Transformers trained in different settings, in which we systematically vary
    the amount of data, the model size and the optimization hyperparameters, (II)
    a total of 51 pretrained Transformers from eight families of Huggingface NLP models,
    including GPT2, BERT, etc., and (III) a total of 28 existing and novel generalization
    metrics. Despite their niche status, we find that metrics derived from the heavy-tail
    (HT) perspective are particularly useful in NLP tasks, exhibiting stronger correlations
    than other, more popular metrics. To further examine these metrics, we extend
    prior formulations relying on power law (PL) spectral …'
- title: 'RLlib flow: distributed reinforcement learning is a dataflow problem'
  authors: Eric Liang and Zhanghao Wu and Michael Luo and Sven Mika and Joseph E Gonzalez
    and Ion Stoica
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 17
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:SdhP9T11ey4C
  abstract: 'Researchers and practitioners in the field of reinforcement learning
    (RL) frequently leverage parallel computation, which has led to a plethora of
    new algorithms and systems in the last few years. In this paper, we re-examine
    the challenges posed by distributed RL and try to view it through the lens of
    an old idea: distributed dataflow. We show that viewing RL as a dataflow problem
    leads to highly composable and performant implementations. We propose RLlib Flow,
    a hybrid actor-dataflow programming model for distributed RL, and validate its
    practicality by porting the full suite of algorithms in RLlib, a widely adopted
    distributed RL library. Concretely, RLlib Flow provides 2-9 code savings in real
    production code and enables the composition of multi-agent algorithms not possible
    by end users before. The open-source code is available as part of RLlib at https://github.
    com/ray-project/ray/tree/master/rllib.'
- title: 'Sglang: Efficient execution of structured language model programs'
  authors: Lianmin Zheng and Liangsheng Yin and Zhiqiang Xie and Chuyue Sun and Jeff
    Huang and Cody Hao Yu and Shiyi Cao and Christos Kozyrakis and Ion Stoica and
    Joseph E Gonzalez and Clark Barrett and Ying Sheng
  venue: arXiv preprint arXiv:2312.07104
  year: ''
  citations: 15
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:DBa1UEJaJKAC
  abstract: Large language models (LLMs) are increasingly used for complex tasks that
    require multiple generation calls, advanced prompting techniques, control flow,
    and structured inputs/outputs. However, efficient systems are lacking for programming
    and executing these applications. We introduce SGLang, a system for efficient
    execution of complex language model programs. SGLang consists of a frontend language
    and a runtime. The frontend simplifies programming with primitives for generation
    and parallelism control. The runtime accelerates execution with novel optimizations
    like RadixAttention for KV cache reuse and compressed finite state machines for
    faster structured output decoding. Experiments show that SGLang achieves up to
    6.4× higher throughput compared to state-of-the-art inference systems on various
    large language and multi-modal models on tasks including agent control, logical
    reasoning, few-shot learning benchmarks, JSON decoding, retrieval-augmented generation
    pipelines, and multi-turn chat. The code is publicly available at https://github.
    com/sgl-project/sglang.
- title: Cilantro:{Performance-Aware} resource allocation for general objectives via
    online feedback
  authors: Romil Bhardwaj and Kirthevasan Kandasamy and Asim Biswal and Wenshuo Guo
    and Benjamin Hindman and Joseph Gonzalez and Michael Jordan and Ion Stoica
  venue: 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI
    23)
  year: ''
  citations: 15
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:3htObqc8RwsC
  abstract: Traditional systems for allocating finite cluster resources among competing
    jobs have either aimed at providing fairness, relied on users to specify their
    resource requirements, or have estimated these requirements via surrogate metrics
    (eg CPU utilization). These approaches do not account for a job’s real world performance
    (eg P95 latency). Existing performance-aware systems use offline profiled data
    and/or are designed for specific allocation objectives. In this work, we argue
    that resource allocation systems should directly account for real-world performance
    and the varied allocation objectives of users. In this pursuit, we build Cilantro.
- title: 'Ls3: Latent space safe sets for long-horizon visuomotor control of sparse
    reward iterative tasks'
  authors: Albert Wilcox and Ashwin Balakrishna and Brijen Thananjeyan and Joseph
    E Gonzalez and Ken Goldberg
  venue: Conference on Robot Learning
  year: ''
  citations: 15
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:dQ2og3OwTAUC
  abstract: Reinforcement learning (RL) has shown impressive success in exploring
    high-dimensional environments to learn complex tasks, but can often exhibit unsafe
    behaviors and require extensive environment interaction when exploration is unconstrained.
    A promising strategy for learning in dynamically uncertain environments is requiring
    that the agent can robustly return to learned Safe Sets, where task success (and
    therefore safety) can be guaranteed. While this approach has been successful in
    low-dimensions, enforcing this constraint in environments with visual observation
    spaces is exceedingly challenging. We present a novel continuous representation
    for Safe Sets framed as a binary classification problem in a learned latent space,
    which flexibly scales to high-dimensional image observations. We then present
    a new algorithm, Latent Space Safe Sets (LS3), which uses this representation
    for long-horizon control. We evaluate LS3 on 4 domains, including a challenging
    sequential pushing task in simulation and a physical cable routing task. We find
    that LS3 can use prior task successes to restrict exploration and learn more efficiently
    than prior algorithms while satisfying constraints. See https://tinyurl. com/latent-safe-sets
    for supplementary material.
- title: 'Prediction-Serving Systems: What happens when we wish to actually deploy
    a machine learning model to production?'
  authors: Dan Crankshaw and Joseph Gonzalez
  venue: Queue
  year: ''
  citations: 15
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:O3NaXMp0MMsC
  abstract: This installment of Research for Practice features a curated selection
    from Dan Crankshaw and Joey Gonzalez, who provide an overview of machine learning
    serving systems. What happens when we wish to actually deploy a machine learning
    model to production, and how do we serve predictions with high accuracy and high
    computational efficiency? Dan and Joey’s selection provides a thoughtful selection
    of cutting-edge techniques spanning database-level integration, video processing,
    and prediction middleware. Given the explosion of interest in machine learning
    and its increasing impact on seemingly every application vertical, it’s possible
    that systems such as these will become as commonplace as relational databases
    are today
- title: 'Serverless Computing: One Step Forward'
  authors: Joseph M Hellerstein and Jose Faleiro and Joseph E Gonzalez and Johann
    Schleier-Smith and Vikram Sreekanti and Alexey Tumanov and Chenggang Wu
  venue: Two Steps Back. arXiv preprint arXivL1812
  year: ''
  citations: 15
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:hMsQuOkrut0C
  abstract: ''
- title: 'Test accuracy vs. generalization gap: Model selection in nlp without accessing
    training or testing data'
  authors: Yaoqing Yang and Ryan Theisen and Liam Hodgkinson and Joseph E Gonzalez
    and Kannan Ramchandran and Charles H Martin and Michael W Mahoney
  venue: ''
  year: ''
  citations: 14
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:8xutWZnSdmoC
  abstract: 'Selecting suitable architecture parameters and training hyperparameters
    is essential for enhancing machine learning (ML) model performance. Several recent
    empirical studies conduct large-scale correlational analysis on neural networks
    (NNs) to search for effective generalization metrics that can guide this type
    of model selection. Effective metrics are typically expected to correlate strongly
    with test performance. In this paper, we expand on prior analyses by examining
    generalization-metric-based model selection with the following objectives: (i)
    focusing on natural language processing (NLP) tasks, as prior work primarily concentrates
    on computer vision (CV) tasks; (ii) considering metrics that directly predict
    test error instead of the generalization gap; (iii) exploring metrics that do
    not need access to data to compute. From these objectives, we are able to provide
    the first model selection results on large pretrained …'
- title: 'Abc-lmpc: Safe sample-based learning mpc for stochastic nonlinear dynamical
    systems with adjustable boundary conditions'
  authors: Brijen Thananjeyan and Ashwin Balakrishna and Ugo Rosolia and Joseph E
    Gonzalez and Aaron Ames and Ken Goldberg
  venue: 'Algorithmic Foundations of Robotics XIV: Proceedings of the Fourteenth Workshop
    on the Algorithmic Foundations of Robotics 14'
  year: ''
  citations: 14
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:vV6vV6tmYwMC
  abstract: Sample-based learning model predictive control (LMPC) strategies have
    recently attracted attention due to their desirable theoretical properties and
    good empirical performance on robotic tasks. However, prior analysis of LMPC controllers
    for stochastic systems has mainly focused on linear systems in the iterative learning
    control setting. We present a novel LMPC algorithm, Adjustable Boundary Condition
    LMPC (ABC-LMPC), which enables rapid adaptation to novel start and goal configurations
    and theoretically show that the resulting controller guarantees iterative improvement
    in expectation for stochastic nonlinear systems. We present results with a practical
    instantiation of this algorithm and experimentally demonstrate that the resulting
    controller adapts to a variety of initial and terminal conditions on 3 stochastic
    continuous control tasks.
- title: Online learning demands in max-min fairness
  authors: Kirthevasan Kandasamy and Gur-Eyal Sela and Joseph E Gonzalez and Michael
    I Jordan and Ion Stoica
  venue: arXiv preprint arXiv:2012.08648
  year: ''
  citations: 14
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:5ugPr518TE4C
  abstract: 'We describe mechanisms for the allocation of a scarce resource among
    multiple users in a way that is efficient, fair, and strategy-proof, but when
    users do not know their resource requirements. The mechanism is repeated for multiple
    rounds and a user''s requirements can change on each round. At the end of each
    round, users provide feedback about the allocation they received, enabling the
    mechanism to learn user preferences over time. Such situations are common in the
    shared usage of a compute cluster among many users in an organisation, where all
    teams may not precisely know the amount of resources needed to execute their jobs.
    By understating their requirements, users will receive less than they need and
    consequently not achieve their goals. By overstating them, they may siphon away
    precious resources that could be useful to others in the organisation. We formalise
    this task of online learning in fair division via notions of efficiency, fairness,
    and strategy-proofness applicable to this setting, and study this problem under
    three types of feedback: when the users'' observations are deterministic, when
    they are stochastic and follow a parametric model, and when they are stochastic
    and nonparametric. We derive mechanisms inspired by the classical max-min fairness
    procedure that achieve these requisites, and quantify the extent to which they
    are achieved via asymptotic rates. We corroborate these insights with an experimental
    evaluation on synthetic problems and a web-serving task.'
- title: Is anyone there? learning a planner contingent on perceptual uncertainty
  authors: Charles Packer and Nicholas Rhinehart and Rowan Thomas McAllister and Matthew
    A Wright and Xin Wang and Jeff He and Sergey Levine and Joseph E Gonzalez
  venue: Conference on Robot Learning
  year: ''
  citations: 13
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:a9-T7VOCCH8C
  abstract: Robots in complex multi-agent environments should reason about the intentions
    of observed and currently unobserved agents. In this paper, we present a new learning-based
    method for prediction and planning in complex multi-agent environments where the
    states of the other agents are partially-observed. Our approach, Active Visual
    Planning (AVP), uses high-dimensional observations to learn a flow-based generative
    model of multi-agent joint trajectories, including unobserved agents that may
    be revealed in the near future, depending on the robot’s actions. Our predictive
    model is implemented using deep neural networks that map raw observations to future
    detection and pose trajectories and is learned entirely offline using a dataset
    of recorded observations (not ground-truth states). Once learned, our predictive
    model can be used for contingency planning over the potential existence, intentions,
    and positions of unobserved agents. We demonstrate the effectiveness of AVP on
    a set of autonomous driving environments inspired by real-world scenarios that
    require reasoning about the existence of other unobserved agents for safe and
    efficient driving. In these environments, AVP achieves optimal closed-loop performance,
    while methods that do not reason about potential unobserved agents exhibit either
    overconfident or underconfident behavior.
- title: Digital seismic event recorder records and spectral for aftershocks of the
    november 29, 1978 Oaxaca earthquake
  authors: Luis Munguia and JN Brune and A Reyes and J Gonzalez and R Simons and F
    Vernon
  venue: Geofisica Internacional
  year: ''
  citations: 13
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:4fGpz3EwCPoC
  abstract: Un arreglo de 7 grabadoras digitales fue operado en la region de las replicas
    de! temblor de Oaxaca, Mexico. Los instrumentos operados durante este estudio
    consistieron en grabadoras digitales de Terra Technology combinadas con sismometros
    Kinemetrics y Geotech S-500 de periodos 5 y 1 segundos respectivamente.Espectros
    y graficas del desplazamiento (corregidos por la respuesta del instrumento y por
    Q) fueron calculados. Formas de onda simples y complejas fueron observadas para
    temblores con aproximadamente el mismo epicentro. Se cree que la complejidad de
    los sismogramas es debido a fuentes complejas y no a complejidad estructural de!
    medio. Los espectros calculados se interpretaron en terminos del modelo de Brune
    para calcular el momento sismico, las caidas de esfuerzo y las dimensiones de
    la fuente. Las frecuencias de esquina observadas estan entre 0.7 y 8 Hz, y las
    caidas de esfuerzo entre 6 y alrededor de 400 bars. Las amplitudes de las ondas
    superficiales observadas en estaciones lejanas fueron utilizadas para hacer una
    segunda determinacion del momento sismico. Se encontro que los momentos calculados
    de este modo son de 2 a 6 veces mayores que los calculados del espectro de! desplazamiento.
- title: 'Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models'
  authors: Ling Yang and Zhaochen Yu and Tianjun Zhang and Shiyi Cao and Minkai Xu
    and Wentao Zhang and Joseph E Gonzalez and Bin Cui
  venue: arXiv preprint arXiv:2406.04271
  year: ''
  citations: 12
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:v1_lew4L6wgC
  abstract: 'We introduce Buffer of Thoughts (BoT), a novel and versatile thought-augmented
    reasoning approach for enhancing accuracy, efficiency and robustness of large
    language models (LLMs). Specifically, we propose meta-buffer to store a series
    of informative high-level thoughts, namely thought-template, distilled from the
    problem-solving processes across various tasks. Then for each problem, we retrieve
    a relevant thought-template and adaptively instantiate it with specific reasoning
    structures to conduct efficient reasoning. To guarantee the scalability and stability,
    we further propose buffer-manager to dynamically update the meta-buffer, thus
    enhancing the capacity of meta-buffer as more tasks are solved. We conduct extensive
    experiments on 10 challenging reasoning-intensive tasks, and achieve significant
    performance improvements over previous SOTA methods: 11% on Game of 24, 20% on
    Geometric Shapes and 51% on Checkmate-in-One. Further analysis demonstrate the
    superior generalization ability and model robustness of our BoT, while requiring
    only 12% of the cost of multi-query prompting methods (e.g., tree/graph of thoughts)
    on average. Notably, we find that our Llama3-8B+BoT has the potential to surpass
    Llama3-70B model. Our project is available at: https://github.com/YangLing0818/buffer-of-thought-llm'
- title: Optimizing llm queries in relational workloads
  authors: Shu Liu and Asim Biswal and Audrey Cheng and Xiangxi Mo and Shiyi Cao and
    Joseph E Gonzalez and Ion Stoica and Matei Zaharia
  venue: arXiv preprint arXiv:2403.05821
  year: ''
  citations: 12
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:CaZNVDsoPx4C
  abstract: 'Analytical database providers (e.g., Redshift, Databricks, BigQuery)
    have rapidly added support for invoking Large Language Models (LLMs) through native
    user-defined functions (UDFs) to help users perform natural language tasks, such
    as classification, entity extraction, and translation, inside analytical workloads.
    For instance, an analyst might want to extract customer sentiments on millions
    of product reviews. However, LLM inference is highly expensive in both computational
    and economic terms: for example, an NVIDIA L4 GPU running Llama2-7B can only process
    6 KB of text per second. In this paper, we explore how to optimize LLM inference
    for analytical workloads that invoke LLMs within relational queries. We show that
    relational queries present novel opportunities for accelerating LLM inference,
    including reordering rows to maximize key-value (KV) cache reuse within the LLM
    inference engine, reordering columns within a row to further increase cache reuse,
    and deduplicating redundant inference requests. We implement these optimizations
    in Apache Spark, with vLLM as the model serving backend and achieve up to 4.4x
    improvement in end-to-end latency on a benchmark of diverse LLM-based queries
    on real datasets. To the best of our knowledge, this is the first work to explicitly
    address the problem of optimizing LLM invocations within SQL queries.'
- title: 'All you need is luv: Unsupervised collection of labeled images using invisible
    uv fluorescent indicators'
  authors: Brijen Thananjeyan and Justin Kerr and Huang Huang and Joseph E Gonzalez
    and Ken Goldberg
  venue: arXiv preprint arXiv:2203.04566
  year: ''
  citations: 12
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:_B80troHkn4C
  abstract: Large-scale semantic image annotation is a significant challenge for learning-based
    perception systems in robotics. Current approaches often rely on human labelers,
    which can be expensive, or simulation data, which can visually or physically differ
    from real data. This paper proposes Labels from UltraViolet (LUV), a novel framework
    that enables rapid, labeled data collection in real manipulation environments
    without human labeling. LUV uses transparent, ultraviolet-fluorescent paint with
    programmable ultraviolet LEDs to collect paired images of a scene in standard
    lighting and UV lighting to autonomously extract segmentation masks and keypoints
    via color segmentation. We apply LUV to a suite of diverse robot perception tasks
    to evaluate its labeling quality, flexibility, and data collection rate. Results
    suggest that LUV is 180-2500 times faster than a human labeler across the tasks.
    We show that LUV provides labels consistent with human annotations on unpainted
    test images. The networks trained on these labels are used to smooth and fold
    crumpled towels with 83% success rate and achieve 1.7mm position error with respect
    to human labels on a surgical needle pose estimation task. The low cost of LUV
    makes it ideal as a lightweight replacement for human labeling systems, with the
    one-time setup costs at $300 equivalent to the cost of collecting around 200 semantic
    segmentation labels on Amazon Mechanical Turk. Code, datasets, visualizations,
    and supplementary material can be found at https://sites.google.com/berkeley.edu/luv
- title: Serverless multi-query motion planning for fog robotics
  authors: Raghav Anand and Jeffrey Ichnowski and Chenggang Wu and Joseph M Hellerstein
    and Joseph E Gonzalez and Ken Goldberg
  venue: 2021 IEEE International Conference on Robotics and Automation (ICRA)
  year: ''
  citations: 12
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Mojj43d5GZwC
  abstract: Robots in semi-structured environments such as homes and warehouses sporadically
    require computation of high-dimensional motion plans. Cloud and fog-based parallelization
    of motion planning can speed up planning. This can be further made efficient by
    the use of "serverless" on-demand computing as opposed to always-on high end computers.
    This paper explores parallelizing the computation of a sampling-based multi-query
    motion planner based on asymptotically-optimal Probabilistic Road Maps (PRM*)
    using the simultaneous execution of 100s of cloud-based serverless functions.
    We propose an algorithm to overcome the communication and bandwidth limitations
    of serverless computing and use different work-sharing techniques to further optimize
    the cost and run time. Additionally, we provide proofs of probabilistic completeness
    and asymptotic optimality. In experiments on synthetic benchmarks and …
- title: Enhancing the interactivity of dataframe queries by leveraging think time
  authors: Doris Xin and Devin Petersohn and Dixin Tang and Yifan Wu and Joseph E
    Gonzalez and Joseph M Hellerstein and Anthony D Joseph and Aditya G Parameswaran
  venue: arXiv preprint arXiv:2103.02145
  year: ''
  citations: 12
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:uWiczbcajpAC
  abstract: We propose opportunistic evaluation, a framework for accelerating interactions
    with dataframes. Interactive latency is critical for iterative, human-in-the-loop
    dataframe workloads for supporting exploratory data analysis. Opportunistic evaluation
    significantly reduces interactive latency by 1) prioritizing computation directly
    relevant to the interactions and 2) leveraging think time for asynchronous background
    computation for non-critical operators that might be relevant to future interactions.
    We show, through empirical analysis, that current user behavior presents ample
    opportunities for optimization, and the solutions we propose effectively harness
    such opportunities.
- title: Hindsight logging for model training
  authors: Rolando Garcia and Eric Liu and Vikram Sreekanti and Bobby Yan and Anusha
    Dandamudi and Joseph E Gonzalez and Joseph M Hellerstein and Koushik Sen
  venue: arXiv preprint arXiv:2006.07357
  year: ''
  citations: 12
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:KxtntwgDAa4C
  abstract: 'In modern Machine Learning, model training is an iterative, experimental
    process that can consume enormous computation resources and developer time. To
    aid in that process, experienced model developers log and visualize program variables
    during training runs. Exhaustive logging of all variables is infeasible. Optimistic
    logging can be accompanied by program checkpoints; this allows developers to add
    log statements post-hoc, and "replay" desired log statements from checkpoint --
    a process we refer to as hindsight logging. Unfortunately, hindsight logging raises
    tricky problems in data management and software engineering. Done poorly, hindsight
    logging can waste resources and generate technical debt embodied in multiple variants
    of training code. In this paper, we present methodologies for efficient and effective
    logging practices for model training, with a focus on techniques for hindsight
    logging. Our goal is for experienced model developers to learn and adopt these
    practices. To make this easier, we provide an open-source suite of tools for Fast
    Low-Overhead Recovery (flor) that embodies our design across three tasks: (i)
    efficient background logging in Python, (ii) adaptable periodic checkpointing,
    and (iii) an instrumentation library that codifies hindsight logging for efficient
    and automatic record-replay of model-training. Model developers can use each flor
    tool separately as they see fit, or they can use flor in hands-free mode, entrusting
    it to instrument their code end-to-end for efficient record-replay. Our solutions
    leverage techniques from physiological transaction logs and recovery in database
    systems. Evaluations on modern ML …'
- title: 'Rllib: Abstractions for distributed reinforcement learning. arxiv e-prints,
    page'
  authors: Eric Liang and Richard Liaw and Philipp Moritz and Robert Nishihara and
    Roy Fox and Ken Goldberg and Joseph E Gonzalez and Michael I Jordan and Ion Stoica
  venue: arXiv preprint arXiv:1712.09381
  year: ''
  citations: 12
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:UHK10RUVsp4C
  abstract: ''
- title: High performance millimeter wave 0.1/spl mu/m InP HEMT MMIC LNAs fabricated
    on 100 mm wafers
  authors: R Grundbacher and J Uyeda and R Lai and D Umemoto and PH Liu and M Barsky
    and A Cavus and LJ Lee and J Chen and J Gonzalez and S Chen and T Block and A
    Oki
  venue: 16th IPRM. 2004 International Conference on Indium Phosphide and Related
    Materials, 2004.
  year: ''
  citations: 12
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:8d8msizDQcsC
  abstract: Millimeter wave 0.1/spl mu/m InP HEMT MMlCs fabricated on 100 mm InP substrates
    have been demonstrated at NGST. Production capability in 100 mm MBE growth, frontside
    processing, and backside processing has been established and is presented. MMIC
    performance is described for Ka-band, Q-band, and W-band low noise amplifiers
    and for a 0.5 to 80 GHz distributed amplifier.
- title: 'Tune: A research platform for distributed model selection and training.
    CoRR abs/1807.05118 (2018)'
  authors: Richard Liaw and Eric Liang and Robert Nishihara and Philipp Moritz and
    Joseph E Gonzalez and Ion Stoica
  venue: ''
  year: ''
  citations: 12
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:uJ-U7cs_P_0C
  abstract: ''
- title: Learning space partitions for path planning
  authors: Kevin Yang and Tianjun Zhang and Chris Cummins and Brandon Cui and Benoit
    Steiner and Linnan Wang and Joseph E Gonzalez and Dan Klein and Yuandong Tian
  venue: Advances in Neural Information Processing Systems
  year: ''
  citations: 11
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:AXPGKjj_ei8C
  abstract: Path planning, the problem of efficiently discovering high-reward trajectories,
    often requires optimizing a high-dimensional and multimodal reward function. Popular
    approaches like CEM and CMA-ES greedily focus on promising regions of the search
    space and may get trapped in local maxima. DOO and VOOT balance exploration and
    exploitation, but use space partitioning strategies independent of the reward
    function to be optimized. Recently, LaMCTS empirically learns to partition the
    search space in a reward-sensitive manner for black-box optimization. In this
    paper, we develop a novel formal regret analysis for when and why such an adaptive
    region partitioning scheme works. We also propose a new path planning method LaP3
    which improves the function value estimation within each sub-region, and uses
    a latent representation of the search space. Empirically, LaP3 outperforms existing
    path planning methods in 2D navigation tasks, especially in the presence of difficult-to-escape
    local optima, and shows benefits when plugged into the planning components of
    model-based RL such as PETS. These gains transfer to highly multimodal real-world
    tasks, where we outperform strong baselines in compiler phase ordering by up to
    39% on average across 9 tasks, and in molecular design by up to 0.4 on properties
    on a 0-1 scale. Code is available at https://github. com/yangkevin2/neurips2021-lap3.
- title: Grounded graph decoding improves compositional generalization in question
    answering
  authors: Yu Gai and Paras Jain and Wendi Zhang and Joseph E Gonzalez and Dawn Song
    and Ion Stoica
  venue: arXiv preprint arXiv:2111.03642
  year: ''
  citations: 11
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:VL0QpB8kHFEC
  abstract: Question answering models struggle to generalize to novel compositions
    of training patterns, such to longer sequences or more complex test structures.
    Current end-to-end models learn a flat input embedding which can lose input syntax
    context. Prior approaches improve generalization by learning permutation invariant
    models, but these methods do not scale to more complex train-test splits. We propose
    Grounded Graph Decoding, a method to improve compositional generalization of language
    representations by grounding structured predictions with an attention mechanism.
    Grounding enables the model to retain syntax information from the input in thereby
    significantly improving generalization over complex inputs. By predicting a structured
    graph containing conjunctions of query clauses, we learn a group invariant representation
    without making assumptions on the target domain. Our model significantly outperforms
    state-of-the-art baselines on the Compositional Freebase Questions (CFQ) dataset,
    a challenging benchmark for compositional generalization in question answering.
    Moreover, we effectively solve the MCD1 split with 98% accuracy.
- title: Constrained thompson sampling for wireless link optimization
  authors: Vidit Saxena and Joseph E Gonzalez and Ion Stoica and Hugo Tullberg and
    Joakim Jaldén
  venue: arXiv preprint arXiv:1902.11102
  year: ''
  citations: 11
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:maZDTaKrznsC
  abstract: Wireless communication systems operate in complex time-varying environments.
    Therefore, selecting the optimal configuration parameters in these systems is
    a challenging problem. For wireless links, \emph{rate selection} is used to select
    the optimal data transmission rate that maximizes the link throughput subject
    to an application-defined latency constraint. We model rate selection as a stochastic
    multi-armed bandit (MAB) problem, where a finite set of transmission rates are
    modeled as independent bandit arms. For this setup, we propose Con-TS, a novel
    constrained version of the Thompson sampling algorithm, where the latency requirement
    is modeled by a high-probability linear constraint. We show that for Con-TS, the
    expected number of constraint violations over T transmission intervals is upper
    bounded by O(\sqrt{KT}), where K is the number of available rates. Further, the
    expected loss in cumulative throughput compared to the optimal rate selection
    scheme (i.e., the egret is also upper bounded by O(\sqrt{KT \log K}). Through
    numerical simulations, we demonstrate that Con-TS significantly outperforms state-of-the-art
    bandit schemes for rate selection.
- title: Deep reinforcement learning in system optimization
  authors: Ameer Haj-Ali and Nesreen K Ahmed and Ted Willke and Joseph Gonzalez and
    Krste Asanovic and Ion Stoica
  venue: arXiv preprint arXiv:1908.01275
  year: ''
  citations: 11
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:L8Ckcad2t8MC
  abstract: The recent advancements in deep reinforcement learning have opened new
    horizons and opportunities to tackle various problems in system optimization.
    Such problems are generally tailored to delayed, aggregated, and sequential rewards,
    which is an inherent behavior in the reinforcement learning setting, where an
    agent collects rewards while exploring and exploiting the environment to maximize
    the long term reward. However, in some cases, it is not clear why deep reinforcement
    learning is a good fit for the problem. Sometimes, it does not perform better
    than the state-of-the-art solutions. And in other cases, random search or greedy
    algorithms could outperform deep reinforcement learning. In this paper, we review,
    discuss, and evaluate the recent trends of using deep reinforcement learning in
    system optimization. We propose a set of essential metrics to guide future works
    in evaluating the efficacy of using deep reinforcement learning in system optimization.
    Our evaluation includes challenges, the types of problems, their formulation in
    the deep reinforcement learning setting, embedding, the model used, efficiency,
    and robustness. We conclude with a discussion on open challenges and potential
    directions for pushing further the integration of reinforcement learning in system
    optimization.
- title: Efficient and accurate clustering for large-scale genetic mapping
  authors: Veronika Strnadova and Aydın Buluç and Jarrod Chapman and John R Gilbert
    and Joseph Gonzalez and Stefanie Jegelka and Daniel Rokhsar and Leonid Oliker
  venue: 2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)
  year: ''
  citations: 11
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:iH-uZ7U-co4C
  abstract: High-throughput “next generation” genome sequencing technologies are producing
    a flood of inexpensive genetic information that is invaluable to genomics research.
    Sequences of millions of genetic markers are being produced, providing genomics
    researchers with the opportunity to construct highresolution genetic maps for
    many complicated genomes. However, the current generation of genetic mapping tools
    were designed for the small data setting, and are now limited by the prohibitively
    slow clustering algorithms they employ in the genetic marker-clustering stage.
    In this work, we present a new approach to genetic mapping based on a fast clustering
    algorithm that exploits the geometry of the data. Our theoretical and empirical
    analysis shows that the algorithm can correctly recover linkage groups. Using
    synthetic and real-world data, including the grand-challenge wheat genome, we
    demonstrate that our …
- title: Parallel splash belief propagation
  authors: Joseph Gonzalez and Yucheng Low and Carlos Guestrin
  venue: J. Mach. Learn. Res
  year: ''
  citations: 11
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:geHnlv5EZngC
  abstract: As computer architectures transition towards exponentially increasing
    parallelism we are forced to adopt parallelism at a fundamental level in the design
    of machine learning algorithms. In this paper we focus on parallel graphical model
    inference. We demonstrate that the natural, synchronous parallelization of belief
    propagation is highly inefficient. By bounding the achievable parallel performance
    in chain graphical models we develop a theoretical understanding of the parallel
    limitations of belief propagation. We then provide a new parallel belief propagation
    algorithm which achieves optimal performance. Using several challenging real-world
    tasks, we empirically evaluate the performance of our algorithm on large cyclic
    graphical models where we achieve near linear parallel scaling and out perform
    alternative algorithms.
- title: Leveraging cloud computing to make autonomous vehicles safer
  authors: Peter Schafhalter and Sukrit Kalra and Le Xu and Joseph E Gonzalez and
    Ion Stoica
  venue: 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems
    (IROS)
  year: ''
  citations: 10
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Ehil0879vHcC
  abstract: The safety of autonomous vehicles (AVs) depends on their ability to perform
    complex computations on high-volume sensor data in a timely manner. Their ability
    to run these computations with state-of-the-art models is limited by the processing
    power and slow update cycles of their onboard hardware. In contrast, cloud computing
    offers the ability to burst computation to vast amounts of the latest generation
    of hardware. However, accessing these cloud resources requires traversing wireless
    networks that are often considered to be too unreliable for real-time AV driving
    applications. Our work seeks to harness this unreliable cloud to enhance the accuracy
    of an AV's decisions, while ensuring that it can always fall back to its on-board
    computational capabilities. We identify three mechanisms that can be used by AVs
    to safely leverage the cloud for accuracy enhancements, and elaborate why current
    execution systems …
- title: Scalable training and serving of personalized models
  authors: Daniel Crankshaw and Xin Wang and Joseph E Gonzalez and Michael J Franklin
  venue: NIPS 2015 Workshop on Machine Learning Systems (LearningSys)
  year: ''
  citations: 10
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:RYcK_YlVTxYC
  abstract: 'The past decade has seen substantial growth in Learning Systems research
    [1, 9, 12, 14, 22] combining advances in system design with new efficient algorithms
    to enable the training of complex models on vast amounts of data. As a consequence
    we have seen widespread adoption of machine learning techniques to address important
    real-world problems [5, 17].While this work has been wildly successful in shaping
    both the machine learning [19, 16, 11] and systems fields [14, 15, 1], it also
    ignores a big part of real-world machine learning. In particular, much of the
    work in Learning Systems has operated under the fiction: the world hands me a
    static, potentially very large, dataset and I train an accurate, potentially complex,
    model. This fiction departs from reality in two key regards that we begin to address
    in this work.'
- title: 'Kernel-as-a-service: A serverless interface to gpus'
  authors: Nathan Pemberton and Anton Zabreyko and Zhoujie Ding and Randy Katz and
    Joseph Gonzalez
  venue: arXiv preprint arXiv:2212.08146
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:QYdC8u9Cj1oC
  abstract: Serverless computing has made it easier than ever to deploy applications
    over scalable cloud resources, all the while driving higher utilization for cloud
    providers. While this technique has worked well for easily divisible resources
    like CPU and local DRAM, it has struggled to incorporate more expensive and monolithic
    resources like GPUs or other application accelerators. We cannot simply slap a
    GPU on a FaaS platform and expect to keep all the benefits serverless promises.
    We need a more tailored approach if we want to best utilize these critical resources.
    In this paper we present Kernel-as-a-Service (KaaS), a serverless interface to
    GPUs. In KaaS, GPUs are first-class citizens that are invoked just like any other
    serverless function. Rather than mixing host and GPU code as is typically done,
    KaaS runs graphs of GPU-only code while host code is run on traditional functions.
    The KaaS system is responsible for managing GPU memory and schedules user kernels
    across the entire pool of available GPUs rather than relying on static allocations.
    This approach allows us to more effectively share expensive GPU resources, especially
    in multitenant environments like the cloud. We add support for KaaS to the Ray
    distributed computing framework and evaluate it with workloads including a TVM-based
    deep learning compiler and a BLAS library. Our results show that KaaS is able
    to drive up to 50x higher throughput and 16x lower latency when GPU resources
    are contended.
- title: 'All you need is LUV: Unsupervised collection of labeled images using UV-fluorescent
    markings'
  authors: Brijen Thananjeyan and Justin Kerr and Huang Huang and Joseph E Gonzalez
    and Ken Goldberg
  venue: 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems
    (IROS)
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:dBIO0h50nwkC
  abstract: 'Learning-based perception systems in robotics often requires large-scale
    image segmentation annotation. Current approaches rely on human labelers, which
    can be expensive, or simulation data, which can visually differ from real data.
    This paper proposes Labels from UltraViolet (LUV), a novel framework that enables
    rapid, automated, inexpensive, high quality data collection in real. LUV uses
    transparent, UV-fluorescent paint with programmable UV LEDs to collect paired
    images of a scene in standard and UV lighting. This makes it possible to autonomously
    extract segmentation masks and keypoints via color thresholding. We apply LUV
    to a suite of diverse robot perception tasks: locating fabric keypoints, cable
    segmentation, and surgical needle detection to evaluate its labeling quality,
    flexibility, and data collection rate. Results suggest that LUV is 180–2500 times
    faster than a human labeler across the tasks …'
- title: Context-aware streaming perception in dynamic environments
  authors: Gur-Eyal Sela and Ionel Gog and Justin Wong and Kumar Krishna Agrawal and
    Xiangxi Mo and Sukrit Kalra and Peter Schafhalter and Eric Leong and Xin Wang
    and Bharathan Balaji and Joseph Gonzalez and Ion Stoica
  venue: ''
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:_FM0Bhl9EiAC
  abstract: Efficient vision works maximize accuracy under a latency budget. These
    works evaluate accuracy offline, one image at a time. However, real-time vision
    applications like autonomous driving operate in streaming settings, where ground
    truth changes between inference start and finish. This results in a significant
    accuracy drop. Therefore, a recent work proposed to maximize accuracy in streaming
    settings on average. In this paper, we propose to maximize streaming accuracy
    for every environment context. We posit that scenario difficulty influences the
    initial (offline) accuracy difference, while obstacle displacement in the scene
    affects the subsequent accuracy degradation. Our method, Octopus, uses these scenario
    properties to select configurations that maximize streaming accuracy at test time.
    Our method improves tracking performance (S-MOTA) by  over the conventional static
    approach. Further, performance …
- title: 'Resource allocation in multi-armed bandit exploration: Overcoming sublinear
    scaling with adaptive parallelism'
  authors: Brijen Thananjeyan and Kirthevasan Kandasamy and Ion Stoica and Michael
    Jordan and Ken Goldberg and Joseph Gonzalez
  venue: International Conference on Machine Learning
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:kz9GbA2Ns4gC
  abstract: We study exploration in stochastic multi-armed bandits when we have access
    to a divisible resource that can be allocated in varying amounts to arm pulls.
    We focus in particular on the allocation of distributed computing resources, where
    we may obtain results faster by allocating more resources per pull, but might
    have reduced throughput due to nonlinear scaling. For example, in simulation-based
    scientific studies, an expensive simulation can be sped up by running it on multiple
    cores. This speed-up however, is partly offset by the communication among cores,
    which results in lower throughput than if fewer cores were allocated to run more
    trials in parallel. In this paper, we explore these trade-offs in two settings.
    First, in a fixed confidence setting, we need to find the best arm with a given
    target success probability as quickly as possible. We propose an algorithm which
    trades off between information accumulation and throughput and show that the time
    taken can be upper bounded by the solution of a dynamic program whose inputs are
    the gaps between the sub-optimal and optimal arms. We also prove a matching hardness
    result. Second, we present an algorithm for a fixed deadline setting, where we
    are given a time deadline and need to maximize the probability of finding the
    best arm. We corroborate our theoretical insights with simulation experiments
    that show that the algorithms consistently match or outperform baseline algorithms
    on a variety of problem instances.
- title: 'SegNBDT: Visual decision rules for segmentation'
  authors: Alvin Wan and Daniel Ho and Younjin Song and Henk Tillman and Sarah Adel
    Bargal and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2006.06868
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:mB3voiENLucC
  abstract: The black-box nature of neural networks limits model decision interpretability,
    in particular for high-dimensional inputs in computer vision and for dense pixel
    prediction tasks like segmentation. To address this, prior work combines neural
    networks with decision trees. However, such models (1) perform poorly when compared
    to state-of-the-art segmentation models or (2) fail to produce decision rules
    with spatially-grounded semantic meaning. In this work, we build a hybrid neural-network
    and decision-tree model for segmentation that (1) attains neural network segmentation
    accuracy and (2) provides semi-automatically constructed visual decision rules
    such as "Is there a window?". We obtain semantic visual meaning by extending saliency
    methods to segmentation and attain accuracy by leveraging insights from neural-backed
    decision trees, a deep learning analog of decision trees for image classification.
    Our model SegNBDT attains accuracy within ~2-4% of the state-of-the-art HRNetV2
    segmentation model while also retaining explainability; we achieve state-of-the-art
    performance for explainable models on three benchmark datasets -- Pascal-Context
    (49.12%), Cityscapes (79.01%), and Look Into Person (51.64%). Furthermore, user
    studies suggest visual decision rules are more interpretable, particularly for
    incorrect predictions. Code and pretrained models can be found at https://github.com/daniel-ho/SegNBDT.
- title: Object Detection
  authors: Xin Wang and Thomas E Huang and Trevor Darrell and Joseph E Gonzalez and
    Fisher Yu Frustratingly Simple Few-Shot
  venue: arXiv preprint arXiv:2003.06957
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:yFnVuubrUp4C
  abstract: "Object Detection Page 1 Object Detection Xiaolong Wang Page 2 This Class:\
    \ Object Detection \n• Background and old fashion object detection • 2-stage object\
    \ detection • FPN , Mask R-CNN \nand more Slides partially from: http://cs231n.stanford.edu/\
    \ https://slazebni.cs.illinois.edu/fall20/ \nPage 3 Background and old fashion\
    \ object detection Page 4 The task: Object Detection \nsemantic segmentation instance\
    \ segmentation image classification object detection Page 5 \nThe task: Object\
    \ Detection Images may contain more than one class, multiple instances from \n\
    the same class Page 6 Evaluation • At test time, predict bounding boxes, class\
    \ labels, and \nconfidence • For each detection, determine whether it is a true\
    \ or false positive • PASCAL \ncriterion: Area(GT ∩ Det) / Area(GT ∪ Det) > 0.5\
    \ • For multiple detections of the same ground \ntruth box, only one is considered\
    \ a true positive cat dog cat: 0.8 dog: 0.6 dog: 0.55 Ground truth (…"
- title: 'Tegra: Efficient ad-hoc analytics on time-evolving graphs'
  authors: A Iyer and Qifan Pu and Kishan Patel and J Gonzalez and Ion Stoica
  venue: UCBerkeley RISELab, Tech. Rep.
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ULOm3_A8WrAC
  abstract: ''
- title: 'Research for practice: prediction-serving systems'
  authors: Dan Crankshaw and Joseph Gonzalez and Peter Bailis
  venue: Communications of the ACM
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:RHpTSmoSYBkC
  abstract: What happens when we wish to actually deploy a machine learning model
    to production?
- title: A Berkeley View of Systems Challenges for AI, 2017
  authors: Ion Stoica and Dawn Song and Raluca Ada Popa and David Patterson and Michael
    W Mahoney and Randy Katz and Anthony D Joseph and Michael Jordan and Joseph M
    Hellerstein and Joseph Gonzalez and Ken Goldberg and Ali Ghodsi and David Culler
    and Pieter Abbeel
  venue: URL https://doi. org/10.48550/ARXIV
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:yqoGN6RLRZoC
  abstract: ''
- title: 'Students’ and Teachers’ Digital Competence: an overview on research status'
  authors: M Gisbert and J González and F Esteve
  venue: Rev. Interuniv. Investig. Technol. Educ
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:1DsIQWDZLl8C
  abstract: ''
- title: From graphs to tables the design of scalable systems for graph analytics.
  authors: Joseph E Gonzalez
  venue: WWW (Companion Volume)
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:4TOpqqG69KYC
  abstract: "From Graphs to Tables: The Design of Scalable Systems for Graph Analytics\
    \ Page 1 From \nGraphs to Tables: The Design of Scalable Systems for Graph Analytics\
    \ Joseph E. Gonzalez \nPost-doc, UC Berkeley AMPLab jegonzal@eecs.berkeley.edu\
    \ Co-founder, GraphLab Inc. \njoseph@graphlab.com WWW’14 Workshop on Big Graph\
    \ Mining *These slides are best \nviewed in PowerPoint with animation. Page 2\
    \ Graphs are Central to Analytics Raw Wikipedia < \n/ > < / > < / > XML Hyperlinks\
    \ PageRank Top 20 Pages Title PR Text Table Title Body Topic \nModel (LDA) Word\
    \ Topics Word Topic Editor Graph Community Detection User Community \nUser Com.\
    \ Term-Doc Graph Discussion Table User Disc. Community Topic Topic Com. Page 3\
    \ \nUpdate ranks in parallel Iterate until convergence Rank of user i Sum of neighbors\
    \ 3 R[i]=0.15 \n+ ∑ j2Nbrs(i) wjiR[j] PageRank: Identifying Leaders Page 4 Ratings\
    \ Items Recommending …"
- title: 0.1 μm InP HEMT MMIC fabrication on 100 mm wafers for low cost, high performance
    millimeter-wave applications
  authors: J Uyeda and R Grundbacher and R Lai and D Umemoto and PH Liu and M Barsky
    and A Cavus and LJ Lee and J Chen and J Gonzalez and S Chen and R Elmadjian and
    T Block and A Oki
  venue: Proc. GaAs MANTECH Conference, Miami Beach, FL
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:FAceZFleit8C
  abstract: 'Northrop Grumman Space Technology (NGST) has recently initiated process
    development for fabricating 0.1 μm InGaAs/InAlAs/InP High Electron Mobility Transistor
    (HEMT) MMICs on 100 mm InP substrates. Successful development of this process
    will further reduce costs for InP HEMT MMICs and rival those of GaAs-based HEMT
    MMICs, including GaAs-based metamorphic HEMT technology, with superior performance.
    Production capability has been demonstrated in three core areas: epitaxial material
    growth using Molecular Beam Epitaxy (MBE), frontside processing in NGST’s 100
    mm MMIC production line, and backside processing in NGST’s 100 mm backside production
    line with final wafer thickness of 75 μm. In this paper, we will present recent
    data and progress on NGST’s 0.1 μm InP HEMT MMIC LNA process on 100 mm InP substrates.'
- title: 'Cloud programming simplified: a Berkeley view on serverless computing (2019).
    CoRR'
  authors: Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and C Tsai and
    Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira and Karl
    Krauth and NJ Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa and Ion Stoica
    and David A Patterson
  venue: arXiv preprint arXiv:1902.03383
  year: ''
  citations: 9
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:XD-gHx7UXLsC
  abstract: ''
- title: 'LLoCO: Learning Long Contexts Offline'
  authors: Sijun Tan and Xiuyu Li and Shishir Patil and Ziyang Wu and Tianjun Zhang
    and Kurt Keutzer and Joseph E Gonzalez and Raluca Ada Popa
  venue: arXiv preprint arXiv:2404.07979
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ubry08Y2EpUC
  abstract: Processing long contexts remains a challenge for large language models
    (LLMs) due to the quadratic computational and memory overhead of the self-attention
    mechanism and the substantial KV cache sizes during generation. We propose a novel
    approach to address this problem by learning contexts offline through context
    compression and in-domain parameter-efficient finetuning. Our method enables an
    LLM to create a concise representation of the original context and efficiently
    retrieve relevant information to answer questions accurately. We introduce LLoCO,
    a technique that combines context compression, retrieval, and parameter-efficient
    finetuning using LoRA. Our approach extends the effective context window of a
    4k token LLaMA2-7B model to handle up to 128k tokens. We evaluate our approach
    on several long-context question-answering datasets, demonstrating that LLoCO
    significantly outperforms in-context learning while using  fewer tokens during
    inference. LLoCO achieves up to  speed-up and substantially reduces the cost of
    long document question answering, making it a promising solution for efficient
    long context processing. Our code is publicly available at https://github.com/jeffreysijuntan/lloco.
- title: Constraining a possible time-variation of the speed of light along with the
    fine-structure constant using strong gravitational lensing and Type Ia supernovae
    observations
  authors: LR Colaço and Susana J Landau and JE Gonzalez and J Spinelly and GLF Santos
  venue: Journal of Cosmology and Astroparticle Physics
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:buQ7SEKw-1sC
  abstract: The possible time variation of the fundamental constants of nature has
    been an active subject of research since the large-number hypothesis was proposed
    by Dirac. In this paper, we propose a new method to investigate a possible time
    variation of the speed of light (c) along with the fine-structure constant (α)
    using Strong Gravitational Lensing (SGL) and Type Ia Supernovae (SNe Ia) observations.
    We assume a general approach to describe the mass distribution of lens-type galaxies,
    the one in favor of the power-law index model (PLAW). We also consider the runaway
    dilaton model to describe a possible time-variation of α. In order to explore
    the results deeply, we split the SGL sample into five sub-samples according to
    the lens stellar velocity dispersion and three sub-samples according to lens redshift.
    The results suggest that it is reasonable to treat the systems separately, but
    no strong indication of varying c was …
- title: 'How Computer Science and Statistics Instructors Approach Data Science Pedagogy
    Differently: Three Case Studies'
  authors: Sam Lau and Deborah Nolan and Joseph Gonzalez and Philip J Guo
  venue: ''
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:PoWvk5oyLR8C
  abstract: 'Over the past decade, data science courses have been growing more popular
    across university campuses. These courses often involve a mix of programming and
    statistics and are taught by instructors from diverse backgrounds. In our experiences
    launching a data science program at a large public U.S. university over the past
    four years, we noticed one central tension within many such courses: instructors
    must finely balance how much computing versus statistics to teach in the limited
    available time. In this experience report, we provide a detailed firsthand reflection
    on how we have personally balanced these two major topic areas within several
    offerings of a large introductory data science course that we taught and wrote
    an accompanying textbook for; our course has served several thousand students
    over the past four years. We present three case studies from our experiences to
    illustrate how computer science …'
- title: 'CathAI: fully automated interpretation of coronary angiograms using neural
    networks'
  authors: Robert Avram and Jeffrey E Olgin and Alvin Wan and Zeeshan Ahmed and Louis
    Verreault-Julien and Sean Abreau and Derek Wan and Joseph E Gonzalez and Derek
    Y So and Krishan Soni and Geoffrey H Tison
  venue: arXiv preprint arXiv:2106.07708
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:g3aElNc5_aQC
  abstract: 'Coronary heart disease (CHD) is the leading cause of adult death in the
    United States and worldwide, and for which the coronary angiography procedure
    is the primary gateway for diagnosis and clinical management decisions. The standard-of-care
    for interpretation of coronary angiograms depends upon ad-hoc visual assessment
    by the physician operator. However, ad-hoc visual interpretation of angiograms
    is poorly reproducible, highly variable and bias prone. Here we show for the first
    time that fully-automated angiogram interpretation to estimate coronary artery
    stenosis is possible using a sequence of deep neural network algorithms. The algorithmic
    pipeline we developed--called CathAI--achieves state-of-the art performance across
    the sequence of tasks required to accomplish automated interpretation of unselected,
    real-world angiograms. CathAI (Algorithms 1-2) demonstrated positive predictive
    value, sensitivity and F1 score of >=90% to identify the projection angle overall
    and >=93% for left or right coronary artery angiogram detection, the primary anatomic
    structures of interest. To predict obstructive coronary artery stenosis (>=70%
    stenosis), CathAI (Algorithm 4) exhibited an area under the receiver operating
    characteristic curve (AUC) of 0.862 (95% CI: 0.843-0.880). When externally validated
    in a healthcare system in another country, CathAI AUC was 0.869 (95% CI: 0.830-0.907)
    to predict obstructive coronary artery stenosis. Our results demonstrate that
    multiple purpose-built neural networks can function in sequence to accomplish
    the complex series of tasks required for automated analysis of real-world angiograms.
    Deployment of …'
- title: The restless cloud
  authors: Nathan Pemberton and Johann Schleier-Smith and Joseph E Gonzalez
  venue: ''
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:0KyAp5RtaNEC
  abstract: Cloud provider APIs have emerged as the de facto operating system interface
    for the warehouse scale computers that comprise the public cloud. Like single-server
    operating systems, they provide the resource allocation, protection, communication
    paths, naming, and scheduling for these large machines. Cloud provider APIs also
    provide all sorts of things that operating systems do not, things like big data
    analytics, machine learning model training, or factory automation. Somewhere,
    lurking within this menagerie of services, there is an operating system interface
    to a really big computer, the computer that today's application developers target.
    This computer works nothing like a single server, yet it also isn't a dispersed
    distributed system like the internet. It is something in-between. Now is the time
    to distill and refine a coherent "cloud system interface" from the multitude of
    cloud provider APIs, preferably a portable one …
- title: Online learning of competitive equilibria in exchange economies
  authors: Wenshuo Guo and Kirthevasan Kandasamy and Joseph E Gonzalez and Michael
    I Jordan and Ion Stoica
  venue: arXiv preprint arXiv:2106.06616
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:gsN89kCJA0AC
  abstract: ''
- title: Learning robot policies for untangling dense knots in linear deformable structures
  authors: Jennifer Grannen and Priya Sundaresan and Brijen Thananjeyan and Jeff Ichnowski
    and Ashwin Balakrishna and Vainavi Viswanath and Michael Laskey and Joseph E Gonzalez
    and Ken Goldberg
  venue: Conference on Robot Learning (CoRL)
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:dTyEYWd-f8wC
  abstract: 'Untangling linear deformable objects (LDOs) such as ropes, wires, and
    cables is a challenging robot task due to the vast set of possible arrangements,
    visual homogeneity, self-occlusions, and complex dynamics. Prior geometric methods
    have focused on loose knot configurations using full rope state estimation before
    planning, while prior data-driven approaches require substantial environment interaction.
    We consider dense (tight) knots that lack space between self-intersections and
    present an iterative algorithm that leverages geometric structure in configurations
    to untie knots. We then practically instantiate this algorithm with HULK: Hierarchical
    Untangling from Learned Keypoints, which combines learning-based perception with
    a bilateral geometric planner to perform untangling without performing full state
    estimation. To evaluate the learned policy, we develop a novel simulator to simulate
    rope with figure-eight and overhand knots and with varying appearances. We present
    experiments comparing two variants of HULK to three baselines and find that HULK
    is able to untangle LDOs consisting of tight figure-eight and overhand knots.
    We find that HULK achieves higher success rates and fewer empirical actions than
    analytical baselines while generalizing to varied textures and appearances. HULK
    is able to successfully untangle an LDO from a dense initial configuration containing
    only up to two overhand and figure-eight knots in 97.9% of 378 simulated experiments
    with an average of 12.1 actions per trial, suggesting that the policy can learn
    the task of untangling effectively from an algorithmic supervisor.'
- title: Random projection design for scalable implicit smoothing of randomly observed
    stochastic processes
  authors: Francois Belletti and Evan Sparks and Alexandre Bayen and Joseph Gonzalez
  venue: Artificial Intelligence and Statistics
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ldfaerwXgEUC
  abstract: Sampling at random timestamps, long range dependencies, and scale hamper
    standard meth-ods for multivariate time series analysis. In this paper we present
    a novel estimator for cross-covariance of randomly observed time series which
    unravels the dynamics of an unobserved stochastic process. We analyze the statistical
    properties of our estimator without needing the assumption that observation timestamps
    are independent from the process of interest and show that our solution is not
    hindered by the issues affecting standard estimators for cross-covariance. We
    implement and evaluate our statistically sound and scalable approach in the distributed
    setting using Apache Spark and demonstrate its ability to unravel causal dynamics
    on both simulations and high-frequency financial trading data.
- title: 'DFS-PERF: A scalable and unified benchmarking framework for distributed
    file systems'
  authors: Rong Gu and Qianhao Dong and Haoyuan Li and Joseph Gonzalez and Zhao Zhang
    and Shuai Wang and Yihua Huang and Scott Shenker and Ion Stoica and Patrick PC
    Lee
  venue: EECS Dept., Univ. California, Berkeley, Berkeley, CA, USA, Tech. Rep. UCB/EECS-2016
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Tyk-4Ss8FVUC
  abstract: A distributed file system (DFS) is a key component of virtually any cluster
    computing system. The performance of such system depends heavily on the underlying
    DFS design and deployment. As a result, it is critical to characterize the performance
    and design trade-offs of DF-Ses with respect to cluster configurations and real-world
    workloads. To this end, we present DFS-Perf, a scalable, extensible, and low-overhead
    benchmarking framework to evaluate the properties and the performance of various
    DFS implementations. DFS-Perf uses a highly parallel architecture to cover a large
    variety of workloads at different scales, and provides an extensible interface
    to incorporate user-defined workloads and integrate with various DFSes. As a proof
    of concept, our current DFS-Perf implementation includes several built-in benchmarks
    and workloads, including machine learning and SQL applications. We present performance
    comparisons of four stateof-the-art DFS designs, namely Alluxio, CephFS, GlusterFS,
    and HDFS, on a cluster with 40 nodes (960 cores). We demonstrate that DFS-Perf
    can provide guidance on existing DFS designs and implementations, while adding
    5.7% overhead.
- title: El impacto de las redes sociales en la enseñanza y el aprendizaje
  authors: C Espuny and J González and M Lleixá and M Gisbert
  venue: Revista de Universidad y Sociedad de Conocimiento
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:-95Q15plzcUC
  abstract: ''
- title: Locations of aftershocks of the Oaxaca earthquake using smoked paper recorders
    and digital event recorders
  authors: A Reyes and J Gonzalez and L Munguia and A Nava and F Nernon and JN Brune
  venue: Geofísica Internacional
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:GtLg2Ama23sC
  abstract: 'Dentro de un proyecto c0operativo en, tre ClCESE y UCSD,. se instalo
    una red de 15 sismografos en la region de las replicas del temblor de Oaxaca (Ms=
    7. 8), de Novie111bre 29, 1978. Ocho sismografos veriicales con registro en papel
    ahumado y siete sismografos de 3 componentes, cor1 graficacion: en formato digital,
    se! listribµyeron 10gfsticamente en. 9 localidades sobre el area de interes. La
    red se. inicio con la instalacion de la priinera estacion endiciembre 1 o; enti-6
    en operacion total cl 5 de diciembre. Cientos de eventos se registraron en papel
    ahumado y un w''. imero considerable se detect. 6 simult~ neamente en las grabadoras
    digitales. Los. registros digitales han sido especialmente utiles para la determinacion
    precisa de. los tiempos de arribo de la onda S. Los resultados'' presentados aqu1,
    incluyen datos para el perfodo del 3 al 18 de diciembre de 1978. Las replicas
    estan distribuidas enuna superficie. de aproximadamente 3,000 km2, con una longitud
    de 60 km, paralela a la costa, y una (Jxtension. de:} 5 km, en tierra firme. La
    distribucion de hipocentros sugiere una echado de 20 para la zona Benioff. Las
    profimdidades va: rian de 10 km al sur de la linea de costa, hasta 40 km hacia
    el norte. En el extremo norte, a 90 km del eje dela. trinchera mesoamericana,
    la zona de ruptura parece de. ternerse abruptamente, debido a la exislencia de
    una falla secundaria, normal al piano de subducci6n. F. sta falla, por prim era
    vez inferida en base a un estudio local, preser1ta un mecanismo focal compuesto
    de tipo normal. Probablerriente el movir''niento sismico principal ocurrio en
    esta. falla, lo cual podrfa explicar los graves dafios …'
- title: DIGITAL SEISMOGRAPH AND STRONG MOTION RECORDINGS OF EARTHQUAKES IN VICTORIA,
    BC MEXICO SWARM OF MARCH, 1978
  authors: L Munguia and JN Brune and R Adair and J Gonzalez and R Simons and F Vernon
  venue: TRANSACTIONS-AMERICAN GEOPHYSICAL UNION
  year: ''
  citations: 8
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:9pM33mqn1YgC
  abstract: ''
- title: Simple token-level confidence improves caption correctness
  authors: Suzanne Petryk and Spencer Whitehead and Joseph E Gonzalez and Trevor Darrell
    and Anna Rohrbach and Marcus Rohrbach
  venue: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer
    Vision
  year: ''
  citations: 7
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:OR75R8vi5nAC
  abstract: The ability to judge whether a caption correctly describes an image is
    a critical part of vision-language understanding. However, state-of-the-art models
    often misinterpret the correctness of fine-grained details, leading to errors
    in outputs such as hallucinating objects in generated captions or poor compositional
    reasoning. In this work, we explore Token-Level Confidence, or TLC, as a simple
    yet surprisingly effective method to assess caption correctness. Specifically,
    we fine-tune a vision-language model on image captioning, input an image and proposed
    caption to the model, and aggregate either algebraic or learned token confidences
    over words or sequences to estimate image-caption consistency. Compared to sequence-level
    scores from pretrained models, TLC with algebraic confidence more than doubles
    image and group scores for compositional reasoning on Winoground. When training
    data are available, a learned confidence estimator provides further improved performance,
    reducing object hallucination rates in MS COCO Captions by a relative 30% over
    the original model and setting a new state-of-the-art.
- title: Elastic hyperparameter tuning on the cloud
  authors: Lisa Dunlap and Kirthevasan Kandasamy and Ujval Misra and Richard Liaw
    and Michael Jordan and Ion Stoica and Joseph E Gonzalez
  venue: ''
  year: ''
  citations: 7
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:vDijr-p_gm4C
  abstract: Hyperparameter tuning is a necessary step in training and deploying machine
    learning models. Most prior work on hyperparameter tuning has studied methods
    for maximizing model accuracy under a time constraint, assuming a fixed cluster
    size. While this is appropriate in data center environments, the increased deployment
    of machine learning workloads in cloud settings necessitates studying hyperparameter
    tuning with an elastic cluster size and time and monetary budgets. While recent
    work has leveraged the elasticity of the cloud to minimize the execution cost
    of a pre-determined hyperparameter tuning job originally designed for fixed-cluster
    sizes, they do not aim to maximize accuracy.In this work, we aim to maximize accuracy
    given time and cost constraints. We introduce SEER---Sequential Elimination with
    Elastic Resources, an algorithm that tests different hyperparameter values in
    the beginning and …
- title: 'Sensai: Fast convnets serving on live data via class parallelism'
  authors: Guanhua Wang and Zhuang Liu and Siyuan Zhuang and Brandon Hsieh and Joseph
    Gonzalez and Ion Stoica
  venue: MLOps Systems workshop in MLSys
  year: ''
  citations: 7
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:eQOLeE2rZwMC
  abstract: 'Convolutional Neural Networks (ConvNets) enable computers to excel on
    vision learning tasks such as image classification, object detection. As model-size
    and dataset-scale are growing larger, the serving time of a single ConvNet increases
    drastically. Thus, distributed serving is adopted to speedup the process by running
    a single CNN over multiple machines simultaneously. Conventional distributed approaches
    are data parallelism [7, 20] and model parallelism [1, 8]. In data parallelism,
    each GPU has a full copy of the model and do inference independently on a subset
    of the whole input data. Model parallelism adopts a different approach: each GPU
    only maintains a portion of the whole model, and communicates intermediate results
    (eg feature-maps) during each round of model serving.Making faster decision on
    live data is becoming more and more important. In the case like autonomous driving
    [4, 19], once the camera captures a frame of image that contains pedestrian, it
    may save people’s lives if the stop decision can be made slightly faster. Other
    application scenarios like automatic stock trading using machine learning, right
    now is happening in giant banks like JP Morgan [21] and Goldman Sachs [15]. If
    one party can make the trading decision several milliseconds earlier than the
    others, it can bring in huge amount of profits. From a system perspective, making
    fast decision on live data means faster model serving on each incoming data item
    (eg an image, a stock’s instantaneous price). Neither data parallelism nor model
    parallelism can achieve faster serving on single data item. It is infeasible to
    split an atomic input piece further for data …'
- title: 'Unsupervised domain adaptation: From simulation engine to the realworld'
  authors: Sicheng Zhao and Bichen Wu and Joseph Gonzalez and Sanjit A Seshia and
    Kurt Keutzer
  venue: arXiv preprint arXiv:1803.09180
  year: ''
  citations: 7
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:d1gkVwhDpl0C
  abstract: Large-scale labeled training datasets have enabled deep neural networks
    to excel on a wide range of benchmark vision tasks. However, in many applications
    it is prohibitively expensive or time-consuming to obtain large quantities of
    labeled data. To cope with limited labeled training data, many have attempted
    to directly apply models trained on a large-scale labeled source domain to another
    sparsely labeled target domain. Unfortunately, direct transfer across domains
    often performs poorly due to domain shift and dataset bias. Domain adaptation
    is the machine learning paradigm that aims to learn a model from a source domain
    that can perform well on a different (but related) target domain. In this paper,
    we summarize and compare the latest unsupervised domain adaptation methods in
    computer vision applications. We classify the non-deep approaches into sample
    re-weighting and intermediate subspace transformation categories, while the deep
    strategy includes discrepancy-based methods, adversarial generative models, adversarial
    discriminative models and reconstruction-based methods. We also discuss some potential
    directions.
- title: Faster jobs in distributed data processing using multi-task learning
  authors: Neeraja J Yadwadkar and Bharath Hariharan and Joseph Gonzalez and Randy
    Katz
  venue: ''
  year: ''
  citations: 7
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:r0BpntZqJG4C
  abstract: Slow running or straggler tasks in distributed processing frameworks [1,
    2] can be 6 to 8 times slower than the median task in a job on a production cluster
    [3], despite existing mitigation techniques. This leads to extended job completion
    times, inefficient use of resources, and increased costs. Recently, proactive
    straggler avoidance techniques [4] have explored the use of predictive models
    to improve task scheduling. However, to capture node and workload variability,
    separate models are built for every node and workload, requiring the time consuming
    collection of training data and limiting the applicability to new nodes and workloads.
    In this work, we observe that predictors for similar nodes or workloads are likely
    to be similar and can share information, suggesting a multi-task learning (MTL)
    based approach. We generalize the MTL formulation of [5] to capture commonalities
    in arbitrary groups. Using our …
- title: The development and evaluation of a thermally-desorbable miniature passive
    dosimeter for the monitoring of organic vapors
  authors: J Gonzalez and SP Levine
  venue: American Industrial Hygiene Association journal
  year: ''
  citations: 7
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:0EnyYjriUFMC
  abstract: 'A thermally desorbable passive dosimeter for organic vapors has been
    developed in conformity with theoretical and practical aspects of passive dosimeter
    design. The device was optimized for low sample loadings which result from short-term
    and/or low concentration level exposure. Laboratory evaluation of this device
    for factors critical to the performance of passive dosimeters included the following:
    desorption efficiency, capacity, sensitivity, accuracy and precision, concentration
    level, environmental conditions (e.g., air face velocity, relative humidity) and
    sample stability during short and long periods of time. This device has been shown
    to operate in accordance with theoretically predicted performance and should be
    adequate for short-term exposure limits and/or low concentration monitoring of
    organic vapors in the workplace.'
- title: 'Distflashattn: Distributed memory-efficient attention for long-context llms
    training'
  authors: Dacheng Li and Rulin Shao and Anze Xie and Eric P Xing and Xuezhe Ma and
    Ion Stoica and Joseph E Gonzalez and Hao Zhang
  venue: First Conference on Language Modeling
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:prdVHNxh-e8C
  abstract: 'FlashAttention effectively reduces the quadratic peak memory usage to
    linear in training transformer-based large language models (LLMs) on a single
    GPU. In this paper, we introduce DistFlashAttention, a distributed memory-efficient
    attention mechanism optimized for long-context LLMs training. We propose three
    key techniques: token-level workload balancing, overlapping key-value communication,
    and a rematerialization-aware gradient checkpointing algorithm. We evaluate DistFlashAttention
    on Llama-7B and variants with sequence lengths from 32K to 512K. DistFlashAttention
    achieves 8x longer sequences, 4.45 - 5.64x speedup compared to Ring Self-Attention,
    2-8x longer sequences, 1.24- 2.01x speedup compared to Megatron-LM with FlashAttention.
    It achieves 1.67x and 1.26-1.88x speedup compared to recent Ring Attention and
    DeepSpeed-Ulysses. Codes are available at https://github.com/RulinShao/LightSeq.'
- title: Prior knowledge-guided attention in self-supervised vision transformers
  authors: Kevin Miao and Akash Gokul and Raghav Singh and Suzanne Petryk and Joseph
    Gonzalez and Kurt Keutzer and Trevor Darrell
  venue: arXiv preprint arXiv:2209.03745
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:NXb4pA-qfm4C
  abstract: Recent trends in self-supervised representation learning have focused
    on removing inductive biases from training pipelines. However, inductive biases
    can be useful in settings when limited data are available or provide additional
    insight into the underlying data distribution. We present spatial prior attention
    (SPAN), a framework that takes advantage of consistent spatial and semantic structure
    in unlabeled image datasets to guide Vision Transformer attention. SPAN operates
    by regularizing attention masks from separate transformer heads to follow various
    priors over semantic regions. These priors can be derived from data statistics
    or a single labeled sample provided by a domain expert. We study SPAN through
    several detailed real-world scenarios, including medical image analysis and visual
    quality assurance. We find that the resulting attention masks are more interpretable
    than those derived from domain-agnostic pretraining. SPAN produces a 58.7 mAP
    improvement for lung and heart segmentation. We also find that our method yields
    a 2.2 mAUC improvement compared to domain-agnostic pretraining when transferring
    the pretrained model to a downstream chest disease classification task. Lastly,
    we show that SPAN pretraining leads to higher downstream classification performance
    in low-data regimes compared to domain-agnostic pretraining.
- title: Learning to design accurate deep learning accelerators with inaccurate multipliers
  authors: Paras Jain and Safeen Huda and Martin Maas and Joseph E Gonzalez and Ion
    Stoical and Azalia Mirhoseini
  venue: 2022 Design, Automation & Test in Europe Conference & Exhibition (DATE)
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:W5xh706n7nkC
  abstract: Approximate computing is a promising way to improve the power efficiency
    of deep learning. While recent work proposes new arithmetic circuits (adders and
    multipliers) that consume substantially less power at the cost of computation
    errors, these approximate circuits decrease the end-to-end accuracy of common
    models. We present AutoApprox, a framework to automatically generate approximate
    low-power deep learning accelerators without any accuracy loss. AutoApprox generates
    a wide range of approximate ASIC accelerators with a TPUv3 systolic-array template.
    AutoApprox uses a learned router to assign each DNN layer to an approximate systolic
    array from a bank of arrays with varying approximation levels. By tailoring this
    routing for a specific neural network architecture, we discover circuit designs
    without the accuracy penalty from prior methods. Moreover, AutoApprox optimizes
    for the end-to-end …
- title: Thompson sampling for linearly constrained bandits
  authors: Vidit Saxena and Joakim Jalden and Joseph Gonzalez
  venue: International Conference on Artificial Intelligence and Statistics
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:7PzlFSSx8tAC
  abstract: We address multi-armed bandits (MAB) where the objective is to maximize
    the cumulative reward under a probabilistic linear constraint. For a few real-world
    instances of this problem, constrained extensions of the well-known Thompson Sampling
    (TS) heuristic have recently been proposed. However, finite-time analysis of constrained
    TS is challenging; as a result, only O (sqrt (T)) bounds on the cumulative reward
    loss (ie, the regret) are available. In this paper, we describe LinConTS, a TS-based
    algorithm for bandits that place a linear constraint on the probability of earning
    a reward in every round. We show that for LinConTS, the regret as well as the
    cumulative constraint violations are upper bounded by O (log (T)). We develop
    a proof technique that relies on careful analysis of the dual problem and combine
    it with recent theoretical work on unconstrained TS. Through numerical experiments
    on two real-world datasets, we demonstrate that LinConTS outperforms an asymptotically
    optimal upper confidence bound (UCB) scheme in terms of simultaneously minimizing
    the regret and the violation.
- title: 'CoVista: A unified view on privacy sensitive mobile contact tracing effort'
  authors: David Culler and Prabal Dutta and Gabe Fierro and Joseph E Gonzalez and
    Nathan Pemberton and Johann Schleier-Smith and Kalyanaraman Shankari and Alvin
    Wan and Thomas Zachariah
  venue: arXiv preprint arXiv:2005.13164
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:4DMP91E08xMC
  abstract: 'Governments around the world have become increasingly frustrated with
    tech giants dictating public health policy. The software created by Apple and
    Google enables individuals to track their own potential exposure through collated
    exposure notifications. However, the same software prohibits location tracking,
    denying key information needed by public health officials for robust contract
    tracing. This information is needed to treat and isolate COVID-19 positive people,
    identify transmission hotspots, and protect against continued spread of infection.
    In this article, we present two simple ideas: the lighthouse and the covid-commons
    that address the needs of public health authorities while preserving the privacy-sensitive
    goals of the Apple and google exposure notification protocols.'
- title: Domain-aware dynamic networks
  authors: Tianyuan Zhang and Bichen Wu and Xin Wang and Joseph Gonzalez and Kurt
    Keutzer
  venue: arXiv preprint arXiv:1911.13237
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:LPZeul_q3PIC
  abstract: 'Deep neural networks with more parameters and FLOPs have higher capacity
    and generalize better to diverse domains. But to be deployed on edge devices,
    the model''s complexity has to be constrained due to limited compute resource.
    In this work, we propose a method to improve the model capacity without increasing
    inference-time complexity. Our method is based on an assumption of data locality:
    for an edge device, within a short period of time, the input data to the device
    are sampled from a single domain with relatively low diversity. Therefore, it
    is possible to utilize a specialized, low-complexity model to achieve good performance
    in that input domain. To leverage this, we propose Domain-aware Dynamic Network
    (DDN), which is a high-capacity dynamic network in which each layer contains multiple
    weights. During inference, based on the input domain, DDN dynamically combines
    those weights into one single weight that specializes in the given domain. This
    way, DDN can keep the inference-time complexity low but still maintain a high
    capacity. Experiments show that without increasing the parameters, FLOPs, and
    actual latency, DDN achieves up to 2.6\% higher AP50 than a static network on
    the BDD100K object-detection benchmark.'
- title: Ideas sobre la Animación Sociocultural de la lengua
  authors: A Jiménez and J González
  venue: 'Aulas para la imaginación: La formación desde la animación Sociocultural
    de la lengua'
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:IaI1MmNe2tcC
  abstract: ''
- title: Extending deep model predictive control with safety augmented value estimation
    from demonstrations
  authors: Brijen Thananjeyan and Ashwin Balakrishna and Ugo Rosolia and Felix Li
    and Rowan McAllister and Joseph E Gonzalez and Sergey Levine and Francesco Borrelli
    and Ken Goldberg
  venue: arXiv preprint arXiv:1905.13402
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:evX43VCCuoAC
  abstract: ''
- title: Using multitask learning to improve 12-lead electrocardiogram classification
  authors: J Weston Hughes and Taylor Sittler and Anthony D Joseph and Jeffrey E Olgin
    and Joseph E Gonzalez and Geoffrey H Tison
  venue: arXiv preprint arXiv:1812.00497
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:YsMSGLbcyi4C
  abstract: We develop a multi-task convolutional neural network (CNN) to classify
    multiple diagnoses from 12-lead electrocardiograms (ECGs) using a dataset comprised
    of over 40,000 ECGs, with labels derived from cardiologist clinical interpretations.
    Since many clinically important classes can occur in low frequencies, approaches
    are needed to improve performance on rare classes. We compare the performance
    of several single-class classifiers on rare classes to a multi-headed classifier
    across all available classes. We demonstrate that the addition of common classes
    can significantly improve CNN performance on rarer classes when compared to a
    model trained on the rarer class in isolation. Using this method, we develop a
    model with high performance as measured by F1 score on multiple clinically relevant
    classes compared against the gold-standard cardiologist interpretation.
- title: Scalable linear causal inference for irregularly sampled time series with
    long range dependencies
  authors: Francois W Belletti and Evan R Sparks and Michael J Franklin and Alexandre
    M Bayen and Joseph E Gonzalez
  venue: arXiv preprint arXiv:1603.03336
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:8k81kl-MbHgC
  abstract: 'Linear causal analysis is central to a wide range of important application
    spanning finance, the physical sciences, and engineering. Much of the existing
    literature in linear causal analysis operates in the time domain. Unfortunately,
    the direct application of time domain linear causal analysis to many real-world
    time series presents three critical challenges: irregular temporal sampling, long
    range dependencies, and scale. Moreover, real-world data is often collected at
    irregular time intervals across vast arrays of decentralized sensors and with
    long range dependencies which make naive time domain correlation estimators spurious.
    In this paper we present a frequency domain based estimation framework which naturally
    handles irregularly sampled data and long range dependencies while enabled memory
    and communication efficient distributed processing of time series data. By operating
    in the frequency domain we eliminate the need to interpolate and help mitigate
    the effects of long range dependencies. We implement and evaluate our new work-flow
    in the distributed setting using Apache Spark and demonstrate on both Monte Carlo
    simulations and high-frequency financial trading that we can accurately recover
    causal structure at scale.'
- title: Parallel and Distributed Systems for Probabilistic Reasoning
  authors: Joseph Gonzalez
  venue: ''
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ZeXyd9-uunAC
  abstract: Scalable probabilistic reasoning is the key to unlocking the full potential
    of the age of big data. From untangling the biological processes that govern cancer
    to effectively targeting products and advertisements, probabilistic reasoning
    is how we make sense of noisy data and turn information into understanding and
    action. Unfortunately, the algorithms and tools for sophisticated structured probabilistic
    reasoning were developed for the sequential Von Neumann architecture and have
    therefore been unable to scale with big data. In this thesis we propose a simple
    set of design principles to guide the development of new parallel and distributed
    algorithms and systems for scalable probabilistic reasoning. We then apply these
    design principles to develop a series of new algorithms for inference in probabilistic
    graphical models and derive theoretical tools to characterize the parallel properties
    of statistical inference. We implement and assess the efficiency and scalability
    of the new inference algorithms in the multicore and distributed settings demonstrating
    the substantial gains from applying the thesis methodology to real-world probabilistic
    reasoning. Based on the lessons learned in statistical inference we introduce
    the GraphLab parallel abstraction which generalizes the thesis methodology and
    enable the rapid development of new efficient and scalable parallel and distributed
    algorithms for probabilistic reasoning. We demonstrate how the GraphLab abstraction
    can be used to rapidly develop new scalable algorithms for probabilistic reasoning
    and assess their performance on real-world problems in both the multicore and
    distributed settings. Finally …
- title: Linear-time inverse covariance matrix estimation in Gaussian processes
  authors: Joseph Gonzalez and Sue Ann Hong
  venue: arXiv preprint arXiv:1610.08035
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:f2IySw72cVMC
  abstract: The computational cost of Gaussian process regression grows cubically
    with respect to the number of variables due to the inversion of the covariance
    matrix, which is impractical for data sets with more than a few thousand nodes.
    Furthermore, Gaussian processes lack the ability to represent conditional independence
    assertions between variables. We describe iterative proportional scaling for directly
    estimating the precision matrix without inverting the covariance matrix, given
    an undirected graph and a covariance function or data. We introduce a variant
    of the Shafer-Shenoy algorithm combined with IPS that runs in O (nC3)-time, where
    C is the largest clique size in the induced junction tree. We present results
    on synthetic data and temperature prediction in a real sensor network.
- title: In vitro regeneration of Gomortega keule (Gomortegaceae), a Chilean endemic
    tree in danger of extinction
  authors: M Jordan and J Gonzalez and C Roveraro
  venue: European Journal of Horticultural Science
  year: ''
  citations: 6
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:r_AWSJRzSzQC
  abstract: 'Axillary buds of nodal sections from 2-year old trees of Gomortega keule
    (Mol.) Baillon,‘Queule’,‘Keule’,(Family: Gomortegaceae) were induced to sprout
    and developed many shoots in presence of 0.54 μM naphthaleneacetic acid (NAA)
    and 4.44 μM benzylaminopurine (BA) in a liquid WP-medium (LLOYD and MCCOWN 1980)
    within a period of 2–3 weeks. After transfer to a medium containing 22.2 μM BA,
    each new single node section of about 0.5 cm initiated numerous adventitious shoots;
    alternatively, roots were formed when these explants were transferred to a medium
    containing 2.95, 12.3 or 24.6 μM indolebutyric acid (IBA). Root formation took
    place in presence of 24.6 μM IBA in approx. 46% of the sub-cultured nodal segments
    after a period of 3 months, leading to plantlets. Regeneration response was restricted
    to the sprouts of axillary buds; other explant-types tested, ie petioles, leaf,
    and internodal …'
- title: 'Text2sql is not enough: Unifying ai and databases with tag'
  authors: Asim Biswal and Liana Patel and Siddarth Jha and Amog Kamsetty and Shu
    Liu and Joseph E Gonzalez and Carlos Guestrin and Matei Zaharia
  venue: arXiv preprint arXiv:2408.14717
  year: ''
  citations: 5
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:yxmsSjX2EkcC
  abstract: AI systems that serve natural language questions over databases promise
    to unlock tremendous value. Such systems would allow users to leverage the powerful
    reasoning and knowledge capabilities of language models (LMs) alongside the scalable
    computational power of data management systems. These combined capabilities would
    empower users to ask arbitrary natural language questions over custom data sources.
    However, existing methods and benchmarks insufficiently explore this setting.
    Text2SQL methods focus solely on natural language questions that can be expressed
    in relational algebra, representing a small subset of the questions real users
    wish to ask. Likewise, Retrieval-Augmented Generation (RAG) considers the limited
    subset of queries that can be answered with point lookups to one or a few data
    records within the database. We propose Table-Augmented Generation (TAG), a unified
    and general-purpose paradigm for answering natural language questions over databases.
    The TAG model represents a wide range of interactions between the LM and database
    that have been previously unexplored and creates exciting research opportunities
    for leveraging the world knowledge and reasoning capabilities of LMs over data.
    We systematically develop benchmarks to study the TAG problem and find that standard
    methods answer no more than 20% of queries correctly, confirming the need for
    further research in this area. We release code for the benchmark at https://github.com/TAG-Research/TAG-Bench.
- title: 'SLoRA: Scalable Serving of Thousands of LoRA Adapters'
  authors: Ying Sheng and Shiyi Cao and Dacheng Li and Coleman Hooper and Nicholas
    Lee and Shuo Yang and Christopher Chou and Banghua Zhu and Lianmin Zheng and Kurt
    Keutzer and Joseph Gonzalez and Ion Stoica
  venue: Proceedings of Machine Learning and Systems
  year: ''
  citations: 5
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:MhiOAD_qIWkC
  abstract: The" pretrain-then-finetune" paradigm is commonly adopted in the deployment
    of large language models. Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning
    method, is often employed to adapt a base model to a multitude of tasks, resulting
    in a substantial collection of LoRA adapters derived from one base model. We observe
    that this paradigm presents significant opportunities for batched inference during
    serving. To capitalize on these opportunities, we present SLoRA, a system designed
    for the scalable serving of many LoRA adapters. SLoRA stores all adapters in the
    main memory and fetches the adapters used by the currently running queries to
    the GPU memory. To efficiently use the GPU memory and reduce fragmentation, SLoRA
    proposes a unified memory pool. This memory pool uses a unified paging mechanism
    to manage dynamic adapter weights with different ranks and KV cache tensors with
    varying sequence lengths. Additionally, SLoRA employs a novel tensor parallelism
    strategy and highly optimized custom CUDA kernels for batched LoRA computation.
    Collectively, these features enable SLoRA to serve thousands of LoRA adapters
    on a single GPU or across multiple GPUs with a small overhead. Compared to state-of-the-art
    libraries such as HuggingFace PEFT and vLLM (with naive support of LoRA serving),
    SLoRA can improve the throughput by up to 4 times and increase the number of served
    adapters by several orders of magnitude. As a result, SLoRA enables scalable serving
    of many task-specific fine-tuned models and offers the potential for large-scale
    customized fine-tuning services.
- title: 'ALOHa: A New Measure for Hallucination in Captioning Models'
  authors: Suzanne Petryk and David M Chan and Anish Kachinthaya and Haodi Zou and
    John Canny and Joseph E Gonzalez and Trevor Darrell
  venue: arXiv preprint arXiv:2404.02904
  year: ''
  citations: 5
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ALROH1vI_8AC
  abstract: Despite recent advances in multimodal pre-training for visual description,
    state-of-the-art models still produce captions containing errors, such as hallucinating
    objects not present in a scene. The existing prominent metric for object hallucination,
    CHAIR, is limited to a fixed set of MS COCO objects and synonyms. In this work,
    we propose a modernized open-vocabulary metric, ALOHa, which leverages large language
    models (LLMs) to measure object hallucinations. Specifically, we use an LLM to
    extract groundable objects from a candidate caption, measure their semantic similarity
    to reference objects from captions and object detections, and use Hungarian matching
    to produce a final hallucination score. We show that ALOHa correctly identifies
    13.6% more hallucinated objects than CHAIR on HAT, a new gold-standard subset
    of MS COCO Captions annotated for hallucinations, and 30.8% more on nocaps, where
    objects extend beyond MS COCO categories. Our code is available at https://davidmchan.github.io/aloha/.
- title: The effect of model size on worst-group generalization
  authors: Alan Pham and Eunice Chan and Vikranth Srivatsa and Dhruba Ghosh and Yaoqing
    Yang and Yaodong Yu and Ruiqi Zhong and Joseph E Gonzalez and Jacob Steinhardt
  venue: arXiv preprint arXiv:2112.04094
  year: ''
  citations: 5
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:j8SEvjWlNXcC
  abstract: 'Overparameterization is shown to result in poor test accuracy on rare
    subgroups under a variety of settings where subgroup information is known. To
    gain a more complete picture, we consider the case where subgroup information
    is unknown. We investigate the effect of model size on worst-group generalization
    under empirical risk minimization (ERM) across a wide range of settings, varying:
    1) architectures (ResNet, VGG, or BERT), 2) domains (vision or natural language
    processing), 3) model size (width or depth), and 4) initialization (with pre-trained
    or random weights). Our systematic evaluation reveals that increasing model size
    does not hurt, and may help, worst-group test performance under ERM across all
    setups. In particular, increasing pre-trained model size consistently improves
    performance on Waterbirds and MultiNLI. We advise practitioners to use larger
    pre-trained models when subgroup labels are unknown.'
- title: Pac best arm identification under a deadline
  authors: Brijen Thananjeyan and Kirthevasan Kandasamy and Ion Stoica and Michael
    I Jordan and Ken Goldberg and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2106.03221
  year: ''
  citations: 5
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:L7CI7m0gUJcC
  abstract: We study -PAC best arm identification, where a decision-maker must identify
    an -optimal arm with probability at least , while minimizing the number of arm
    pulls (samples). Most of the work on this topic is in the sequential setting,
    where there is no constraint on the time taken to identify such an arm; this allows
    the decision-maker to pull one arm at a time. In this work, the decision-maker
    is given a deadline of  rounds, where, on each round, it can adaptively choose
    which arms to pull and how many times to pull them; this distinguishes the number
    of decisions made (i.e., time or number of rounds) from the number of samples
    acquired (cost). Such situations occur in clinical trials, where one may need
    to identify a promising treatment under a deadline while minimizing the number
    of test subjects, or in simulation-based studies run on the cloud, where we can
    elastically scale up or down the number of virtual machines to conduct as many
    experiments as we wish, but need to pay for the resource-time used. As the decision-maker
    can only make  decisions, she may need to pull some arms excessively relative
    to a sequential algorithm in order to perform well on all possible problems. We
    formalize this added difficulty with two hardness results that indicate that unlike
    sequential settings, the ability to adapt to the problem difficulty is constrained
    by the finite deadline. We propose Elastic Batch Racing (EBR), a novel algorithm
    for this setting and bound its sample complexity, showing that EBR is optimal
    with respect to both hardness results. We present simulations evaluating EBR in
    this setting, where it outperforms baselines by several orders of …
- title: Preliminary results of the NEA FHR benchmark phase IA and IB (Fuel element
    2-D benchmark)
  authors: B Petrovic and K Ramey and I Hill and E Losa and M Elsawi and Z Wu and
    C Lu and J Gonzalez and D Novog and G Chee and K Huff and M Margulis and N Read
    and E Shwageraus
  venue: ''
  year: ''
  citations: 5
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:PVgj2kMGcgYC
  abstract: '[en] Under the auspices on OECD-NEA, a benchmark has been initiated to
    assess state of the art modelling and simulation capabilities for Fluoride salt-cooled
    High-temperature Reactors (FHRs) with TRISO fuel embedded in fuel plates (''planks'')
    of hexagonal fuel elements. Benchmark phases IA and IB involve reactor physics
    analysis of a representative fuel element, without and with depletion. Several
    configurations are considered (eg, unrodded and rodded configuration, presence
    of burnable absorbers, variable enrichment). Parameters compared include multiplication
    factor, reactivity coefficients, flux distribution, neutron spectrum and isotopic
    composition change with burnup. Seven organizations from four countries are taking
    part in this blind-benchmark exercise, using Monte Carlo and deterministic methods.
    Given the complex combination of materials and geometry, the FHR benchmark is
    expected to be challenging, particularly for deterministic codes. As the nuclear
    data libraries underpinning both deterministic and Monte Carlo methods have had
    limited testing for FHR systems, and molten salt systems in general, the benchmark
    aims to provide feedback to both the nuclear data community as well as molten
    salt reactor designers with regards to the variance of results with different
    nuclear data sources. This paper reports on the current results submitted and
    provides comparisons and analysis. Overall, the observed agreement is satisfactory,
    although notable differences are identified in specific cases, suggesting need
    for further in-depth analysis of those cases.(authors)'
- title: 'GoEX: Perspectives and Designs Towards a Runtime for Autonomous LLM Applications'
  authors: Shishir G Patil and Tianjun Zhang and Vivian Fang and Roy Huang and Aaron
    Hao and Martin Casado and Joseph E Gonzalez and Raluca Ada Popa and Ion Stoica
  venue: arXiv preprint arXiv:2404.06921
  year: ''
  citations: 4
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:1lhNe0rCu4AC
  abstract: Large Language Models (LLMs) are evolving beyond their classical role
    of providing information within dialogue systems to actively engaging with tools
    and performing actions on real-world applications and services. Today, humans
    verify the correctness and appropriateness of the LLM-generated outputs (e.g.,
    code, functions, or actions) before putting them into real-world execution. This
    poses significant challenges as code comprehension is well known to be notoriously
    difficult. In this paper, we study how humans can efficiently collaborate with,
    delegate to, and supervise autonomous LLMs in the future. We argue that in many
    cases, "post-facto validation" - verifying the correctness of a proposed action
    after seeing the output - is much easier than the aforementioned "pre-facto validation"
    setting. The core concept behind enabling a post-facto validation system is the
    integration of an intuitive undo feature, and establishing a damage confinement
    for the LLM-generated actions as effective strategies to mitigate the associated
    risks. Using this, a human can now either revert the effect of an LLM-generated
    output or be confident that the potential risk is bounded. We believe this is
    critical to unlock the potential for LLM agents to interact with applications
    and services with limited (post-facto) human involvement. We describe the design
    and implementation of our open-source runtime for executing LLM actions, Gorilla
    Execution Engine (GoEX), and present open research questions towards realizing
    the goal of LLMs and applications interacting with each other with minimal human
    supervision. We release GoEX at https://github.com/ShishirPatil/gorilla/.
- title: Decomposing Complex Queries for Tip-of-the-tongue Retrieval
  authors: Kevin Lin and Kyle Lo and Joseph E Gonzalez and Dan Klein
  venue: arXiv preprint arXiv:2305.15053
  year: ''
  citations: 4
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:yMeIxYmEMEAC
  abstract: When re-finding items, users who forget or are uncertain about identifying
    details often rely on creative strategies for expressing their information needs
    -- complex queries that describe content elements (e.g., book characters or events),
    information beyond the document text (e.g., descriptions of book covers), or personal
    context (e.g., when they read a book). This retrieval setting, called tip of the
    tongue (TOT), is especially challenging for models heavily reliant on lexical
    and semantic overlap between query and document text. In this work, we introduce
    a simple yet effective framework for handling such complex queries by decomposing
    the query into individual clues, routing those as sub-queries to specialized retrievers,
    and ensembling the results. This approach allows us to take advantage of off-the-shelf
    retrievers (e.g., CLIP for retrieving images of book covers) or incorporate retriever-specific
    logic (e.g., date constraints). We show that our framework incorportating query
    decompositions into retrievers can improve gold book recall up to 7% relative
    again for Recall@5 on a new collection of 14,441 real-world query-book pairs from
    an online community for resolving TOT inquiries.
- title: Learning competitive equilibria in exchange economies with bandit feedback
  authors: Wenshuo Guo and Kirthevasan Kandasamy and Joseph Gonzalez and Michael Jordan
    and Ion Stoica
  venue: International Conference on Artificial Intelligence and Statistics
  year: ''
  citations: 4
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:k8Z6L05lTy4C
  abstract: The sharing of scarce resources among multiple rational agents is one
    of the classical problems in economics. In exchange economies, which are used
    to model such situations, agents begin with an initial endowment of resources
    and exchange them in a way that is mutually beneficial until they reach a competitive
    equilibrium (CE). The allocations at a CE are Pareto efficient and fair. Consequently,
    they are used widely in designing mechanisms for fair division. However, computing
    CEs requires the knowledge of agent preferences which are unknown in several applications
    of interest. In this work, we explore a new online learning mechanism, which,
    on each round, allocates resources to the agents and collects stochastic feedback
    on their experience in using that allocation. Its goal is to learn the agent utilities
    via this feedback and imitate the allocations at a CE in the long run. We quantify
    CE behavior via two losses and propose a randomized algorithm which achieves sublinear
    loss under a parametric class of utilities. Empirically, we demonstrate the effectiveness
    of this mechanism through numerical simulations.
- title: 'CATHAI: Fully automated coronary angiography interpretation and stenosis
    detection using a deep learning-based algorithmic pipeline'
  authors: Robert Avram and Jeffrey Olgin and Alvin Wan and Zeeshan Ahmed and Louis
    Verreault-Julien and Sean Abreau and Derek Wan and Joseph E Gonzalez and Derek
    So and Krishan Soni and Geoffrey Tison
  venue: Journal of the American College of Cardiology
  year: ''
  citations: 4
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:_Ybze24A_UAC
  abstract: BackgroundCoronary angiography is the gold standard for coronary heart
    disease (CHD) evaluation, but relies upon ad-hoc visual assessment which suffers
    from high variability and poor reproducibility. We developed a pipeline of deep
    neural network algorithms (CathAI) that accomplishes the tasks necessary for automated
    assessment of coronary stenosis severity from coronary angiograms.MethodsCathAI
    used angiograms designed to flow sequentially from Algorithms 1 to 4, to achieve
    automated angiogram interpretation (Figure 1) using UCSF data from April 2008
    to December 2019. CathAI-predicted stenosis severity was compared against the
    clinical angiographic report for that artery segment.ResultsA total of 13,843
    angiographic studies were obtained from 11,972 patients. Algorithms 1-2 had positive
    predictive values and sensitivities of≥ 90% to identify angiographic projection
    angle and left/right coronary …
- title: 'MMGSD: Multi-Modal Gaussian Shape Descriptors for correspondence matching
    in 1D and 2D deformable objects'
  authors: Aditya Ganapathi and Priya Sundaresan and Brijen Thananjeyan and Ashwin
    Balakrishna and Daniel Seita and Ryan Hoque and Joseph E Gonzalez and Ken Goldberg
  venue: arXiv preprint arXiv:2010.04339
  year: ''
  citations: 4
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:t7zJ5fGR-2UC
  abstract: We explore learning pixelwise correspondences between images of deformable
    objects in different configurations. Traditional correspondence matching approaches
    such as SIFT, SURF, and ORB can fail to provide sufficient contextual information
    for fine-grained manipulation. We propose Multi-Modal Gaussian Shape Descriptor
    (MMGSD), a new visual representation of deformable objects which extends ideas
    from dense object descriptors to predict all symmetric correspondences between
    different object configurations. MMGSD is learned in a self-supervised manner
    from synthetic data and produces correspondence heatmaps with measurable uncertainty.
    In simulation, experiments suggest that MMGSD can achieve an RMSE of 32.4 and
    31.3 for square cloth and braided synthetic nylon rope respectively. The results
    demonstrate an average of 47.7% improvement over a provided baseline based on
    contrastive learning, symmetric pixel-wise contrastive loss (SPCL), as opposed
    to MMGSD which enforces distributional continuity.
- title: Extracellular tau oligomers produce an immediate impairment of LTP and memory.
    Sci Rep 6
  authors: M Fá and D Puzzo and R Piacentini and A Staniszewski and H Zhang and MA
    Baltrons and DD Li Puma and I Chatterjee and J Li and F Saeed and HL Berman and
    C Ripoli and W Gulisano and J Gonzalez and H Tian and JA Costa and P Lopez and
    E Davidowitz and WH Yu and V Haroutunian and LM Brown and A Palmeri and EM Sigurdsson
    and KE Duff and AF Teich and LS Honig and M Sierks and JG Moe and L D’Adamio and
    C Grassi and NM Kanaan and PE Fraser and O Arancio
  venue: ''
  year: ''
  citations: 4
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:rHJHxKgnXwkC
  abstract: ''
- title: 'The Missing Piece in Complex Analytics: Low Latency, Scalable Model Management
    and Serving with Velox. CoRR abs/1409.3809 (2014)'
  authors: Daniel Crankshaw and Peter Bailis and Joseph E Gonzalez and Haoyuan Li
    and Zhao Zhang and Michael J Franklin and Ali Ghodsi and Michael I Jordan
  venue: arXiv preprint arXiv:1409.3809
  year: ''
  citations: 4
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Wp0gIr-vW9MC
  abstract: ''
- title: Parallel belief propagation in factor graphs
  authors: Joseph Gonzalez and Yucheng Low and Carlos Guestrin
  venue: 'Scaling Up Machine Learning: Parallel and Distributed Approaches'
  year: ''
  citations: 4
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:abG-DnoFyZgC
  abstract: Probabilistic graphical models are used in a wide range of machine learning
    applications. From reasoning about protein interactions (J aimovich et al., 2006)
    to stereo vision (Sun, Shum, and Zheng, 2002), graphical models have facilitated
    the application of probabilistic methods to challenging machine learning problems.
    A core operation in probabilistic graphical models is inference—the process of
    computing the probability of an event given particular observations. Although
    inference is NP-complete in general, there are several popular approximate inference
    algorithms that typically perform well in practice. Unfortunately, the approximate
    inference algorithms are still computationally intensive and therefore can beneﬁt
    from parallelization. In this chapter, we parallelize loopy belief propagation
    (or loopy BP in short), which is used in a wide range of ML applications (Jaimovich
    et al., 2006; Sun et al., 2002; Lan et al., 2006; Baron, Sarvotham, and Baraniuk,
    2010; Singla and Domingos, 2008). We begin by brieﬂy reviewing the sequential
    BP algorithm as well as the necessary background in probabilistic graphical models.
    We then present a collection of parallel shared memory BP algorithms that demonstrate
    the importance of scheduling in parallel BP. Next, we develop the Splash BP algorithm,
    which combines new scheduling ideas to address the limitations of existing sequential
    BP algorithms and achieve theoretically optimal parallel performance. Finally,
    we present how to efﬁciently implement loopy BP algorithms in the distributed
    parallel setting by addressing the challenges of distributed state and load balancing.
    Where possible, we provide …
- title: 'Cloud programming simplified: a Berkeley view on serverless computing, February
    2019'
  authors: Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-che
    Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and João Carreira
    and Karl Krauth and Neeraja Jayant Yadwadkar and Joseph E Gonzalez and Raluca
    Ada Popa and Ion Stoica and David A Patterson
  venue: arXiv preprint arXiv:1902.03383
  year: ''
  citations: 4
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ML0RJ9NH7IQC
  abstract: ''
- title: Cloudcast:{High-Throughput},{Cost-Aware} Overlay Multicast in the Cloud
  authors: Sarah Wooders and Shu Liu and Paras Jain and Xiangxi Mo and Joseph E Gonzalez
    and Vincent Liu and Ion Stoica
  venue: 21st USENIX Symposium on Networked Systems Design and Implementation (NSDI
    24)
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:4xDN1ZYqzskC
  abstract: Bulk data replication across multiple cloud regions and providers is essential
    for large organizations to support data analytics, disaster recovery, and geo-distributed
    model serving. However, data multicast in the cloud can be expensive due to network
    egress costs and slow due to cloud network constraints. In this paper, we study
    the design of high-throughput, cost-optimized overlay multicast for bulk cloud
    data replication that exploits trends in modern provider pricing models along
    with techniques like ephemeral waypoints to minimize cloud networking costs.
- title: Energy-based predictive representations for partially observed reinforcement
    learning
  authors: Tianjun Zhang and Tongzheng Ren and Chenjun Xiao and Wenli Xiao and Joseph
    E Gonzalez and Dale Schuurmans and Bo Dai
  venue: Uncertainty in Artificial Intelligence
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:P7Ujq4OLJYoC
  abstract: In real-world applications, handling partial observability is a common
    requirement for reinforcement learning algorithms, which is not captured by a
    Markov decision process (MDP). Although partially observable Markov decision processes
    (POMDPs) have been specifically designed to address this requirement, they present
    significant computational and statistical challenges in learning and planning.
    In this work, we introduce the Energy-based Predictive Representation (EPR) to
    provide a unified approach for designing practical reinforcement learning algorithms
    in both the MDP and POMDP settings. This framework enables coherent handling of
    learning, exploration, and planning tasks. The proposed framework leverages a
    powerful neural energy-based model to extract an adequate representation, allowing
    for efficient approximation of Q-functions. This representation facilitates the
    efficient computation of confidence, enabling the implementation of optimism or
    pessimism in planning when faced with uncertainty. Consequently, it effectively
    manages the trade-off between exploration and exploitation. Experimental investigations
    demonstrate that the proposed algorithm achieves state-of-the-art performance
    in both MDP and POMDP settings.
- title: Improving Code Style for Accurate Code Generation
  authors: Naman Jain and Tianjun Zhang and Wei-Lin Chiang and Joseph E Gonzalez and
    Koushik Sen and Ion Stoica
  venue: NeurIPS 2023 Workshop on Synthetic Data Generation with Generative AI
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:6yz0xqPARnAC
  abstract: Natural language to code generation is an important application area of
    LLMs and has received wide attention from the community.  The majority of relevant
    studies have exclusively concentrated on increasing the quantity and functional
    correctness of training sets while disregarding other stylistic elements of programs.
    More recently, data quality has garnered a lot of interest and multiple works
    have showcased its importance for improving performance. In this work, we investigate
    data quality for code and find that making the code more structured and readable
    leads to improved code generation performance of the system. We build a novel
    data-cleaning pipeline that uses these principles to transform existing programs
    by 1.) renaming variables, 2.) modularizing and decomposing complex code into
    smaller helper sub-functions, and 3.) inserting natural-language based planning
    annotations. We evaluate our approach on two challenging algorithmic code generation
    benchmarks and find that fine-tuning CodeLLaMa-7B on our transformed programs
    improves the performance by up to \textbf{30\%} compared to fine-tuning on the
    original dataset. Additionally, we demonstrate improved performance from using
    a smaller amount of higher-quality data, finding that a model fine-tuned on the
    entire original dataset is outperformed by a model trained on one-eighth of our
    cleaned dataset. Even in comparison to closed-source models, our models outperform
    the much larger AlphaCode models.
- title: 'Feature Stores: The Data Side of ML Pipelines'
  authors: Sarah Wooders and Peter Schafhalter and Joseph E Gonzalez
  venue: ''
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:7T2F9Uy0os0C
  abstract: ''
- title: 'Pyplover: A system for gpu-enabled serverless instances'
  authors: Ryan Yang and Nathan Pemberton and Jichan Chung and Randy H Katz and Joseph
    Gonzalez
  venue: ''
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:S16KYo8Pm5AC
  abstract: Serverless computing is a cloud-computing execution model that enables
    users to deploy applications in the form of a function, without the necessity
    of a server. The main advantage of the service is that it enables fine-grained
    control of pricing by allowing the user to pay for the actual amount of resources
    they use for the task, rather than using pre-purchased units of capacity. Another
    advantage is that the user does not have to worry about configuring the server,
    making it easy to deploy and scale up. The framework is also beneficial for the
    cloud service provider by allowing it to maximize utilization using load balancing,
    thanks to fine-grained resource allocation. Due to these advantages, Cloud providers
    (eg, AWS Lambda, Google Cloud Functions) and open source projects (eg, OpenLambda
    [4]) have developed an infrastructure for serverless computing, and many applications
    are built on top of these services (eg, PyWren [3]) as a way to utilize these
    low-cost and scalable compute resources.Currently, these publicly available services
    only provide CPU access. With the rise of Deep Learning applications, the necessity
    for large-scale computations utilizing other types of accelerators such as GPUs
    have emerged. Considering the advantages of serverless computing, it is natural
    to extend this framework for these applications.
- title: 'Inter-bmv: Interpolation with block motion vectors for fast semantic segmentation
    on video'
  authors: Samvit Jain and Joseph E Gonzalez
  venue: arXiv preprint arXiv:1810.04047
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:l7t_Zn2s7bgC
  abstract: Models optimized for accuracy on single images are often prohibitively
    slow to run on each frame in a video. Recent work exploits the use of optical
    flow to warp image features forward from select keyframes, as a means to conserve
    computation on video. This approach, however, achieves only limited speedup, even
    when optimized, due to the accuracy degradation introduced by repeated forward
    warping, and the inference cost of optical flow estimation. To address these problems,
    we propose a new scheme that propagates features using the block motion vectors
    (BMV) present in compressed video (e.g. H.264 codecs), instead of optical flow,
    and bi-directionally warps and fuses features from enclosing keyframes to capture
    scene context on each video frame. Our technique, interpolation-BMV, enables us
    to accurately estimate the features of intermediate frames, while keeping inference
    costs low. We evaluate our system on the CamVid and Cityscapes datasets, comparing
    to both a strong single-frame baseline and related work. We find that we are able
    to substantially accelerate segmentation on video, achieving near real-time frame
    rates (20+ frames per second) on large images (e.g. 960 x 720 pixels), while maintaining
    competitive accuracy. This represents an improvement of almost 6x over the single-frame
    baseline and 2.5x over the fastest prior work.
- title: Fast semantic segmentation on video using motion vectorbased feature interpolation
  authors: Samvit Jain and Joseph E Gonzalez
  venue: arXiv preprint arXiv:1803.07742
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ipzZ9siozwsC
  abstract: ''
- title: 'Tafe-net: Task-aware feature embeddings for efficient learning and inference'
  authors: Xin Wang and Fisher Yu and Ruth Wang and Trevor Darrell and Joseph E Gonzalez
  venue: arXiv preprint arXiv:1806.01531
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:M3NEmzRMIkIC
  abstract: Learning good feature embeddings for images often requires substantial
    training data. As a consequence, in settings where training data is limited (eg,
    few-shot and zeroshot learning), we are typically forced to use a general feature
    embedding across prediction tasks. Ideally, we would like to construct feature
    embeddings that are tuned for the given task and even input image. In this work,
    we propose Task-Aware Feature Embedding Networks (TAFE-Nets) to learn how to adapt
    the image representation to a new task in a meta learning fashion. Our network
    is composed of a meta learner and a prediction network, where the meta learner
    generates parameters for the feature layers in the prediction network based on
    a task input so that the feature embedding can be accurately adjusted for that
    task. We show that our TAFE-Net is highly effective in generalizing to new tasks
    or concepts and offers efficient prediction with low computational cost. We demonstrate
    the general applicability of TAFE-Net in several tasks including zeroshot/few-shot
    learning and dynamic efficient prediction. Our networks exceed or match the state-of-the-art
    on most tasks. In particular, our approach improves the prediction accuracy of
    unseen attribute-object pairs by 4 to 15 points on the challenging visual attributes
    composition task.
- title: 'IDK Cascades: Fast Deep Learning by Learning not to Overthink. CoRR abs/1706.00885
    (2017)'
  authors: Xin Wang and Yujia Luo and Daniel Crankshaw and Alexey Tumanov and Joseph
    E Gonzalez
  venue: arXiv preprint arXiv:1706.00885
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:tzM49s52ZIMC
  abstract: ''
- title: Efficient data reduction for large-scale genetic mapping
  authors: Veronika Strnadová-Neeley and Aydın Buluç and Jarrod Chapman and John R
    Gilbert and Joseph Gonzalez and Leonid Oliker
  venue: ''
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:BrmTIyaxlBUC
  abstract: We present a fast and accurate algorithm for reducing large-scale genetic
    marker data to a smaller, less noisy, and more complete set of bins, representing
    uniquely identifiable locations on a chromosome. Our experimental results on real
    and synthetic data show that our algorithm runs in near-linear time, allowing
    for the analysis of millions of markers. Our algorithm reduces the problem scale
    while preserving accuracy, making it feasible to use existing genetic mapping
    tools without resorting to complex, time-intensive preprocessing methods to filter
    or sample the original data set. Additionally, our approach also decreases the
    uncertainty in genotype calls, improving the quality of the data. Preliminary
    results demonstrate that existing methods for marker ordering designed for the
    small scale settings perform with equivalent accuracy when given our reduced bin
    set as input.
- title: 'Graphlab: A new framework for parallel machine learning. CoRR abs/1408.2041
    (2014)'
  authors: Yucheng Low and Joseph E Gonzalez and Aapo Kyrola and Danny Bickson and
    Carlos E Guestrin and Joseph Hellerstein
  venue: ''
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:KUbvn5osdkgC
  abstract: ''
- title: Field comparison of portable gas chromatographs with method TO-14
  authors: Richard E Berkley and Maribel Colon and J Gonzalez and I Droz and J Adams
  venue: ''
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:QD3KBmkZPeQC
  abstract: A field-deployable prototype fast gas chromatograph (FGC) and two commercially-available
    portable gas chromatographs (PGC) were evaluated by measuring organic vapors in
    ambient air at a field monitoring site in metropolitan San Juan, Puerto Rico.
    The data were compared with simultaneous grab samples which were collected in
    six-liter Summa-polished canisters and analyzed by method TO-14. Because of fluctuating
    retention times, the FGC produced no useable data. High humidity levels may have
    adversely affected its performance. Both commercially-available PGCs performed
    successfully, and data from twenty analyses were compared with the reference method.
- title: The graphx graph processing system
  authors: Daniel Crankshaw and Ankur Dave and Reynold S Xin and Joseph E Gonzalez
    and Michael J Franklin and Ion Stoica
  venue: UC Berkeley AMPLab
  year: ''
  citations: 3
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:LkGwnXOMwfcC
  abstract: The growing scale and importance of graph data has driven the development
    of specialized graph computation engines capable of inferring complex recursive
    properties of graph-structured data. However, these systems are unable to express
    many of the inherently data-parallel stages in a typical graph-analytics pipeline.
    As a consequence, existing graph analytics pipelines resort to multiple stages
    of data-parallel and graph-parallel systems composed through external storage
    systems. Instead, the GraphX abstraction unifies graph-parallel and data-parallel
    computation in a single system and is capable of succinctly expressing the entire
    graph analytics pipeline. However, implemented naively with relational operators
    it is impractically slow.We describe an implementation of the GraphX abstraction
    that encodes graphs as collections of edges and vertices along with simple auxiliary
    index structures, and represents graph computations as a sequence of relational
    joins and aggregations. We incorporate techniques such as incremental view maintenance
    and index scans in databases and adapt these techniques to exploit common characteristics
    of graph computation workloads. We evaluate these techniques individually as well
    as our overall GraphX implementation and find that it achieves performance comparable
    to contemporary graph-parallel systems in graph computation while retaining the
    expressiveness of contemporary dataparallel systems.
- title: 'Carff: Conditional auto-encoded radiance field for 3d scene forecasting'
  authors: Jiezhi Yang and Khushi Desai and Charles Packer and Harshil Bhatia and
    Nicholas Rhinehart and Rowan McAllister and Joseph E Gonzalez
  venue: European Conference on Computer Vision
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:jgBuDB5drN8C
  abstract: 'We propose CARFF: Conditional Auto-encoded Radiance Field for 3D Scene
    Forecasting, a method for predicting future 3D scenes given past observations.
    Our method maps 2D ego-centric images to a distribution over plausible 3D latent
    scene configurations and predicts the evolution of hypothesized scenes through
    time. Our latents condition a global Neural Radiance Field (NeRF) to represent
    a 3D scene model, enabling explainable predictions and straightforward downstream
    planning. This approach models the world as a POMDP and considers complex scenarios
    of uncertainty in environmental states and dynamics. Specifically, we employ a
    two-stage training of Pose-Conditional-VAE and NeRF to learn 3D representations,
    and auto-regressively predict latent scene representations utilizing a mixture
    density network. We demonstrate the utility of our method in scenarios using the
    CARLA driving simulator …'
- title: 'MoE-Lightning: High-Throughput MoE Inference on Memory-constrained GPUs'
  authors: Shiyi Cao and Shu Liu and Tyler Griggs and Peter Schafhalter and Xiaoxuan
    Liu and Ying Sheng and Joseph E Gonzalez and Matei Zaharia and Ion Stoica
  venue: arXiv preprint arXiv:2411.11217
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:HGTzPopzzJcC
  abstract: Efficient deployment of large language models, particularly Mixture of
    Experts (MoE), on resource-constrained platforms presents significant challenges,
    especially in terms of computational efficiency and memory utilization. The MoE
    architecture, renowned for its ability to increase model capacity without a proportional
    increase in inference cost, greatly reduces the token generation latency compared
    with dense models. However, the large model size makes MoE models inaccessible
    to individuals without high-end GPUs. In this paper, we propose a high-throughput
    MoE batch inference system, that significantly outperforms past work. MoE-Lightning
    introduces a novel CPU-GPU-I/O pipelining schedule, CGOPipe, with paged weights
    to achieve high resource utilization, and a performance model, HRM, based on a
    Hierarchical Roofline Model we introduce to help find policies with higher throughput
    than existing systems. MoE-Lightning can achieve up to 10.3x higher throughput
    than state-of-the-art offloading-enabled LLM inference systems for Mixtral 8x7B
    on a single T4 GPU (16GB). When the theoretical system throughput is bounded by
    the GPU memory, MoE-Lightning can reach the throughput upper bound with 2-3x less
    CPU memory, significantly increasing resource utilization. MoE-Lightning also
    supports efficient batch inference for much larger MoEs (e.g., Mixtral 8x22B and
    DBRX) on multiple low-cost GPUs (e.g., 2-4 T4).
- title: 'CLAIR-A: Leveraging Large Language Models to Judge Audio Captions'
  authors: Tsung-Han Wu and Joseph E Gonzalez and Trevor Darrell and David M Chan
  venue: arXiv preprint arXiv:2409.12962
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Ade32sEp0pkC
  abstract: The Automated Audio Captioning (AAC) task asks models to generate natural
    language descriptions of an audio input. Evaluating these machine-generated audio
    captions is a complex task that requires considering diverse factors, among them,
    auditory scene understanding, sound-object inference, temporal coherence, and
    the environmental context of the scene. While current methods focus on specific
    aspects, they often fail to provide an overall score that aligns well with human
    judgment. In this work, we propose CLAIR-A, a simple and flexible method that
    leverages the zero-shot capabilities of large language models (LLMs) to evaluate
    candidate audio captions by directly asking LLMs for a semantic distance score.
    In our evaluations, CLAIR-A better predicts human judgements of quality compared
    to traditional metrics, with a 5.8% relative accuracy improvement compared to
    the domain-specific FENSE metric and up to 11% over the best general-purpose measure
    on the Clotho-Eval dataset. Moreover, CLAIR-A offers more transparency by allowing
    the language model to explain the reasoning behind its scores, with these explanations
    rated up to 30% better by human evaluators than those provided by baseline methods.
    CLAIR-A is made publicly available at https://github.com/DavidMChan/clair-a.
- title: 'Stylus: Automatic Adapter Selection for Diffusion Models'
  authors: Michael Luo and Justin Wong and Brandon Trabucco and Yanping Huang and
    Joseph E Gonzalez and Zhifeng Chen and Ruslan Salakhutdinov and Ion Stoica
  venue: arXiv preprint arXiv:2404.18928
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:zCSUwVk65WsC
  abstract: Beyond scaling base models with more data or parameters, fine-tuned adapters
    provide an alternative way to generate high fidelity, custom images at reduced
    costs. As such, adapters have been widely adopted by open-source communities,
    accumulating a database of over 100K adapters-most of which are highly customized
    with insufficient descriptions. This paper explores the problem of matching the
    prompt to a set of relevant adapters, built on recent work that highlight the
    performance gains of composing adapters. We introduce Stylus, which efficiently
    selects and automatically composes task-specific adapters based on a prompt's
    keywords. Stylus outlines a three-stage approach that first summarizes adapters
    with improved descriptions and embeddings, retrieves relevant adapters, and then
    further assembles adapters based on prompts' keywords by checking how well they
    fit the prompt. To evaluate Stylus, we developed StylusDocs, a curated dataset
    featuring 75K adapters with pre-computed adapter embeddings. In our evaluation
    on popular Stable Diffusion checkpoints, Stylus achieves greater CLIP-FID Pareto
    efficiency and is twice as preferred, with humans and multimodal models as evaluators,
    over the base model. See stylus-diffusion.github.io for more.
- title: Ashera; Neural Guided Optimization Modulo Theory
  authors: Justin Wong and Pei-Wei Chen and Tianjun Zhang and Joseph Gonzalez and
    Yuandong Tian and Sanjit A Seshia
  venue: ''
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:u-coK7KVo8oC
  abstract: Applications of Satisfiability Modulo Theories (SMT) within 1 design automation
    and software/hardware verification often 2 require finding models whose quantitative
    cost objective is 3 guaranteed to be optimal. As an example, in worst-case ex-4
    ecution time analysis, it does not suffice to simply discover 5 a feasible execution
    trace; we are instead interested in prov-6 ing properties on the longest execution
    trace. Such problems 7 can be formulated as Optimization Modulo Theory (OMT),
    8 and solving them is much more challenging than both SMT 9 problems and unconstrained
    optimization. Current solutions 10 struggle to scale to problems of large size,
    because they 11 require experts to tune solvers and carefully craft problem 12
    encodings. This approach is not only problem-specific but 13 also requires manual
    effort. Recent progress in neural tech-14 niques have been successfully applied
    to Mixed Integer Lin-15 ear Programming (MILP) and certain instances of the Travel-16
    ing Salesman Problem (TSP). We make the case for learning-17 based solvers in
    OMT and present Ashera, a neural-guided 18 OMT solver. Ashera innovates on prior
    art by introducing 19 Logical Neighborhood Search and neural-based warm start-20
    ing. Additionally, we introduce new benchmarks for learning-21 based OMT techniques,
    targeted at real-world applications 22 including scheduling and multi-agent TSP.
    Ashera exhibits as 23 much as a 3x speedup and shows improved scaling compared
    24 to MILP approximation as used in industry and state-of-the-25 art OMT solvers.
    26
- title: Robust class parallelism-error resilient parallel inference with low communication
    cost
  authors: Yaoqing Yang and Jichan Chung and Guanhua Wang and Vipul Gupta and Adarsh
    Karnati and Kenan Jiang and Ion Stoica and Joseph Gonzalez and Kannan Ramchandran
  venue: 2020 54th Asilomar Conference on Signals, Systems, and Computers
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:K3LRdlH-MEoC
  abstract: Model parallelism is a standard paradigm to decouple a deep neural network
    (DNN) into sub-nets when the model is large. Recent advances in class parallelism
    significantly reduce the communication overhead of model parallelism to a single
    floating-point number per machine per iteration. However, traditional fault-tolerance
    schemes, when applied to class parallelism, require storing the entire model on
    the hard disk. Thus, these schemes are not suitable for soft and frequent system
    noise such as stragglers (temporarily slow worker machines). In this paper, we
    propose an erasure-coding based redundant computing technique called robust class
    parallelism to improve the error resilience of model parallelism. We show that
    by introducing slight overhead in the computation at each machine, we can obtain
    robustness to soft system noise while maintaining the low communication overhead
    in class parallelism. More …
- title: 'InferLine: ML prediction pipeline provisioning and management for tight
    latency objectives'
  authors: Daniel Crankshaw and Gur-Eyal Sela and Corey Zumar and Xiangxi Mo and Joseph
    E Gonzalez and Ion Stoica and Alexey Tumanov
  venue: arXiv preprint arXiv:1812.01776
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:WbkHhVStYXYC
  abstract: Serving ML prediction pipelines spanning multiple models and hardware
    accelerators is a key challenge in production machine learning. Optimally configuring
    these pipelines to meet tight end-to-end latency goals is complicated by the interaction
    between model batch size, the choice of hardware accelerator, and variation in
    the query arrival process. In this paper we introduce InferLine, a system which
    provisions and manages the individual stages of prediction pipelines to meet end-to-end
    tail latency constraints while minimizing cost. InferLine consists of a low-frequency
    combinatorial planner and a high-frequency auto-scaling tuner. The low-frequency
    planner leverages stage-wise profiling, discrete event simulation, and constrained
    combinatorial search to automatically select hardware type, replication, and batching
    parameters for each stage in the pipeline. The high-frequency tuner uses network
    calculus to auto-scale each stage to meet tail latency goals in response to changes
    in the query arrival process. We demonstrate that InferLine outperforms existing
    approaches by up to 7.6x in cost while achieving up to 34.5x lower latency SLO
    miss rate on realistic workloads and generalizes across state-of-the-art model
    serving frameworks.
- title: 'InferLine: ML Inference Pipeline Composition Framework. CoRR abs/1812.01776
    (2018)'
  authors: Daniel Crankshaw and Gur-Eyal Sela and Corey Zumar and Xiangxi Mo and Joseph
    E Gonzalez and Ion Stoica and Alexey Tumanov
  venue: arXiv preprint arXiv:1812.01776
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:hkOj_22Ku90C
  abstract: ''
- title: Task-Relevant embeddings for robust perception in reinforcement learning
  authors: Eric Liang and Roy Fox and Joseph E Gonzalez and Ion Stoica
  venue: ''
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Zph67rFs4hoC
  abstract: Reinforcement learning is unreasonably sample inefficient in many real-world
    visual domains, which require relatively simple control behaviors but pose challenging
    perception problems. We show that even simple visual noise added to common reinforcement
    learning benchmark environments can significantly degrade learning efficiency
    and break common approaches such as the use of autoencoders. We propose new methods
    for learning task-relevant state representations, and show that they can discover
    image embeddings that are significantly more effective when robust perception
    is required.
- title: Neural code completion
  authors: Xin Wang and Chang Liu and Richard Shin and Joseph E Gonzalez and Dawn
    Song
  venue: ''
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:WqliGbK-hY8C
  abstract: ''
- title: La presencia social en una experiencia docente universitaria en entornos
    virtuales 3D
  authors: Vanessa Esteve-González and J González and M Gisbert and J Cela-Ranilla
  venue: XVIII Congreso Internacional EDUTEC
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:artPoR2Yc-kC
  abstract: El avance tecnológico facilita la creación de escenarios de aprendizaje
    utilizando herramientas inmersivas y colaborativas para trabajar en red, como
    es el caso de los entornos virtuales multiusuario. La proyección social y emocional
    dentro del entorno virtual, entendida como presencia social, puede tener incidencia
    directa en el aprendizaje del alumno, por lo que nos planteamos su análisis en
    una experiencia que propone la inmersión de 52 alumnos de Pedagogía de la Universitat
    Rovira i Virgili en un entorno virtual multiusuario con la finalidad de mejorar
    la competencia de trabajo en equipo. Como conclusiones, destacamos que no se hayan
    encontrado muestras de presencia social negativa, sino evidencias positivas en
    expresión emocional, comunicación abierta y cohesión de grupo.
- title: Using Bayesian Optimization for Hardware Design
  authors: Orianna DeMasi and Joseph Gonzalez and Benjamin Recht and James Demmel
  venue: NIPS Workshop on Bayesian Optimization
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:nb7KW1ujOQ8C
  abstract: The problem of searching complex spaces with difficult to model or even
    blackbox functions arises in many domains. One such domain is hardware design
    in computer architecture. As hardware and software become more sophisticated,
    the importance and difficulty of finding an optimal design increases. We explore
    the use of Bayesian optimization on a problem of hardware design. Applying this
    approach on an example where traditional methods to optimize blackbox functions
    don’t apply, this method outperforms a naive approach in both number of samples
    and the quality of the solution found.
- title: Parallel learning and inference in probabilistic graphical models
  authors: Joseph Gonzalez
  venue: ''
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:QIV2ME_5wuYC
  abstract: Probabilistic graphical models are one of the most influential and widely
    used techniques in machine learning. Powered by exponential gains in processor
    technology, graphical models have been successfully applied to a wide range of
    increasingly large and complex real-world problems. However, recent developments
    in computer architecture, large-scale computing, and data-storage have shifted
    the focus away from sequential performance scaling and towards parallelism and
    large-scale distributed systems. Therefore, in order for graphical models to continue
    to benefit from developments in computer architecture and remain a viable option
    in the clouds and beyond, we must discover and exploit the parallelism of learning
    and inference in probabilistic graphical models.In this thesis we explore how
    to design efficient parallel algorithms for probabilistic graphical models by
    framing learning and inference as iterative adaptive asynchronous computation.
    We first present our work on efficient parallel algorithms for loopy belief propagation
    and Gibbs sampling. We then describe GraphLab, a new parallel abstraction for
    designing and implementing iterative adaptive asynchronous computation. Finally,
    we conclude with our proposed work on parallel parameter and structure learning
    in probabilistic graphical models.
- title: 'GraphLab: A new framework for parallel machine learning. CoRR abs/1006.4990
    (2010)'
  authors: Yucheng Low and Joseph E Gonzalez and Aapo Kyrola and Danny Bickson and
    Carlos E Guestrin and Joseph Hellerstein
  venue: ''
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:TIZ-Mc8IlK0C
  abstract: ''
- title: Influencia del macho en la actividad sexual durante el anoestro estacionario
    de la oveja marina.
  authors: J Gonzalez and J Alvarez and A Jimenez
  venue: ''
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:CdxZDUztZiMC
  abstract: "Influencia del macho en la actividad sexual durante el anoestro estacionario\
    \ de la oveja \nmarina. Food and Agriculture Organization of the United Nations\
    \ Discover About FAO News \nMultimedia Main topics Statistics Members Publications\
    \ English العربية Español Français \nРусский 中文 AGRIS - International System for\
    \ Agricultural Science and Technology About \nAGRIS Contribute Acceptable use\
    \ policy facebook linkedin twitter weibo Close Advanced \nSearch Influencia del\
    \ macho en la actividad sexual durante el anoestro estacionario de la oveja \n\
    marina. 1984 Gonzalez J. | Alvarez J. | Jimenez A. AGROVOC Keywords brebis breeds\
    \ ciclo \nestral comportamiento sexual comportement sexuel cycle oestral ewes\
    \ morueco oestrous cycle \noveja ovin ovinos race rams razas sexual behaviour\
    \ sheep Bibliographic information Other \nSubjects belier Language Spanish; Castilian\
    \ Note 13 references. Translated Title English. [Male …"
- title: 'Helen: Maliciously Secure Coopetitive Learning for Linear Models, 2019'
  authors: Wenting Zheng and Raluca Ada Popa and Joseph E Gonzalez and Ion Stoica
  venue: ''
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:b1wdh0AR-JQC
  abstract: ''
- title: 'Tune: A Research Platform for Distributed Model Selection and Training.
    arXiv 2018'
  authors: R Liaw and E Liang and R Nishihara and P Moritz and JE Gonzalez and I Stoica
  venue: URL http://arxiv. org/abs
  year: ''
  citations: 2
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:HE397vMXCloC
  abstract: ''
- title: 'VibeCheck: Discover and Quantify Qualitative Differences in Large Language
    Models'
  authors: Lisa Dunlap and Krishna Mandal and Trevor Darrell and Jacob Steinhardt
    and Joseph E Gonzalez
  venue: arXiv preprint arXiv:2410.12851
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:AXkvAH5U_nMC
  abstract: Large language models (LLMs) often exhibit subtle yet distinctive characteristics
    in their outputs that users intuitively recognize, but struggle to quantify. These
    "vibes" -- such as tone, formatting, or writing style -- influence user preferences,
    yet traditional evaluations focus primarily on the singular axis of correctness.
    We introduce VibeCheck, a system for automatically comparing a pair of LLMs by
    discovering identifying traits of a model (vibes) that are well-defined, differentiating,
    and user-aligned. VibeCheck iteratively discovers vibes from model outputs and
    then utilizes a panel of LLM judges to quantitatively measure the utility of each
    vibe. We validate that the vibes generated by VibeCheck align with those found
    in human discovery and run VibeCheck on pairwise preference data from real-world
    user conversations with Llama-3-70b vs GPT-4. VibeCheck reveals that Llama has
    a friendly, funny, and somewhat controversial vibe. These vibes predict model
    identity with 80% accuracy and human preference with 61% accuracy. Lastly, we
    run VibeCheck on a variety of models and tasks including summarization, math,
    and captioning to provide insight into differences in model behavior. VibeCheck
    discovers vibes like Command X prefers to add concrete intros and conclusions
    when summarizing in comparison to TNGL, Llama-405b often overexplains its thought
    process on math problems compared to GPT-4o, and GPT-4 prefers to focus on the
    mood and emotions of the scene when captioning compared to Gemini-1.5-Flash. Code
    can be found at https://github.com/lisadunlap/VibeCheck
- title: Post-training sparse attention with double sparsity
  authors: Shuo Yang and Ying Sheng and Joseph E Gonzalez and Ion Stoica and Lianmin
    Zheng
  venue: arXiv preprint arXiv:2408.07092
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:CB2v5VPnA5kC
  abstract: The inference process for large language models is slow and memory-intensive,
    with one of the most critical bottlenecks being excessive Key-Value (KV) cache
    accesses. This paper introduces "Double Sparsity," a novel post-training sparse
    attention technique designed to alleviate this bottleneck by reducing KV cache
    access. Double Sparsity combines token sparsity, which focuses on utilizing only
    the important tokens for computing self-attention, with channel sparsity, an approach
    that uses important feature channels for identifying important tokens. Our key
    insight is that the pattern of channel sparsity is relatively static, allowing
    us to use offline calibration to make it efficient at runtime, thereby enabling
    accurate and efficient identification of important tokens. Moreover, this method
    can be combined with offloading to achieve significant memory usage reduction.
    Experimental results demonstrate that Double Sparsity can achieve  token and channel
    sparsity with minimal impact on accuracy across various tasks, including wiki-2
    perplexity, key-value retrieval, and long context benchmarks with models including
    Llama-2-7B, Llama-2-70B, and Mixtral-8x7B. It brings up to a 14.1 acceleration
    in attention operations and a 1.9 improvement in end-to-end inference on GPUs.
    With offloading, it achieves a decoding speed acceleration of 16.3 compared to
    state-of-the-art solutions at a sequence length of 256K. Our code is publicly
    available at https://github.com/andy-yang-1/DoubleSparse.
- title: 'Visual Haystacks: A Vision-Centric Needle-In-A-Haystack Benchmark'
  authors: Tsung-Han Wu and Giscard Biamby and Jerome Quenum and Ritwik Gupta and
    Joseph E Gonzalez and Trevor Darrell and David M Chan
  venue: arXiv preprint arXiv:2407.13766
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Dem6FJhTUoYC
  abstract: Large Multimodal Models (LMMs) have made significant strides in visual
    question-answering for single images. Recent advancements like long-context LMMs
    have allowed them to ingest larger, or even multiple, images. However, the ability
    to process a large number of visual tokens does not guarantee effective retrieval
    and reasoning for multi-image question answering (MIQA), especially in real-world
    applications like photo album searches or satellite imagery analysis. In this
    work, we first assess the limitations of current benchmarks for long-context LMMs.
    We address these limitations by introducing a new vision-centric, long-context
    benchmark, "Visual Haystacks (VHs)". We comprehensively evaluate both open-source
    and proprietary models on VHs, and demonstrate that these models struggle when
    reasoning across potentially unrelated images, perform poorly on cross-image reasoning,
    as well as exhibit biases based on the placement of key information within the
    context window. Towards a solution, we introduce MIRAGE (Multi-Image Retrieval
    Augmented Generation), an open-source, lightweight visual-RAG framework that processes
    up to 10k images on a single 40G A100 GPU -- far surpassing the 1k-image limit
    of contemporary models. MIRAGE demonstrates up to 13% performance improvement
    over existing open-source LMMs on VHs, sets a new state-of-the-art on the RetVQA
    multi-image QA benchmark, and achieves competitive performance on single-image
    QA with state-of-the-art LMMs.
- title: Investigating the behavior of diffusion models for accelerating electronic
    structure calculations
  authors: Daniel Rothchild and Andrew S Rosen and Eric Taw and Connie Robinson and
    Joseph E Gonzalez and Aditi S Krishnapriyan
  venue: Chemical Science
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:BJbdYPG6LGMC
  abstract: We present an investigation of diffusion models for molecular generation,
    with the aim of better understanding how their predictions compare to the results
    of physics-based calculations. The investigation into these models is driven by
    their potential to significantly accelerate electronic structure calculations
    using machine learning, without requiring expensive first-principles datasets
    for training interatomic potentials. We find that the inference process of a popular
    diffusion model for de novo molecular generation is divided into an exploration
    phase, where the model chooses the atomic species, and a relaxation phase, where
    it adjusts the atomic coordinates to find a low-energy geometry. As training proceeds,
    we show that the model initially learns about the first-order structure of the
    potential energy surface, and then later learns about higher-order structure.
    We also find that the relaxation phase of the diffusion …
- title: 'RALF: Accuracy-Aware Scheduling for Feature Store Maintenance'
  authors: Sarah Wooders and Xiangxi Mo and Amit Narang and Kevin Lin and Ion Stoica
    and Joseph M Hellerstein and Natacha Crooks and Joseph E Gonzalez
  venue: Proceedings of the VLDB Endowment
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:uDGL6kOW6j0C
  abstract: 'Feature stores (also sometimes referred to as embedding stores) are becoming
    ubiquitous in model serving systems: downstream applications query these stores
    for auxiliary inputs at inference-time. Stored features are derived by featurizing
    rapidly changing base data sources. Featurization can be costly prohibitively
    expensive to trigger on every data update, particularly for features that are
    vector embeddings computed by a model. Yet, existing systems naively apply a one-size-fits-all
    policy as to when/how to update these features, and do not consider query access
    patterns or impacts on prediction accuracy. This paper introduces RALF, which
    orchestrates feature updates by leveraging downstream error feedback to minimize
    feature store regret, a metric for how much featurization degrades downstream
    accuracy. We evaluate with representative feature store workloads, anomaly detection
    and recommendation …'
- title: Multiversion Hindsight Logging for Continuous Training
  authors: Rolando Garcia and Anusha Dandamudi and Gabriel Matute and Lehan Wan and
    Joseph Gonzalez and Joseph M Hellerstein and Koushik Sen
  venue: arXiv preprint arXiv:2310.07898
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:gVv57TyPmFsC
  abstract: Production Machine Learning involves hosting multiple versions of models
    over time, often with many model versions running at once. When model performance
    does not meet expectations, Machine Learning Engineers (MLEs) debug issues by
    exploring and analyzing numerous prior versions of code and training data to identify
    root causes and mitigate problems. Traditional debugging and logging tools often
    fall short in managing this experimental, multi-version context. To address the
    challenges in this domain, novel approaches are required for logging and log data
    management. FlorDB introduces Multiversion Hindsight Logging, which allows engineers
    to use the most recent version's logging statements to explore past versions,
    even when older versions logged different data. Log statement propagation enables
    consistent injection of logging statements into past code versions, regardless
    of changes to the codebase. Once log statements are propagated across code versions,
    the remaining challenges in Multiversion Hindsight Logging relate to efficiently
    replaying the new log statements based on checkpoints from previous runs. Finally,
    a coherent user experience is required to help MLEs debug across all versions
    of code and data. To this end, FlorDB presents a unified relational model for
    efficient handling of historical queries, offering a comprehensive view of the
    log history to simplify the exploration of past code iterations. In sum, FlorDB
    provides a robust tool tailored to the specific needs of MLEs, significantly enhancing
    their ability to navigate the intricate landscape of ML experimentation.
- title: The Story of GraphLab-From Scaling Machine Learning to Shaping Graph Systems
    Research (VLDB 2023 Test-of-Time Award Talk)
  authors: Joseph E Gonzalez and Yucheng Low
  venue: Proceedings of the VLDB Endowment
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Aul-kAQHnToC
  abstract: The GraphLab project spanned almost a decade and had profound academic
    and industrial impact on large-scale machine learning and graph processing systems.
    There were numerous papers written describing the innovations in GraphLab including
    the original vertex-centric [8] and edge-centric [3] programming abstractions,
    high-performance asynchronous execution engines [9], out-of-core graph computation
    [6], tabular graph-systems [4], and even new statistical inference algorithms
    [2] enabled by the GraphLab project. This work became the basis of multiple PhD
    theses [1, 5, 7]. The GraphLab open-source project had broad academic and industrial
    adoption and ultimately lead to the launch of Turi.In this talk, we tell the story
    of GraphLab, how it began and the key ideas behind it. We will focus on the approach
    to achieving scalable asynchronous systems in machine learning. During our talk,
    we will explore …
- title: Knowledge-Guided Self-Supervised Vision Transformers for Medical Imaging
  authors: Kevin Miao and Akash Gokul and Suzanne Petryk and Raghav Singh and Kurt
    Keutzer and Joseph Gonzalez and Trevor Darrell
  venue: ''
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:OTTXONDVkokC
  abstract: Recent trends in self-supervised representation learning have focused
    on removing inductive biases from the training process. However, inductive biases
    can be useful in certain settings, such as medical imaging, where domain expertise
    can help define a prior over semantic structure. We present Medical DINO (MeDINO),
    a method that ta es advantage of consistent spatial and semantic structure in
    unlabeled medical imaging datasets to guide vision transformer attention. MeDINO
    operates by regularizing attention mas s from separate transformer heads to follow
    various priors over semantic regions. These priors can be derived from data statistics
    or are provided via a single labeled sample from a domain expert. Using chest
    X-ray radiographs as a primary case study, we show that the resulting attention
    mas s are more interpretable than those resulting from domain-agnostic pretraining,
    producing a 58.7 mAP improvement for lung and heart segmentation following the
    self-supervised pretraining. Additionally, our method yields a 2.2 mAUC improvement
    compared to domain-agnostic pretraining when transferring the pretrained model
    to a downstream chest disease classification tas.
- title: 'Fogros: An adaptive framework for automating fog robotics deployment'
  authors: Yafei Liang and Nikhil Jha and Jeffrey Ichnowski and Michael Danielczuk
    and Joseph Gonzalez and John Kubiatowicz and Ken Goldberg
  venue: arXiv preprint arXiv:2108.11355
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:5qfkUJPXOUwC
  abstract: 'As many robot automation applications increasingly rely on multi-core
    processing or deep-learning models, cloud computing is becoming an attractive
    and economically viable resource for systems that do not contain high computing
    power onboard. Despite its immense computing capacity, it is often underused by
    the robotics and automation community due to lack of expertise in cloud computing
    and cloud-based infrastructure. Fog Robotics balances computing and data between
    cloud edge devices. We propose a software framework, FogROS, as an extension of
    the Robot Operating System (ROS), the de-facto standard for creating robot automation
    applications and components. It allows researchers to deploy components of their
    software to the cloud with minimal effort, and correspondingly gain access to
    additional computing cores, GPUs, FPGAs, and TPUs, as well as predeployed software
    made available by other researchers. FogROS allows a researcher to specify which
    components of their software will be deployed to the cloud and to what type of
    computing hardware. We evaluate FogROS on 3 examples: (1) simultaneous localization
    and mapping (ORB-SLAM2), (2) Dexterity Network (Dex-Net) GPU-based grasp planning,
    and (3) multi-core motion planning using a 96-core cloud-based server. In all
    three examples, a component is deployed to the cloud and accelerated with a small
    change in system launch configuration, while incurring additional latency of 1.2
    s, 0.6 s, and 0.5 s due to network communication, the computation speed is improved
    by 2.6x, 6.0x and 34.2x, respectively. Code, videos, and supplementary material
    can be …'
- title: Robotic Untangling and Disentangling of Cables via Learned Manipulation and
    Recovery Strategies
  authors: Priya Sundaresan and Ken Goldberg and Joseph Gonzalez
  venue: ''
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:FPJr55Dyh1AC
  abstract: Having to detangle power cords, wiring, tubing, suturing thread, and shoelaces
    is an all too common occurrence in homes, offices, concert stages, warehouses,
    operating rooms, and more [25, 38, 41, 30]. Rope disentangling can also be critical
    procedure in life-saving systems for search-and-rescue operations [26, 17]. Thus,
    untangling and disentangling 1D deformable objects, which we broadly refer to
    as cables, can greatly benefit from automation by mobile manipulators.To realize
    this, robots will need to tackle knots with increasing complexity and cables in
    greater quantities, which is the central focus of this thesis. Autonomous untangling/disentangling
    would be fundamentally impactful as a stand-alone task but can also serve as a
    prerequisite for any downstream cable arrangement task such as knot-tying or coiling.
    In Chapter 2, we review relevant literature for the cable manipulation tasks considered
    in this thesis. There is a large body of related work that focuses on developing
    analytical controllers for deformable object manipulation. Such methods often
    require many hand-tuned specifications, significant system engineering, and rely
    on classical methods for state estimation via visual feature extraction or segmentation.
    These methods tend to suffer when applied to objects exhibiting self-occlusion,
    which is characteristic of tightly intertwined cables or complex knots. Meanwhile
    end-to-end methods have come a long way in developing generalizable, task-agnostic
    robot learning frameworks. In doing so, they tend to not leverage task/object
    geometry which can critically inform long-horizon planning for complex tasks like
    cable manipulation. In …
- title: Multi-Task Learning Architectures and Applications
  authors: Andy Yan and Xin Wang and Yanlai Yang and Roy Fox and Xiaolong Wang and
    Joseph Gonzalez
  venue: ''
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:HbR8gkJAVGIC
  abstract: Multi-task learning fundamentally involves utilizing multiple tasks to
    assist with generalization. In the biological context, humans utilize multi-task
    learning in day to day tasks. For instance, when learning to play a song on different
    instruments such as a guitar and a piano, aspects of the song such as the melody
    can be generalized between the instruments. Therefore, playing the song on the
    guitar can assist with playing the song on the piano. The same intuition may be
    applied to deep learning. Given two tasks that are similar to each other, co-training
    the two tasks on the same neural network can help the network to generalize learning
    of certain features.Given a single task, generally reasonable performance can
    be obtained by optimizing for that task by collecting data and training a network
    to optimize for it. However, limitations may arise as data collection may be costly.
    In addition, collecting enough data for a …
- title: Task-Aware Deep Sampling for Feature Generation.
  authors: Xin Wang and Fisher Yu and Trevor Darrell and Joseph E Gonzalez
  venue: CoRR abs/1906.04854
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:bEWYMUwI8FkC
  abstract: ''
- title: Neural Networks for irregularly observed continuous-time Stochastic Processes
  authors: Francois W Belletti and Alexander Ku and Joseph E Gonzalez
  venue: ''
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:UxriW0iASnsC
  abstract: 'Designing neural networks for continuous-time stochastic processes is
    challenging, especially when observations are made irregularly. In this article,
    we analyze neural networks from a frame theoretic perspective to identify the
    sufficient conditions that enable smoothly recoverable representations of signals
    in L^2(R). Moreover, we show that, under certain assumptions, these properties
    hold even when signals are irregularly observed. As we converge to the family
    of (convolutional) neural networks that satisfy these conditions, we show that
    we can optimize our convolution filters while constraining them so that they effectively
    compute a Discrete Wavelet Transform. Such a neural network can efficiently divide
    the time-axis of a signal into orthogonal sub-spaces of different temporal scale
    and localization. We evaluate the resulting neural network on an assortment of
    synthetic and real-world tasks: parsimonious auto-encoding, video classification,
    and financial forecasting.'
- title: Batch Methods for Incremental Learning
  authors: Noah Golmant and Evan R Sparks and Joseph Gonzalez
  venue: ''
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:fPk4N6BV_jEC
  abstract: Data is increasingly collected and processed in an online fashion, but
    existing large-scale machine learning systems are batch-oriented. Existing stream-oriented
    ML algorithms are often limited in application scope or present significantly
    stronger assumptions to the learning model. We present two techniques to automatically
    and generically adapt batch-oriented algorithms to the incremental setting, extend
    an existing large-scale system to support the algorithms, and demonstrate the
    effectiveness of these techniques on several classification workloads.
- title: Beating State-of-the-art By-10000%.
  authors: Reynold Xin and UC AMPLab and Joseph Gonzalez and Josh Rosen and Matei
    Zaharia and Michael Franklin and Scott Shenker and Ion Stoica
  venue: CIDR
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:MXK_kJrjxJIC
  abstract: "Reynold Xin, AMPLab, UC Berkeley with help from Joseph Gonzalez, Josh\
    \ Rosen, Matei \nZaharia, Michael Franklin, Scott Shenker, Ion Page 1 Beating\
    \ State-of-the-art By -10000% \nReynold Xin, AMPLab, UC Berkeley with help from\
    \ Joseph Gonzalez, Josh Rosen, Matei \nZaharia, Michael Franklin, Scott Shenker,\
    \ Ion Stoica Page 2 Beating State-of-the-art By -10000% \nNOT A TYPO Reynold Xin,\
    \ AMPLab, UC Berkeley with help from Joseph Gonzalez, Josh Rosen, \nMatei Zaharia,\
    \ Michael Franklin, Scott Shenker, Ion Stoica Page 3 MapReduce deterministic,\
    \ \nidempotent tasks fault-tolerance elasticity resource sharing Page 4 “The bar\
    \ for open source \nsoftware is at historical low.” Page 5 “The bar for open source\
    \ software is at historical low.” \nie “This is the right time to do grad school.”\
    \ Page 6 iterative machine learning OLAP strong \ntemporal locality Page 7 Does\
    \ in-memory computation help in petabyte-scale warehouses? …"
- title: Communication skills assessment in the clinical interview of physiotherapy
    with simulated patient and video
  authors: S Montull and JM Cela and R Descarrega and I Miralles and S Monterde and
    I Salvat and J González
  venue: EDULEARN11 Proceedings
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:_axFR9aDTf0C
  abstract: ''
- title: Sexual activity of Merino ewes during lactation and its interaction with
    seasonal anoestrus.
  authors: J González and J Alvarez and V Domenech
  venue: ''
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:LPtt_HFRSbwC
  abstract: 30 Merino ewes lambing in Feb. and 32 in Dec. were studied. Each group
    was divided into subgroups with lambs weaned at 45 and 75 days. The ovarian activity
    of the ewes lambing in Feb. was found to be at a low level during the spring,
    and only slightly influenced by different weaning times. In those lambing in Dec.,
    ovarian activity occurred in 59% of ewes in the 1st 45 days, with 12% showing
    an oestrous cycle immediately after parturition. There was a marked increase in
    ovarian activity after weaning, particularly weaning at 45 days.
- title: 'Persistent adaptive radix trees: Efficient fine-grained updates to immutable
    data'
  authors: Ankur Dave and Joseph E Gonzalez and Michael J Franklin and Ion Stoica
  venue: ''
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:HoB7MX3m0LUC
  abstract: Immutability dramatically simplifies fault tolerance, straggler mitigation,
    and data consistency and is an essential part of widely-used distributed batch
    analytics systems including MapReduce, Dryad, and Spark. However, these systems
    are increasingly being used for new applications like stream processing and incremental
    analytics, which often demand fine-grained updates and are seemingly at odds with
    the essential assumption of immutability. In this paper we introduce the persistent
    adaptive radix tree (PART), a map data structure designed for in-memory analytics
    that supports efficient fine-grained updates without compromising immutability.
    PART (1) allows applications to trade off latency for throughput using batching,(2)
    supports efficient scans using an optimized memory layout and periodic compaction,
    and (3) achieves efficient fault recovery using incremental checkpoints.PART outperforms
    existing persistent data structures in lookup, update, scan, and memory usage
    microbenchmarks. Additionally, we evaluate PART in a variety of distributed applications
    and show that it improves upon the performance of state-of-the-art immutable and
    even mutable systems by anywhere from 50x to 4 orders of magnitude.
- title: Distributed GraphLab
  authors: Y Low and J Gonzalez and A Kyrola and D Bickson and C Guestrin and J Hellerstein
  venue: A Framework for Machine Learning and Data Mining in the Cloud,” VLDB
  year: ''
  citations: 1
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:hMod-77fHWUC
  abstract: "Distributed GraphLab Page 1 Distributed GraphLab A Framework for Machine\
    \ Learning and \nData Mining in the Cloud By Maciej Biskupiak for R212 Y. Low,\
    \ J. Gonzalez, A. Kyrola, D. \nBickson, C. Guestrin, J. Hellerstein Page 2 Motivation\
    \ Abstractions of parallel computation \nare necessary. Current Models such as\
    \ MapReduce, Dryad or Pregel are too limiting or \ninefficient for our purposes.\
    \ Page 3 GraphLab Abstraction GraphLab is: ● Asynchronous:parameter \nvalues are\
    \ not necessarily updated at the same time ● Dynamic:Parameters are not updated\
    \ \nequally often ● Serialisable: All parallel executions have an equivalent serial\
    \ execution (no \ndata races) It was originally developed for the multicore in\
    \ memory setting. Page 4 GraphLab \nAbstraction GraphLab consists of three main\
    \ parts: ● The Data Graph ● Update Function ● \nSync Function Page 5 Data Graph\
    \ V1 V2 V4 V6 V5 V3 ● Computation can be expressed as …"
- title: 'HashAttention: Semantic Sparsity for Faster Inference'
  authors: Aditya Desai and Shuo Yang and Alejandro Cuadron and Ana Klimovic and Matei
    Zaharia and Joseph E Gonzalez and Ion Stoica
  venue: arXiv preprint arXiv:2412.14468
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ce2CqMG-AY4C
  abstract: Utilizing longer contexts is increasingly essential to power better AI
    systems. However, the cost of attending to long contexts is high due to the involved
    softmax computation. While the scaled dot-product attention (SDPA) exhibits token
    sparsity, with only a few pivotal tokens significantly contributing to attention,
    leveraging this sparsity effectively remains an open challenge. Previous methods
    either suffer from model degradation or require considerable additional resources.
    We propose HashAttention --a principled approach casting pivotal token identification
    as a recommendation problem. Given a query, HashAttention encodes keys and queries
    in Hamming space capturing the required semantic similarity using learned mapping
    functions. HashAttention efficiently identifies pivotal tokens for a given query
    in this Hamming space using bitwise operations, and only these pivotal tokens
    are used for attention computation, significantly improving overall attention
    efficiency. HashAttention can reduce the number of tokens used by a factor of  for
    the Llama-3.1-8B model with LongBench, keeping average quality loss within 0.6
    points, while using only 32 bits per token auxiliary memory. At  sparsity, HashAttention
    is  faster than LightLLM and  faster than gpt-fast on Nvidia-L4 GPU.
- title: 'VisionArena: 230K Real World User-VLM Conversations with Preference Labels'
  authors: Christopher Chou and Lisa Dunlap and Koki Mashita and Krishna Mandal and
    Trevor Darrell and Ion Stoica and Joseph E Gonzalez and Wei-Lin Chiang
  venue: arXiv preprint arXiv:2412.08687
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:sszUF3NjhM4C
  abstract: 'With the growing adoption and capabilities of vision-language models
    (VLMs) comes the need for benchmarks that capture authentic user-VLM interactions.
    In response, we create VisionArena, a dataset of 230K real-world conversations
    between users and VLMs. Collected from Chatbot Arena - an open-source platform
    where users interact with VLMs and submit preference votes - VisionArena spans
    73K unique users, 45 VLMs, and 138 languages. Our dataset contains three subsets:
    VisionArena-Chat, 200k single and multi-turn conversations between a user and
    a VLM; VisionArena-Battle, 30K conversations comparing two anonymous VLMs with
    user preference votes; and VisionArena-Bench, an automatic benchmark of 500 diverse
    user prompts that efficiently approximate the live Chatbot Arena model rankings.
    Additionally, we highlight the types of question asked by users, the influence
    of response style on preference, and areas where models often fail. We find open-ended
    tasks like captioning and humor are highly style-dependent, and current VLMs struggle
    with spatial reasoning and planning tasks. Lastly, we show finetuning the same
    base model on VisionArena-Chat outperforms Llava-Instruct-158K, with a 17-point
    gain on MMMU and a 46-point gain on the WildVision benchmark. Dataset at https://huggingface.co/lmarena-ai'
- title: 'Specifications: The missing link to making the development of LLM systems
    an engineering discipline'
  authors: Ion Stoica and Matei Zaharia and Joseph Gonzalez and Ken Goldberg and Hao
    Zhang and Anastasios Angelopoulos and Shishir G Patil and Lingjiao Chen and Wei-Lin
    Chiang and Jared Q Davis
  venue: arXiv preprint arXiv:2412.05299
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:PyEswDtIyv0C
  abstract: 'Despite the significant strides made by generative AI in just a few short
    years, its future progress is constrained by the challenge of building modular
    and robust systems. This capability has been a cornerstone of past technological
    revolutions, which relied on combining components to create increasingly sophisticated
    and reliable systems. Cars, airplanes, computers, and software consist of components-such
    as engines, wheels, CPUs, and libraries-that can be assembled, debugged, and replaced.
    A key tool for building such reliable and modular systems is specification: the
    precise description of the expected behavior, inputs, and outputs of each component.
    However, the generality of LLMs and the inherent ambiguity of natural language
    make defining specifications for LLM-based components (e.g., agents) both a challenging
    and urgent problem. In this paper, we discuss the progress the field has made
    so far-through advances like structured outputs, process supervision, and test-time
    compute-and outline several future directions for research to enable the development
    of modular and reliable LLM-based systems through improved specifications.'
- title: 'Managing Bandwidth: The Key to Cloud-Assisted Autonomous Driving'
  authors: Alexander Krentsel and Peter Schafhalter and Joseph E Gonzalez and Sylvia
    Ratnasamy and Scott Shenker and Ion Stoica
  venue: arXiv preprint arXiv:2410.16227
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:jFemdcug13IC
  abstract: Prevailing wisdom asserts that one cannot rely on the cloud for critical
    real-time control systems like self-driving cars. We argue that we can, and must.
    Following the trends of increasing model sizes, improvements in hardware, and
    evolving mobile networks, we identify an opportunity to offload parts of time-sensitive
    and latency-critical compute to the cloud. Doing so requires carefully allocating
    bandwidth to meet strict latency SLOs, while maximizing benefit to the car.
- title: How to Evaluate Reward Models for RLHF
  authors: Evan Frick and Tianle Li and Connor Chen and Wei-Lin Chiang and Anastasios
    N Angelopoulos and Jiantao Jiao and Banghua Zhu and Joseph E Gonzalez and Ion
    Stoica
  venue: arXiv preprint arXiv:2410.14872
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:6_hjMsCP8ZoC
  abstract: We introduce a new benchmark for reward models that quantifies their ability
    to produce strong language models through RLHF (Reinforcement Learning from Human
    Feedback). The gold-standard approach is to run a full RLHF training pipeline
    and directly probe downstream LLM performance. However, this process is prohibitively
    expensive. To address this, we build a predictive model of downstream LLM performance
    by evaluating the reward model on proxy tasks. These proxy tasks consist of a
    large-scale human preference and a verifiable correctness preference dataset,
    in which we measure 12 metrics across 12 domains. To investigate which reward
    model metrics are most correlated to gold-standard RLHF outcomes, we launch an
    end-to-end RLHF experiment on a large-scale crowdsourced human preference platform
    to view real reward model downstream performance as ground truth. Ultimately,
    we compile our data and findings into Preference Proxy Evaluations (PPE), the
    first reward model benchmark explicitly linked to post-RLHF real-world human preference
    performance, which we open-source for public use and further development. Our
    code and evaluations can be found at https://github.com/lmarena/PPE .
- title: 'SuperCorrect: Supervising and Correcting Language Models with Error-Driven
    Insights'
  authors: Ling Yang and Zhaochen Yu and Tianjun Zhang and Minkai Xu and Joseph E
    Gonzalez and Bin Cui and Shuicheng Yan
  venue: arXiv preprint arXiv:2410.09008
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:NDuN12AVoxsC
  abstract: Large language models (LLMs) like GPT-4, PaLM, and LLaMA have shown significant
    improvements in various reasoning tasks. However, smaller models such as Llama-3-8B
    and DeepSeekMath-Base still struggle with complex mathematical reasoning because
    they fail to effectively identify and correct reasoning errors. Recent reflection-based
    methods aim to address these issues by enabling self-reflection and self-correction,
    but they still face challenges in independently detecting errors in their reasoning
    steps. To overcome these limitations, we propose SuperCorrect, a novel two-stage
    framework that uses a large teacher model to supervise and correct both the reasoning
    and reflection processes of a smaller student model. In the first stage, we extract
    hierarchical high-level and detailed thought templates from the teacher model
    to guide the student model in eliciting more fine-grained reasoning thoughts.
    In the second stage, we introduce cross-model collaborative direct preference
    optimization (DPO) to enhance the self-correction abilities of the student model
    by following the teacher's correction traces during training. This cross-model
    DPO approach teaches the student model to effectively locate and resolve erroneous
    thoughts with error-driven insights from the teacher model, breaking the bottleneck
    of its thoughts and acquiring new skills and knowledge to tackle challenging problems.
    Extensive experiments consistently demonstrate our superiority over previous methods.
    Notably, our SuperCorrect-7B model significantly surpasses powerful DeepSeekMath-7B
    by 7.8%/5.3% and Qwen2.5-Math-7B by 15.1%/6.3% on MATH/GSM8K …
- title: 'SimpleStrat: Diversifying Language Model Generation with Stratification'
  authors: Justin Wong and Yury Orlovskiy and Michael Luo and Sanjit A Seshia and
    Joseph E Gonzalez
  venue: arXiv preprint arXiv:2410.09038
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:q-HalDI95KYC
  abstract: Generating diverse responses from large language models (LLMs) is crucial
    for applications such as planning/search and synthetic data generation, where
    diversity provides distinct answers across generations. Prior approaches rely
    on increasing temperature to increase diversity. However, contrary to popular
    belief, we show not only does this approach produce lower quality individual generations
    as temperature increases, but it depends on model's next-token probabilities being
    similar to the true distribution of answers. We propose SimpleStrat, an alternative
    approach that uses the language model itself to partition the space into strata.
    At inference, a random stratum is selected and a sample drawn from within the
    strata. To measure diversity, we introduce CoverageQA, a dataset of underspecified
    questions with multiple equally plausible answers, and assess diversity by measuring
    KL Divergence between the output distribution and uniform distribution over valid
    ground truth answers. As computing probability per response/solution for proprietary
    models is infeasible, we measure recall on ground truth solutions. Our evaluation
    show using SimpleStrat achieves higher recall by 0.05 compared to GPT-4o and 0.36
    average reduction in KL Divergence compared to Llama 3.
- title: 'Visual Haystacks: Answering Harder Questions About Sets of Images'
  authors: Tsung-Han Wu and Giscard Biamby and Jerome Quenum and Ritwik Gupta and
    Joseph E Gonzalez and Trevor Darrell and David M Chan
  venue: arXiv e-prints
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:j7_hQOaDUrUC
  abstract: 'Recent advancements in Large Multimodal Models (LMMs) have made significant
    progress in the field of single-image visual question answering. However, these
    models face substantial challenges when tasked with queries that span extensive
    collections of images, similar to real-world scenarios like searching through
    large photo albums, finding specific information across the internet, or monitoring
    environmental changes through satellite imagery. This paper explores the task
    of Multi-Image Visual Question Answering (MIQA): given a large set of images and
    a natural language query, the task is to generate a relevant and grounded response.
    We propose a new public benchmark, dubbed" Visual Haystacks (VHs)," specifically
    designed to evaluate LMMs'' capabilities in visual retrieval and reasoning over
    sets of unrelated images, where we perform comprehensive evaluations demonstrating
    that even robust closed …'
- title: Synthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource
    Programming Languages
  authors: Federico Mora and Justin Wong and Haley Lepe and Sahil Bhatia and Karim
    Elmaaroufi and George Varghese and Joseph E Gonzalez and Elizabeth Polgreen and
    Sanjit A Seshia
  venue: arXiv preprint arXiv:2406.03636
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:U4n9YNQMCAIC
  abstract: Recent advances in large language models (LLMs) for code applications
    have demonstrated remarkable zero-shot fluency and instruction following on challenging
    code related tasks ranging from test case generation to self-repair. Unsurprisingly,
    however, models struggle to compose syntactically valid programs in programming
    languages unrepresented in pre-training, referred to as very low-resource Programming
    Languages (VLPLs). VLPLs appear in crucial settings, including domain-specific
    languages for internal tools and tool-chains for legacy languages. Inspired by
    an HCI technique called natural program elicitation, we propose designing an intermediate
    language that LLMs ``naturally'' know how to use and which can be automatically
    compiled to a target VLPL. When LLMs generate code that lies outside of this intermediate
    language, we use compiler techniques to repair the code into programs in the intermediate
    language. Overall, we introduce \emph{synthetic programming elicitation and compilation}
    (SPEAC), an approach that enables LLMs to generate syntactically valid code even
    for VLPLs. We empirically evaluate the performance of SPEAC in a case study and
    find that, compared to existing retrieval and fine-tuning baselines, SPEAC produces
    syntactically correct programs significantly more frequently without sacrificing
    semantic correctness.
- title: Improve Model Inference Cost with Image Gridding
  authors: Shreyas Krishnaswamy and Lisa Dunlap and Lingjiao Chen and Matei Zaharia
    and James Zou and Joseph E Gonzalez
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:BzfGm06jWhQC
  abstract: The success of AI has spurred the rise of Machine Learning as a Service
    (MLaaS), where companies develop, maintain, and serve general-purpose models such
    as object detectors and image classifiers for users that pay a fixed rate per
    inference. As more organizations rely on AI, the MLaaS market is set to expand,
    necessitating cost optimization for these services. We explore how a simple yet
    effective method of increasing model efficiency, aggregating multiple images into
    a grid before inference, can significantly reduce the required number of inferences
    for processing a batch of images with varying drops in accuracy. Experiments on
    open-source and commercial models show that image gridding reduces inferences
    by 50%, while maintaining low impact on mean average precision (mAP) over the
    Pascal VOC object detection task.
- title: 'Reliable Visual Question Answering: Abstain Rather Than Answer Incorrectly'
  authors: Vedaad Shakib and Spencer Whitehead and Suzanne Petryk and Joseph Gonzalez
    and Trevor Darrell and Anna Rohrbach and Marcus Rohrbach
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:VaXvl8Fpj5cC
  abstract: Machine learning has advanced dramatically, narrowing the accuracy gap
    to humans in multimodal tasks like visual question answering (VQA). However, while
    humans can say “I don’t know” when they are uncertain (ie, abstain from answering
    a question), such ability has been largely neglected in multimodal research, despite
    the importance of this problem to the usage of VQA in real settings. In this work,
    we promote a problem formulation for reliable VQA, where we prefer abstention
    over providing an incorrect answer. We first enable abstention capabilities for
    several VQA models, and analyze both their coverage, the portion of questions
    answered, and risk, the error on that portion. For that we explore several abstention
    approaches. We find that although the best performing models achieve over 71%
    accuracy on the VQA v2 dataset, introducing the option to abstain by directly
    using a model’s softmax scores limits them to answering less than 8% of the questions
    to achieve a low risk of error (ie, 1%). This motivates us to utilize a multimodal
    selection function to directly estimate the correctness of the predicted answers,
    which we show can triple the coverage from, for example, 5.0% to 16.7% at 1% risk.
    We also explore probabilistic calibration of VQA models, which improves coverage
    but less so than a multimodel selection function. While it is important to analyze
    both coverage and risk, these metrics have a trade-off which makes comparing VQA
    models challenging. To address this, we also propose an Effective Reliability
    metric for VQA that places a larger cost on incorrect answers compared to abstentions.
    This new problem formulation, metric …
- title: 'Neurotoxin: Durable Backdoors in Federated Learning'
  authors: Linyue Song and Zhengming Zhang and Ashwinee Panda and Yaoqing Yang and
    Michael Mahoney and Joseph Gonzalez and Prateek Prateek Mittal and Kannan Ramchandran
    and Gerald Friedland
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:-FonjvnnhkoC
  abstract: Due to their decentralized nature, federated learning (FL) systems have
    an inherent vulnerability during their training to adversarial backdoor attacks.
    In this type of attack, the goal of the attacker is to use poisoned updates to
    implant so-called backdoors into the learned model such that, at test time, the
    model’s outputs can be fixed to a given target for certain inputs.(As a simple
    example, if a user types “people from New York” into a mobile keyboard app that
    uses a backdoored next word prediction model, then the model could auto-complete
    the sentence to “people from New York are rude”). Prior work has shown that backdoors
    can be inserted into FL models, but these backdoors are often not durable, ie,
    they do not remain in the model after the attacker stops uploading poisoned updates.
    Thus, since training typically continues progressively in production FL systems,
    an inserted backdoor may not survive until deployment. Here, we propose Neurotoxin,
    a simple one-line modification to existing backdoor attacks that acts by attacking
    parameters that are changed less in magnitude during training. We conduct an exhaustive
    evaluation across ten natural language processing and computer vision tasks, and
    we find that we can double the durability of state-of-the-art backdoors.
- title: 'FogROS: An Adaptive Framework for Automating Fog Robotics Deployment and
    Co-scheduling Feature Updates and Queries for Feature Stores'
  authors: Yafei Liang and Joseph Gonzalez and Joseph M Hellerstein
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ODE9OILHJdcC
  abstract: Power, weight, and cost considerations often mean robots do not include
    computing capabilities capable of running large-scale multi-core CPU-based, graphics
    processing unit (GPU)-based, field-programmable gate array (FPGA)-based, or tensor
    processing unit (TPU)-based algorithms. For example, a light-weight drone with
    an attached gripper that uses a GPU-based grasp-planning module to compute grasp
    points for picking up objects [4] or perching [48], requires access to a GPU that
    the drone would not have onboard. While nearby computers can provide the necessary
    computing capabilities, this practice can be complex to set up, scale, and is
    prone to over-provisioning. Instead, we propose a framework based on the Fog Robotics
    [24, 40, 60] idea of balancing between the compute available at the edge and in
    the cloud. This framework, FogROS, is an extension of the Robot Operating System
    (ROS)[47] that, with minimal effort, allows researchers to deploy components of
    their software to the cloud, and correspondingly gain access to additional computing
    cores, GPUs, FPGAs, and TPUs, as well as predeployed software made available by
    other researchers. ROS, at its core, is a platform in which software components
    (nodes) communicate with each other via a publication/subscription (pub/sub) system.
    Individual nodes can publish messages to named topics and subscribe to other named
    topics to get messages published by other nodes. In practice, these nodes all
    run on the robot and perhaps a nearby computer. For example, on a robot, a sensor
    node publishes to a sensor topic, a planning node subscribes to the sensor topic
    and …
- title: 'Masked Layer Distillation: Fast and Robust Training Through Knowledge Transfer
    Normalization'
  authors: Derek Wan and Paras Jain and Tianjun Zhang and Joseph Gonzalez and Kurt
    Keutzer
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:MLfJN-KU85MC
  abstract: Distillation is a common tool to compress models, accelerate training,
    and improve model performance. Often a model trained via distillation is able
    to achieve accuracy exceeding that of a model with the same architecture but trained
    from scratch. However, we surprisingly find that distillation incurs significant
    accuracy penalties for EfficientNet and MobileNet. We offer a hypothesis as to
    why this happens as well as Masked Layer Distillation, a new training algorithm
    that recovers a significant amount of this performance loss and also translates
    well to other models such as ResNets and VGGs. As an additional benefit, we also
    find that our method accelerates training by 2x to 5x and is robust to adverse
    initialization schemes.
- title: Learning Self-Supervised Representations of Code Functionality
  authors: Paras Jain and Ajay Jain and Tianjun Zhang and Pieter Abbeel and Joseph
    Gonzalez and Ion Stoica
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:anf4URPfarAC
  abstract: 'Recent work learns contextual representations of source code by reconstructing
    tokens from their context. For downstream semantic understanding tasks like summarizing
    code in English, these representations should ideally capture program functionality.
    However, we show that the popular reconstruction-based BERT model is sensitive
    to source code edits, even when the edits preserve semantics. We propose ContraCode:
    a contrastive pre-training task that learns code functionality, not form. ContraCode
    pre-trains a neural network to identify functionally similar variants of a program
    among many non-equivalent distractors. We scalably generate these variants using
    an automated source-to-source compiler as a form of data augmentation. Contrastive
    pre-training improves JavaScript summarization and TypeScript type inference accuracy
    by 2% to 13%. We also propose a new zero-shot JavaScript code clone detection
    dataset, showing that ContraCode is both more robust and semantically meaningful.
    On it, we outperform RoBERTa by 39% AUROC in an adversarial setting and up to
    5% on natural code.'
- title: 'LS3: latent space safe sets for long-horizon visuomotor control of iterative
    tasks'
  authors: Albert Wilcox and Ashwin Balakrishna and Brijen Thananjeyan and Joseph
    E Gonzalez and Ken Goldberg
  venue: Conference on Robot Learning (CoRL)
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:JoZmwDi-zQgC
  abstract: ''
- title: A Study of Transfer Learning Methods within Natural Language Processing and
    Reinforcement Learning
  authors: Shrishti Jeswani and Joseph Gonzalez and John F Canny
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Tiz5es2fbqcC
  abstract: The classic supervised machine learning paradigm is based on learning
    in isolation, where each task is solved by using a separate model with a single
    dataset. Transfer learning is a set of methods used to overcome the isolated learning
    paradigm by utilizing knowledge acquired for one task to solve related ones. By
    leveraging data from additional domains or tasks, models are able to generalize
    better and transfer knowledge between tasks. In fact, transfer learning is very
    reminiscent to how humans approach learning; humans have the inherent ability
    to utilize knowledge/experiences from previous tasks and domains to solve new
    tasks. In the last few years, Natural Language Processing (NLP) has witnessed
    the emergence of several transfer learning methods and architectures; these techniques
    have significantly improved performance on a wide range of NLP tasks and transformed
    the landscape of NLP research. Similarly, within reinforcement learning (RL),
    there has been an increased interest in training agents to adapt to different
    environments by learning from previous experience. There are several interesting
    transfer learning applications within NLP and RL; we explore a few of them within
    this work.In real-world NLP settings, the examples received at test-time are often
    drawn from a different distribution than examples during training. Since many
    distribution shifts are unforeseen in practice, language models must be robust
    to out-of-distribution examples at test time without prior knowledge of the distribution
    shift. In this work, we explore a new setting where there is no data available
    during training to anticipate distribution shifts at test-time …
- title: Challenges and Tradeoffs in Trajectory Prediction for Autonomous Driving
  authors: Alvin Kao and Joseph Gonzalez
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:2P1L_qKh6hAC
  abstract: Autonomous vehicles (AVs) have the potential to revolutionize transportation
    by increasing safety, reducing traffic congestion and the resulting carbon emissions,
    providing mobility to people with disabilities, and enabling rapid, low-cost shipping.
    The National Highway Traffic Safety Administration expects AVs to (i) remove human
    error from traffic accidents, which made up 94% of the 37,133 motor-vehicle related
    deaths in the US in 2017 [28],(ii) increase traffic flow, which could potentially
    free up as much as 50 minutes per person per day [24], and (iii) provide new employment
    opportunities to approximately 2 million people with disabilities [10].In spite
    of all the perceived benefits, fully autonomous vehicles are still far from reality.
    Table 1.1 shows that production vehicles have collectively driven an order-of-magnitude
    less than the 291 million fatality-free miles needed to claim that autonomous
    vehicles are as safe as human drivers with 95% confidence [16, 34].
- title: Interpretable Few-Shot Image Classification with Neural-Backed Decision Trees
  authors: Scott Lee and Joseph Gonzalez and Matthew Wright
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:mvPsJ3kp5DgC
  abstract: In image-based tasks such as image classification and semantic segmentation,
    deep learning techniques, especially convolutional neural networks (CNNs), have
    become increasingly popular due to their high accuracy [14, 6, 12, 23, 7, 8].
    Although CNNs often yield state-ofthe-art accuracy results for such tasks, they
    provide little insight into the decision-making mechanism of the neural network
    itself. Indeed, this major limitation of CNNs makes it difficult to diagnose their
    misclassifications and other errors. Despite this, CNNs are still widely favored
    due to their high performance, especially in cases where forgoing explainability
    yields significantly higher accuracy.With increasing applications of computer
    vision and artificial intelligence in industry, however, explainable AI has become
    a major priority in high-stakes applications (eg medical services, autonomous
    vehicles) and right-to-explanation interpretability tasks (eg explaining insurance
    decisions, GDPR compliance). In such sensitive scenarios where it is paramount
    to understand how a model arrives at its prediction, decision trees are one of
    the most popular methods due to their transparency. By reducing the task at hand
    into a series of smaller sub-decisions, each represented by a branch split in
    the tree, one can better infer which decisions are made for a given input by tracing
    the path taken in the tree; furthermore, even for incorrect predictions, one can
    analyze the outcome by locating the branches with incorrect sub-decisions. Even
    when decision trees do not output the correct prediction for a particular input,
    they provide useful information for both human intervention (when a human …
- title: Communication-Efficient Federated Learning with Sketching
  authors: Ashwinee Panda and Daniel Rothchild and Enayat Ullah and Nikita Ivkin and
    Ion Stoica and Joseph Gonzalez and Raman Arora and Vladimir Braverman
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:4fKUyHm3Qg0C
  abstract: Existing approaches to federated learning suffer from a communication
    bottleneck as well as convergence issues due to sparse client participation. In
    this paper we introduce a novel algorithm, called FedSketchedSGD, to overcome
    these challenges. FedSketchedSGD compresses model updates using a Count Sketch,
    and then takes advantage of the mergeability of sketches to combine model updates
    from many workers. A key insight in the design of FedSketchedSGD is that, because
    the Count Sketch is linear, momentum and error accumulation can both be carried
    out within the sketch. This allows the algorithm to move momentum and error accumulation
    from clients to the central aggregator, overcoming the challenges of sparse client
    participation while still achieving high compression rates. We prove that FedSketchedSGD
    has favorable convergence guarantees, and we demonstrate its empirical effectiveness
    by training two residual networks and a transformer model.
- title: Efficient Inference on Video, In Real-Time and At Scale
  authors: Samvit Jain and Joseph Gonzalez
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Dip1O2bNi0gC
  abstract: A large and growing majority of the data streamed on the Internet today
    is video. In 2016, video constituted 73% of web traffic, more than gaming (1%),
    file sharing (8%), and basic web data (18%), a figure expected to reach 82% by
    2021 [5]. Within video traffic, the most rapidly growing segment is live video–video
    that is streamed as it is captured, to social media users, anomaly detection systems,
    and other entities, human and non-human. Live video formed only 3% of video traffic
    in 2016, but its share is projected to triple by 2021 [5]. Underpinning this growth
    is a plethora of new use cases–journaling and event broadcasting (Facebook Live,
    Twitter Periscope); visual monitoring for industrial and agricultural oversight,
    retail intelligence, and public security; and perception-based autonomous systems
    (Tesla Autopilot). The video these applications accept as input originates from
    a wide range of sources, including …
- title: 'Cloud programming simplified: A berkeley view on serverless computing. arXiv'
  authors: Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-Che
    Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira
    and Karl Krauth and Neeraja Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa
    and Ion Stoica and David A Patterson
  venue: arXiv preprint arXiv:1902.03383
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:tkaPQYYpVKoC
  abstract: ''
- title: On-Policy Imitation Learning from an Improving Supervisor
  authors: Ashwin Balakrishna and Brijen Thananjeyan and Jonathan Lee and Arsh Zahed
    and Felix Li and Joseph E Gonzalez and Ken Goldberg
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:3s1wT3WcHBgC
  abstract: Most on-policy imitation algorithms, such as DAgger, are designed for
    learning with a fixed supervisor. However, there are many settings in which the
    supervisor improves during policy learning, such as when the supervisor is a human
    performing a novel task or an improving algorithmic controller. We consider learning
    from an “improving supervisor” and derive a bound on the static-regret of online
    gradient descent when a converging supervisor policy is used. We present an on-policy
    imitation learning algorithm, Follow the Improving Teacher (FIT), which uses a
    deep model-based reinforcement learning (deep MBRL) algorithm to provide the sample
    complexity benefits of model-based methods but enable faster training and evaluation
    via distillation into a reactive controller. We evaluate FIT with experiments
    on the Reacher and Pusher MuJoCo domains using the deep MBRL algorithm, PETS,
    as the improving supervisor. To the best of our knowledge, this work is the first
    to formally consider the setting of an improving supervisor in on-policy imitation
    learning.
- title: Using Multitask Learning to Improve 12-Lead Electrocardiogram Classification
  authors: J Weston Hughes and Taylor Sittler and Anthony D Joseph and Jeffrey E Olgin
    and Joseph E Gonzalez and Geoffrey H Tison
  venue: arXiv e-prints
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:RGFaLdJalmkC
  abstract: We develop a multi-task convolutional neural network (CNN) to classify
    multiple diagnoses from 12-lead electrocardiograms (ECGs) using a dataset comprised
    of over 40,000 ECGs, with labels derived from cardiologist clinical interpretations.
    Since many clinically important classes can occur in low frequencies, approaches
    are needed to improve performance on rare classes. We compare the performance
    of several single-class classifiers on rare classes to a multi-headed classifier
    across all available classes. We demonstrate that the addition of common classes
    can significantly improve CNN performance on rarer classes when compared to a
    model trained on the rarer class in isolation. Using this method, we develop a
    model with high performance as measured by F1 score on multiple clinically relevant
    classes compared against the gold-standard cardiologist interpretation.
- title: 'Server-less computing: One step forward two steps back'
  authors: M Hellerstein Joseph and Faleiro Jose and E Gonzalez Joseph and Schleier-Smith
    Johann and Vikram Sreekanti
  venue: arXiv preprint
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:fEOibwPWpKIC
  abstract: ''
- title: ML Systems Workshop@ NIPS 2017
  authors: Aparna Lakshmiratan and Sarah Bird and Siddhartha Sen and Chris Ré and
    Li Erran Li and Joseph Gonzalez and Dan Crankshaw
  venue: Schedule Highlights
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:u9iWguZQMMsC
  abstract: A new area is emerging at the intersection of artificial intelligence,
    machine learning, and systems design. This birth is driven by the explosive growth
    of diverse applications of ML in production, the continued growth in data volume,
    and the complexity of large-scale learning systems. The goal of this workshop
    is to bring together experts working at the crossroads of machine learning, system
    design and software engineering to explore the challenges faced when building
    practical large-scale ML systems. In particular, we aim to elicit new connections
    among these diverse fields, and identify tools, best practices and design principles.
    We also want to think about how to do research in this area and properly evaluate
    it. The workshop will cover ML and AI platforms and algorithm toolkits, as well
    as dive into machine learning-focused developments in distributed learning platforms,
    programming languages, data structures, GPU processing, and other topics.
- title: Efficient Data Reduction for Large-Scale Genetic Mapping
  authors: Aydın Buluç and Jarrod Chapman and John R Gilbert and Joseph Gonzalez and
    Leonid Oliker
  venue: idea
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:4OULZ7Gr8RgC
  abstract: We present a fast and accurate algorithm for reducing largescale genetic
    marker data to a smaller, less noisy, and more complete set of bins, representing
    uniquely identifiable locations on a chromosome. Our experimental results on real
    and synthetic data show that our algorithm runs in nearlinear time, allowing for
    the analysis of millions of markers. Our algorithm reduces the problem scale while
    preserving accuracy, making it feasible to use existing genetic mapping tools
    without resorting to complex, time-intensive preprocessing methods to filter or
    sample the original data set. Additionally, our approach also decreases the uncertainty
    in genotype calls, improving the quality of the data. Preliminary results demonstrate
    that existing methods for marker ordering designed for the small scale settings
    perform with equivalent accuracy when given our reduced bin set as input.
- title: GABB Introduction
  authors: Tim Mattson and David A Bader and Aydin Buluç and John Gilbert and Joseph
    Gonzalez and Jeremy Kepner
  venue: 2014 IEEE International Parallel & Distributed Processing Symposium Workshops
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:UeHWp8X0CEIC
  abstract: The Basic Linear Algebra Subprograms (BLAS), introduced over 30 years
    ago, had a transformative effect on linear algebra. By building Linear Algebra
    algorithms from a common set of highly optimized building blocks, researchers
    spend less time mapping algorithms onto specific hardware features and more time
    on interesting new algorithms. Could the same transformation occur for Graph algorithms?
    Can Graph algorithm researchers converge around a core set of building blocks
    so we can focus more on algorithms and less on mapping software onto hardware?
    Graph Algorithms Building Blocks workshop (GAB'14) will address these questions.
    The workshop will open with a pair of talks that define a candidate set of graph
    algorithm building blocks that we call the “Graph BLAS”. With this context established,
    the reamining talks explore issues raised by these Graph BLAS, suggest alternative
    sets of low level …
- title: 'Full Text: GraphX: Unifying Data-Parallel and Graph-Parallel Analytics-Onikle'
  authors: Reynold S Xin and Daniel Crankshaw and Ankur Dave and Joseph E Gonzalez
    and Michael J Franklin and Ion Stoica
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:1yQoGdGgb4wC
  abstract: ''
- title: 'IBL2001: Phase (ph) I/II study of a novel dose-dense (dd) schedule of indibulin
    for the treatment of metastastic breast cancer.'
  authors: Tiffany A Traina and Clifford Hudis and Joseph Gonzalez and Stephen Patrick
    Anthony and David A Smith and Jason Claud Chandler and Jaroslaw Jac and Hagop
    Youssoufian and Larry Norton
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:KaMxkj08jr0C
  abstract: 'TPS1143Background:  Indibulin (Zybulin, ZIO‑301) is a new, synthetic
    agent that inhibits tumor cell growth at the G2/M phase through destabilization
    of microtubule dynamics. It binds tubulin at a different site than taxanes and
    vinca alkaloids. Indibulin does not interact with acetylated (neuronal) tubulins
    and has not exhibited the neurotoxicity associated with other tubulin binders.
    Indibulin has potent antitumor activity in human cancer cell lines, including
    multidrug-, taxane-, and vinblastine-resistant lines. Norton-Simon modeling based
    on cell line data suggested that dd administration could optimize efficacy while
    limiting toxicity.  Methods:    Eligible are patients (pts) with metastatic or
    unresectable locally advanced breast cancer, measurable or non-measurable disease,
    and any number of prior therapies. The objective of the Ph I portion is to determine
    the maximum tolerated dose (MTD) of indibulin when given in a …'
- title: The addition of fermented milk with plant sterols improves the adherence
    to lifestyle changes in hypercholesterolemic patients. The RECIPE study
  authors: Lluis Masana and Manuel Lagares and Xavier Pinto and Leandro Reinares and
    Manuel Zuniga and Olivier Descamps and Emanuele Bosi and FA Allaert and John Chapman
    and Erik Bruckert and T Hernandez and C Martin and H Gomes and PJ Perez and EM
    Gil and A Moro and MD Jorda and JL Lopez and M Alba and I Bilbao and MR Alustiza
    and M Aliaga and JG Munoz and AM Terol and P Gomez and MA Marcos and M Gonzalez
    and MJ Rodriguez and MV Lopez and MA Romero and N Puyo and JF Egido and I Monreal
    and A Ramirez and MA Madariaga and MC De Miguel and A Lorda and G Munoz and IM
    Moreno and A Martinez and A Sanchez and A Espino and C Pracht and C Ocana and
    MA Pena and C Domingo and MT Gilaberte and C Garcia and JA Diez and FV Fornes
    and MD Gutierrez and E Macarra and JI Bugella and A Bravo and MJ Becerra and C
    Carbonell and M De Miguel and A Perez and A Martin and J Romero and P Gonzalez
    and A Iglesias and B Lopez and G Villalonga and P Carvajal and C Marin and F Cardona
    and A Gonzalez and G Fernandez and D Gomez and CL Sanchez and D Viveros and MG
    De Lucas and JM Marin and J Osorno and C Pumares and R Gimenez and J Latorre and
    MC Barreiro and JR Villanueva and JA Lopez and I Balaguer and J Baron and M Espuga
    and R Firas and F Trias and A Moran and V Velasco and F Vazquez and A Hernando
    and A Manzanares and JL Abad and M Peraferrer and A Obarrio and ML Alonso and
    L Gomez and J Roca and BE Ayus and F Urban and E Gonzalez and C Masegosa and E
    Barrilero and MC Jimenez and MM Carratala and D Petitbo and J Ferrandiz and MJ
    Mialdea and J Montoro and ME Muncharaz and A Shehchar and L De Paula and A Cano
    and L Sanchez and J Perez and C Alarcon and JF Martinez and T Garrido and F Martinez
    and I Gomariz and M Caparros and T Kseibi and L Palomo and T Jimenez and I Luque
    and P Villar and JJ Gonzalez and J Aparicio and O Jimenez and JJ Munoz and F Baez
    and MP Marcos and T Gonzalez and JA Estevez and J Garcia and S Ajuria-Gogeasko
    and M Cabrera and JM Manzano and G Segura and X Abat and N Yanovsky and JM Borrachero
    and M Fortuny and MD Martinez and AR Gutierrez and N Najem and MC Romero and S
    Martin and RJ Valverde and C Molina and B Martinez
  venue: CLÍNICA E INVESTIGACIÓN EN ARTERIOSCLEROSIS
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:5MTHONV0fEkC
  abstract: Introduction RECIPE study was designed to assess the impact of dietary
    supplementation with fermented milk enriched with plant sterols (FMPS) on the
    nutritional behavior, lifestyle and the joint therapeutic responsibility of hypercholesterolemic
    patients. Methods Observational, prospective, multicenter, international study,
    was conducted to assess dietary habits and other lifestyle components in hypercholesterolemic
    patients in whom the general practitioner indicated FMPS supplementation. Nutritional,
    lifestyle and clinical data were collected at the initial visit and after a 4
    months follow-up. The biochemical and anthropometric data were retrieved from
    medical records obtained at baseline and 4 months. Results We report the results
    of Spain. Two hundred and one physicians who provided valid data of 1044 patients
    participated. The addition of FMPS was associated with improved overall nutritional
    index, being adequate initially in 28.2% of patients, and increasing up to 75.2%
    at the end of the study (P< 001). This nutritional change was associated with
    an improvement in the lipid profile and anthropometric data. Patients more adherent
    to therapy generally achieved a better result in all parameters compared to non-compliant
    ones. Conclusions The addition of FMPS to a diet designed to reduce the LDL enhances
    the patient's attitude regarding changes in lifestyle, leading to better overall
    control of dyslipidemia and anthropometric improvement.© 2012 Elsevier España,
    SL and SEA.
- title: Dallera V, 279 Daniels JSM, 135 Danino A, 314 Deppe H, 211 Drebber U, 166
  authors: J Acero and N Adolphs and M Albanese and I Alvarez and AP Angelopoulos
    and MH Ansari and D Attelscheck and A Bakardjiev and AJ Baldwin and M Baltensperger
    and A Bartnick and A Barutcu and C Baytekin and L Bedrin and K Bekes and V Bellot-Samson
    and G Berger and S Berrone and L Berthold and SK Bhatnagar and E Biemer and J
    Bier and F Biglioli and JL Blanc and RA Bockmann and P Boettcher and H Boos and
    KH Breuning and E Bruder and R Brusati and A Bucur and B Canbaz and F Cheynet
    and FM Chiari and L Chiarini and BH Choi and C Chossegros and P Christophis and
    L Clauser and C Concejo and JC Cooper and S Crean and M Cuesta-Gil and B Erol
    and J Ervens and G Eyrich and MT Fadda and M Fasolis and JR Fernandez and F Ferrari
    and S Figurelli and M Folwaczny and Francesco Nocini and JK Fraser and RE Friedrich
    and A Gaggl and M Galie and M Gallas Torreira and P Garzino-Demo and S Gatti and
    P Gennaro and CR Gernhardt and C Glaser and J Godzinski and R Gola and J Gonzalez
    and B Gorgun and K Gratz and O Guven and L Guyot and L Hadjipetrou and PE Haers
    and C Haffner and SG Han and S Hanstein and N Hardt and K Harii and J Hartel and
    S Hassfeld and T Hattori and MH Hedrick and K Heidinger and A Hemprich and K Hendrickx
    and J Henke and KO Henkel and R Hickel
  venue: Journal of Cranio-Maxillofacial Surgery
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:-jrNzM816MMC
  abstract: "Author Index: Volume 32 Page 1 Author Index: Volume 32 A Acero J, 21\
    \ Adolphs N, 391 \nAlbanese M, 5 Alvarez I, 155 Angelopoulos AP, 350 Ansari MH,\
    \ 28 Attelscheck D, 324 B \nBakardjiev A, 90 Baldwin AJ, 354 Baltensperger M,\
    \ 43 Bartnick A, 247 Barutcu A, 243 Baytekin \nC, 243 Bedrin L, 19 Bekes K, 85\
    \ Bellot-Samson V, 98 Berger G, 330 Berrone S, 251 Berthold L, \n370 Bhatnagar\
    \ SK, 38 Biemer E, 199 Bier J, 391 Biglioli F, 94 Blanc JL, 98 Bockmann RA, 71\
    \ \nBoettcher P, 199 Boos H, 199 Breuning KH, 119 Bruder E, 43 Brusati R, 94 Bucur\
    \ A, 16 C \nCanbaz B, 64 Cheynet F, 98 Chiari FM, 324 Chiarini L, 5 Choi BH, 51\
    \ Chossegros C, 98 \nChristophis P, 370 Clauser L, 279 Concejo C, 21 Cooper JC,\
    \ 354 Crean S, 170 Cuesta-Gil M, \n21 D Dallera V, 279 Daniels JSM, 135 Danino\
    \ A, 314 Deppe H, 211 Drebber U, 166 E El Khatib \nK, 314 Erdinler P, 64 Erhardt\
    \ W, 199 Erol B, 308 Ervens J, 330 Eyrich G, 43 F Fadda MT, 220 …"
- title: Simulating a Fountain
  authors: Lyric P Doshi and Joseph Edgar Gonzalez and Philip B Kidd
  venue: UMAPJournal
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:vRqMK49ujn8C
  abstract: We establish the mathematical behavior of water droplets emitted from
    a fountain and apply this behavior in a computer model to predict the amount of
    splash and spray produced by a fountain under given conditions. Our goal is a
    control system that creates the tallest fountain possible while limiting water
    spillage to a specified level.We combine height and volume of the fountain spray,
    making both functions of the speed at which water exits the fountain nozzle. We
    simulate water droplets launched from the fountain, using basic physics to model
    the effects of drag, wind, and gravity. The simulation tracks the flight of droplets
    in the air and records their landing positions, for wind speeds from 0 to 15 m/s
    and water speeds from 5 to 30 m/s. It calculates the amount of water spilled outside
    of a pool around the fountain, for pool radii from 0 to 40 m. We design an algorithm
    for a programmable logic controller, located inside an anemometer, to do a table
    search to find allowable water speeds for given pool radius, acceptable water
    spillage, and wind velocity. We test the control system with simulation, subjecting
    a fountain with a 4-m pool radius to wind speeds from 0 to 3 m/s with an allowable
    spillage of 5%. We also test the model for accuracy and for sensitivity to changes
    in the base variables.
- title: The Crowd Before the Storm
  authors: Jonathan David Charlesworth and Finale Pankaj Doshi and Joseph Edgar Gonzalez
  venue: UMAPJournal
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:5Ul4iDaHHb8C
  abstract: Applying safety regulations and flow-density equations, we find the maximum
    rate of flow through a lane of road is 1,500 cars/h, occurring when cars travel
    at 27.6 mph.We construct a computer simulation that tracks the exit of cars through
    South Carolina’s evacuation network. We attempt to optimize the network by reversing
    opposing lanes on various roads and altering the time that each city should begin
    evacuating, using a modified genetic algorithm. The best solution—the one that
    evacuates the most people in 24 h—involves reversing all the opposing lanes on
    evacuation routes. Increasing the holding capacity of Columbia is only marginally
    helpful. Georgia and Florida traffic on I-95 is only mildly detrimental, but allowing
    people to take their boats and campers greatly decreases the number of people
    that can be evacuated.
- title: Thrombocytosis and coronary disease. Report of a case
  authors: JR Rumoroso and PM Montes and A Jiménez and J Alcíbar and JC Cembellin
    and J González and JI Arrizabalaga and JI Barrenetxea
  venue: Revista Espanola de Cardiologia
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:lgwcVrK6X84C
  abstract: We report the case of a young male with an inferior myocardial infarction
    who was treated with fibrinolytic agents and displayed a good evolution. The only
    cardiovascular risk factor that this patient had was an idiopathic thrombocytosis
    with abnormal platelet hyperreactivity tests. The angiogram showed an eccentric
    lesion of 60% in the left main coronary artery. A week later, after treatment
    based on anticoagulants and antithrombotic agents the angiogram was normal, and
    the lesion had disappeared. The association between these conditions is discussed
    the therapeutic approach is also discussed. A review of the literature is conducted.
- title: 'Desarrollo embriológico humano: aparición" anomalías cardio-vasculares"'
  authors: Luis Álvarez de Cifuengos Rodríguez and Antonia Aránega Jiménez and JE
    Fernández and J González
  venue: Actualidad médica
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:FiytvqdAVhgC
  abstract: ''
- title: Actividad sexual de la oveja merina durante el periodo de lactacion y su
    interaccion con el anoestro estacional.
  authors: J Gonzalez and J Alvarez and V Domenech
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:3NQIlFlcGxIC
  abstract: "Actividad sexual de la oveja merina durante el periodo de lactacion y\
    \ su interaccion con el \nanoestro estacional. Food and Agriculture Organization\
    \ of the United Nations Discover About \nFAO News Multimedia Main topics Statistics\
    \ Members Publications English العربية Español \nFrançais Русский 中文 AGRIS - International\
    \ System for Agricultural Science and Technology \nAbout AGRIS Contribute Acceptable\
    \ use policy facebook linkedin twitter weibo Close \nAdvanced Search Actividad\
    \ sexual de la oveja merina durante el periodo de lactacion y su \ninteraccion\
    \ con el anoestro estacional. 1984 Gonzalez J. | Alvarez J. | Domenech V. AGROVOC\
    \ \nKeywords brebis breeds ciclo estral comportamiento sexual comportement sexuel\
    \ cycle \noestral ewes lactation oestrous cycle oveja ovin ovinos race razas sexual\
    \ behaviour sheep \nBibliographic information Other Subjects lactacion Language\
    \ Spanish; Castilian Note ill. 14 …"
- title: Sexual activity of the Merino ewe during the lactation period and its interaction
    with seasonal anestrus
  authors: J Gonzalez and J Alvarez and V Domenech
  venue: 10. international congress on animal reproduction and artificial insemination,
    University of Illinois at Urbana-Champaign, Illinois (USA), 10-14 Jun 1984
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:1yWc8FF-_SYC
  abstract: ''
- title: '[Male influence on the sexual activity of the Merino ewe during seasonal
    anestrus].[Spanish]'
  authors: J Gonzalez and J Alvarez and A Jimenez
  venue: 10. international congress on animal reproduction and artificial insemination.
    University of Illinois at Urbana-Champaign, Illinois (USA). 10-14 Jun 1984.
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:kw52XkFRtyQC
  abstract: ''
- title: The influence of the male on sexual activity of the Merino ewe during seasonal
    anoestrus.
  authors: J Gonzalez and J Alvarez and A Jimenez
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:1taIhTC69MYC
  abstract: Of 49 Merino ewes, 24 were run with rams for 23 days during seasonal anoestrus,
    and 25 were isolated from ♂♂. The presence of the ♂ provoked reactivation of the
    ovaries, oestrus and ovulation in 72% of the ♀♀ 24 days after introduction of
    the ♂♂.
- title: Tradeoffs in using Remote Resources to Improve Autonomous Driving Safety
  authors: Alexander Krentsel and Peter Schafhalter and Joseph E Gonzalez and Sylvia
    Ratnasamy and Scott Shenker and Ion Stoica
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:OBSaB-F7qqsC
  abstract: Prevailing wisdom asserts that one cannot rely on the cloud for critical
    real-time control systems like self-driving cars. We argue that we can, and must.
    Following the trends of increasing model sizes, improvements in hardware, and
    evolving mobile networks, we identify an opportunity to offload parts of time-sensitive
    and latency-critical compute to the cloud. Doing so requires carefully allocating
    bandwidth to meet strict latency SLOs, while maximizing benefit to the car.
- title: 'FogROS: A User-Friendly+ Adaptive Framework for Fog Robotics+ Automation'
  authors: Kaiyuan Eric Chen and Yafei Liang and Nikhil Jha and Jeffrey Ichnowski
    and Michael Danielczuk and Joseph Gonzalez and John Kubiatowicz and Ken Goldberg
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:Br1UauaknNIC
  abstract: As many robot automation applications increasingly rely on multi-core
    processing or deep learning models, cloud computing is becoming an attractive
    and economically viable resource for systems that do not contain high computing
    power onboard. Despite its immense computing capacity, it is often underused by
    the robotics and automation community due to lack of expertise in cloud computing
    and cloud-based infrastructure. Fog Robotics balances computing and data between
    cloud edge devices. We propose a software framework, FogROS, that allows existing
    applications to gain access to additional computing cores, graphics-processing
    units (GPUs), fieldprogrammable gate arrays (FPGAs), and tensor-processing units
    (TPUs) available on commercial cloud-based services. This framework is built on
    Robot Operating System (ROS), the de-facto standard for creating robot automation
    applications and components. FogROS allows a researcher to specify which components
    of their software will be deployed to the cloud and to what type of computing
    hardware. We evaluate FogROS on 3 examples:(1) simultaneous localization and mapping
    (SLAM),(2) Dexterity Network (Dex-Net) GPU-based grasp planning, and (3) multi-core
    motion planning using a 96-core cloudbased server. In all three examples, a component
    is deployed to the cloud and accelerated with a small change in system launch
    configuration, while incurring additional latency of 1.2 s, 0.6 s, and 0.5 s due
    to network communication, the computation speed is improved by 4.5×, 5.2× and
    31.5×, respectively. Code, videos, and supplementary material can be found at
    https://github …
- title: Appendix for:“Simple Token-Level Confidence Improves Caption Correctness”
  authors: Suzanne Petryk and Spencer Whitehead and Joseph E Gonzalez and Trevor Darrell
    and Anna Rohrbach and Marcus Rohrbach
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:0CzhzZyukY4C
  abstract: Appendix B provides details on how the confidence threshold γ is chosen.
    Appendix C presents an ablation showing several alternative algebraic confidence
    estimates, and compares the precision-recall curve for the learned TLC-L to that
    of algebraic confidences when separating correct and hallucinated objects. Appendix
    D presents additional qualitative examples of both success and failure cases,
    comparing TLC-L to the Baseline model. Appendix E and Appendix F provide further
    details on datasets and models respectively.
- title: Graph Algorithms Building Blocks (GABB’2014)
  authors: Tim Mattson and David Bader and Aydın Buluç and John Gilbert and Joseph
    Gonzalez and Jeremy Kepner
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:gKiMpY-AVTkC
  abstract: The Basic Linear Algebra Subprograms (BLAS), introduced over 30 years
    ago, had a transformative effect on linear algebra. By building Linear Algebra
    algorithms from a common set of highly optimized building blocks, researchers
    spend less time mapping algorithms onto specific hardware features and more time
    on interesting new algorithms. Could the same transformation occur for Graph algorithms?
    Can Graph algorithm researchers converge around a core set of building blocks
    so we can focus more on algorithms and less on mapping software onto hardware?
    Graph Algorithms Building Blocks workshop (GAB’14) will address these questions.
    The workshop will open with a pair of talks that define a candidate set of graph
    algorithm building blocks that we call the “Graph BLAS”. With this context established,
    the reamining talks explore issues raised by these Graph BLAS, suggest alternative
    sets of low level building blocks, and finally consider lessons learned from past
    standards efforts. We will close with an interactive panel about our collective
    quest to standardize a set of core graph algorithm building blocks.
- title: '論文翻訳:" Gorilla: Large Language Model Connected with Massive APIs'
  authors: Shishir G Patil and Tianjun Zhang and Xin Wang and Joseph E Gonzalez
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:_OXeSy2IsFwC
  abstract: Gorilla AI の紹介 YouTube の紹介記事を先日書いたのですが, やはり 1 次情報が大切なので, 本家の論文を紹介したいと思います.
- title: Energy-based Predictive Representation for Reinforcement Learning
  authors: Tianjun Zhang and Tongzheng Ren and Chenjun Xiao and Wenli Xiao and Joseph
    E Gonzalez and Dale Schuurmans and Bo Dai
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:DJbcl8HfkQkC
  abstract: In real world applications, it is usually necessary for a reinforcement
    learning algorithm to handle the partial observability beyond Markov decision
    processes (MDPs). Although the partially observable Markov decision process (POMDP)
    has been precisely motivated for this requirement, such a formulation raises significant
    computational and statistical hardness challenges in learning and planning. In
    this work, we introduce the Energy-based Predictive Representation (EPR), which
    leads to a unified framework for practical reinforcement learning algorithm design
    in both MDPs and POMDPs settings, to handle the learning, exploration, and planning
    in a coherent way. The proposed approach relies on the powerful neural energy-based
    model to extract sufficient representation, from which Q-functions can be efficiently
    approximated. With such a representation, we develop an efficient approach for
    computing confidence, which allows optimism/pessimism in the face of uncertainty
    to be efficiently implemented in planning, hence managing the exploration versus
    exploitation tradeoff. An experimental investigation shows that the proposed algorithm
    can surpass state-of-the-art performance in both MDP and POMDP settings in comparison
    to existing baselines.
- title: Yucheng Low, Haijie Gu, Danny Bickson, and Carlos Guestrin. 2012
  authors: Joseph E Gonzalez
  venue: 'PowerGraph: Distributed Graph-parallel Computation on Natural Graphs (OSDI’12)'
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:tuHXwOkdijsC
  abstract: ''
- title: 'Design and Implementation is sponsored by USENIX. GraphX: Graph Processing
    in a Distributed Dataflow Framework'
  authors: Joseph E Gonzalez and Reynold S Xin and Ankur Dave Daniel Crankshaw and
    Michael J Franklin
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:zLWjf1WUPmwC
  abstract: ''
- title: Jun Huan 397 Chih-Wei Huang 521 Degen Huang 379, 493, 497 De-Shuang Huang
    31, 86
  authors: Lu Feng and Herman Ferra and Pedro M Ferreira and Guillaume Fertin and
    Changlin Fu and Goutam Ghosh and John Gilbert and Bruce Golden and Haijun Gong
    and Joseph Gonzalez and Benjamin Goudey and Russell Greiner and Jianying Gu and
    Yi Guan and Alexandre Guerra and Haitao Guo and Minyi Guo and Rui Guo and Christophe
    Guyeux and Pietro Hiram Guzzi and E Mark Haccke and Sangjo Han and Shiying Hao
    and Yuantao Hao and Nigel Harris and Aaron Harwood and Liang He and Zehui He and
    Aron Henriksson and Nic Herndon and Stephan Heuer and Raquel Hontecillas and Stefan
    Hoops and Bin Hu and Qian-nan Hu and Qinmin Hu and Xiaopeng Hu
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:kRWSkSYxWN8C
  abstract: "Author index Page 1 Author Index M. Roselle Abraham 224 Theodore Abraham\
    \ 224 Jeagyoon \nAhn 201 Bassam AlKindy 71 Yuan An 444, 515, 578 Michael Andel\
    \ 410 Sameer Antani 289 \nLars Asker 536 Dean A Attali 51 Jacques M. Bahi 71 Yang\
    \ Bai 205 Josep Bassaganya-Riera \n391 Matthias Becker 279 Amir Ben-Dor 99 Sílvia\
    \ Bessa 325 Mahua Bhattacharya 601 \nMoumita Bhattacharya 348 Noha Bhiary 605\
    \ Amrisha Bhosle 209 Jinbo Bi 340 Inanç Birol 51 \nEnrico Blanzieri 480 Henrik\
    \ Boström 536 Hazel Boyd 608 Rui M. Branca 99 Claus Braun 424 \nPedro Brites 261\
    \ Fiona Browne 25, 385 Diyue Bu 63 Aydin Buluc 3 Hugh Byrne 254 Hanshu \nCai 529\
    \ Hong Cai 107 Richard Campbell 403 Marco Canepa 344 Hongfei Cao 463 Doina \n\
    Caragea 432, 501 Adria Carbo 391 Jaime Cardoso 325 Jaime S. Cardoso 293 Pedro\
    \ Cardoso \n325 Hubert Cecotti 230, 335 Kihoon Cha 162 Nagasuma Chandra 209 Jarrod\
    \ Chapman 3 …"
- title: Support Vector Machines
  authors: Joseph Gonzalez
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:uWQEDVKXjbEC
  abstract: "Support Vector Machines Page 1 Support Vector Machines Joseph Gonzalez\
    \ Page 2 From a \nlinear classifier to ... *One of the most famous slides you\
    \ will see, ever! Page 3 O X O O X X X \nX X X O O O O O O Page 4 Maximum margin\
    \ Maximum possible separation between positive \nand negative training examples\
    \ *One of the most famous slides you will see, ever! Page 5 \nGeometric Intuition\
    \ O X O O O X X X SUPPORT VECTORS Page 6 Geometric Intuition O X X \nO O O X X\
    \ X SUPPORT VECTORS Page 7 Primal Version min ||w|| 2 +C ∑ξ st (wx + b)y ≥ \n\
    1-ξ ξ ≥ 0 Page 8 DUAL Version Where did this come from? Remember Lagrange Multipliers\
    \ \nLet us “incorporate” constraints into objective Then solve the problem in\
    \ the “dual” space of \nlagrange multipliers max ∑α-1/2 ∑αiαjyiyjxixj st ∑αiyi\
    \ = 0 C ≥ αi ≥ 0 Page 9 Primal vs \nDual Number of parameters? large # features?\
    \ large # examples? for large # features, DUAL …"
- title: 'T: Efficient Ad-Hoc Analytics on Time-Evolving Graphs'
  authors: Anand Padmanabha Iyer and Qifan Pu and Kishan Patel and Joseph E Gonzalez
    and Ion Stoica
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:dshw04ExmUIC
  abstract: Several emerging evolving graph application workloads demand support for
    efficient ad-hoc analytics—the ability to perform ad-hoc queries on arbitrary
    time windows of the graph. Existing systems face limitations when used for such
    tasks. We present T, a system that enables efficient adhoc window operations on
    evolving graphs. T enables efficient access to the state of the graph at arbitrary
    windows, and significantly accelerates ad-hoc window queries by using a compact
    in-memory representation for both graph and intermediate computation state. For
    this, it leverages persistent datastructures to build a versioned, distributed
    graph state store, and couples it with an incremental computation model which
    can leverage these compact states. For users, it exposes these compact states
    using Timelapse, a natural abstraction. We extensively evaluate T against existing
    evolving graph analysis techniques, and show that it significantly outperforms
    other systems (by up to 30×) for ad-hoc window operation workloads.
- title: Choose What to Log, After You Execute
  authors: Rolando Garcia and Eric Liu and Nishita Shetty and Anusha Dandamudi and
    Joseph E Gonzalez and Joseph M Hellerstein
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:ns9cj8rnVeAC
  abstract: Research in AI is dominated by experimentation, and training a single
    model can be extremely expensive. In fact, training and experimenting with an
    NLP model can produce more carbon emissions than seven human lifetimes [6]. However,
    we may not know all the questions we would like to ask until after the experiment
    completes, forcing us to re-run expensive experiments to log information that
    we missed the first time. The cost of re-running experiments can be offset by
    intermittent checkpointing, so that we may return and re-execute from these checkpoints,
    but checkpointing at relatively high frequencies would incur a run-time cost that
    is too great to handle. The result is that most data scientists and ML researchers
    checkpoint too infrequently to be effective for it to be an effective method of
    work sharing and analysis.Flor is a system that enables post-hoc analysis of model
    training via fast, memoization-backed, re-execution. Flor automatically makes
    decisions about what to memoize, reducing the burden on users, and uses an optimized
    materialization module so that memoization has minimal impact on execution. Our
    re-executions have order of magnitude speedups and can be done simply by adding
    log statements to the code. This makes it easy for the developer to conduct post-hoc
    analysis and collect values or objects that were lost on the first-pass.
- title: ZHANG, Yi CMU-ML-12-102
  authors: Byron BOOTS and Duen Horng Polo CHAU and Joseph GONZALEZ and Edith LM LAW
    and Benjamin SHIH and Suyash SHRINGARPURE
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:isC4tDSrTZIC
  abstract: ''
- title: Multi-Task Learning via Task Multi-Clustering
  authors: Andy Yan and Xin Wang and Ion Stoica and Joseph Gonzalez and Roy Fox
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:e5wmG9Sq2KIC
  abstract: Multi-task learning has the potential to facilitate learning of shared
    representations between tasks, leading to better task performance. Some sets of
    tasks are related, and can share many features that are useful latent representations
    for these tasks. Other sets of tasks are less related, possibly sharing some features,
    but also competing on the representational resources of shared parameters. We
    propose to discover how to share parameters between related tasks and split parameters
    between conflicting tasks, by learning a multi-clustering of the tasks. We present
    a mixture-of-experts model, where each cluster is an expert that extracts a feature
    vector from the input, and each task belongs to a set of clusters whose experts
    it can mix. In experiments on the CIFAR-100 MTL domain, multi-clustering outperforms
    a model that mixes all experts in accuracy and computation time. The results suggest
    that the performance of our method is robust to regularization that increases
    the model’s sparsity when sufficient data is available, and can benefit from sparser
    models as data becomes scarcer.
- title: An Empirical Exploration of Gradient Correlations in Deep Learning
  authors: Daniel Rothchild and Roy Fox and Noah Golmant and Joseph Gonzalez and Michael
    Mahoney and Kai Rothauge and Ion Stoica and Zhewei Yao
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:9ZlFYXVOiuMC
  abstract: We introduce the mean and RMS dot product between normalized gradient
    vectors as tools for investigating the structure of loss functions and the trajectories
    followed by optimizers. We show that these quantities are sensitive to well-understood
    properties of the optimization algorithm, and we argue that investigating these
    quantities in detail can provide insight into properties that are less well understood.
    Using these tools, we observe that variance in the gradients of the loss function
    can be mostly explained by a small number of dimensions, and we compare results
    when training networks within the subspace spanned by the first few gradients
    to those obtained by training within a randomly chosen subspace.
- title: Optimistic Concurrency Control for Distributed Learning
  authors: Xinghao Pan and Joseph E Gonzalez and Stefanie Jegelka and Tamara Broderick
    and Michael I Jordan
  venue: ''
  year: ''
  citations: 0
  url: https://scholar.google.com/citations?view_op=view_citation&citation_for_view=B96GkdgAAAAJ:3fE2CSJIrl8C
  abstract: "Optimistic Concurrency Control for Distributed Learning Page 1 DP-‐means:\
    \ Novel clustering \nalgorithm [2] • Extends popular K-‐means approach • Cluster\
    \ data without need to specify # of \nclusters • Small variance asymptotic approx.\
    \ to Dirichlet Process Serial algorithm 1. Read data \nx i and set of clusters,\
    \ represented by centers {µ c } 2. Compute distance d = min c ||x i -µ c ||2 \n\
    of x i to centers {µ c} 3. If d < λ, assign x i to nearest center; Otherwise,\
    \ create new cluster with \ncenter at x i Transaction T i for each data object\
    \ x i: 1. Read cluster centers {µ c } 2. Compute \ndistance d= min c ||x i -µ\
    \ c || of x i to centers {µ c} 3. If d < λ, assign x i to nearest center, commit\
    \ \nimmediately; Otherwise, create new cluster with center at x i, validate x\
    \ i Validate cluster \ncreation for x i 1. Read cluster centers {µ k} created\
    \ since read phase of T i 2. Compute \ndistance d*=min k ||x i -µ k ||2 of x i\
    \ to centers {µ k} 3. If d* < λ, resolve: assign x i to nearest …"
last_updated: '2024-12-29 03:40:25'
